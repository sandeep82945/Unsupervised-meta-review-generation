eid,rid,review,input_text
ICLR_2018_813,6,this paper is well motivated the problem is relevant and also appears in similar form in domain adaptation and transfer learning ..,motivation [SEP] positive [SEP]  this is paper motivated [SEP]  well motivated the problem
ICLR_2018_813,7,the theoretical results justify the optimization procedures presented in section 5. experimental results on the ihdp dataset confirm the advantage of the proposed approach ..,soundness [SEP] positive [SEP]  the results confirm advantage [SEP]  the theoretical results justify procedures [SEP]  the results justify optimization procedures [SEP]  the results ihdp dataset confirm advantage
ICLR_2018_813,8,the implications of the assumptions in theorem 1 are not easy to understand.,soundness [SEP] negative [SEP]  the the implications assumptions not [SEP]  the the implications assumptions
ICLR_2018_813,9,"the derived bounds and procedures are interesting and nontrivial ,.",originality [SEP] positive [SEP]  the derived bounds procedures
ICLR_2018_813,10,manuscript is written in a very compact style and i wish some passages would have been explained in more depth and detail ..,clarity [SEP] negative [SEP]  wish some passages [SEP]  manuscript is written [SEP]  manuscript a is written very compact style
ICLR_2018_813,11,"overall, the paper is well written and organized with good description on the related work, research background, and theoretic proofs ..",clarity [SEP] positive [SEP]  the paper well written [SEP]  organized good description
ICLR_2018_813,12,i appreciate that it is difficult to find good test datasets for evaluating causal estimator ..,substance [SEP] negative [SEP]  i appreciate is [SEP]  find good test datasets [SEP]  evaluating causal estimator
ICLR_2018_726,22,"2 .the experiments are only evaluated on synthetic datasets, and applications of the set autoencoder to real world applications or scientific problems will make this work more interesting and significant. it would have been very interesting to see experiments on real data concerned with sets and have not provided results on real data the experiments are on toy datasets only ..",substance [SEP] negative [SEP]  data real concerned [SEP]  experiments are only evaluated synthetic datasets [SEP]  applications will make this work interesting [SEP]  interesting significant it would have been [SEP]  experiments are [SEP]  sets concerned [SEP]  have not not provided results
ICLR_2018_726,23,"but in the end a bit disappointing the autoencoder does not seem to help much on the regression tasks where even for the smaller training set size setting is perhaps not working well, or is not well suited to the regression tasks being considered ..",soundness [SEP] negative [SEP]  the not help much much regression tasks [SEP]  the bit disappointing autoencoder not seem [SEP]  the smaller training set size setting
ICLR_2018_726,24,this is interesting (and novel the analysis of how the decoder generates data is insightful ..,originality [SEP] positive [SEP]  novel the analysis [SEP]  the how decoder generates data [SEP]  how decoder generates data
ICLR_2018_726,25,compared to the order matters paper.,originality [SEP] negative [SEP]  the order matters paper [SEP]  matters paper
ICLR_2018_726,26,quality this paper describes the proposed model quite well and provides encouraging clarity the paper is easy to understand.,clarity [SEP] positive [SEP]  quality describes the proposed model well [SEP]  is provides encouraging clarity
ICLR_2018_726,27,significance this paper proposes a way of learning representations of sets which will be of broad interest across the machine learning community ..,motivation [SEP] positive [SEP]  significance a paper proposes way [SEP]  learning representations [SEP]  will be broad interest
ICLR_2020_1729,38,the proposed approach is a variation of a fairly well known heuristic. 2 .the proposed approach is not novel. the method it proposes is also a nave extension of existing methods. both the problem setting and the technique does not have novelty. the motivated problem is not new ..,originality [SEP] negative [SEP]  the setting technique [SEP]  the proposed a approach variation [SEP]  the problem setting
ICLR_2020_1729,39,"3 .there have been approaches which attempt to learn rejection function 2, so it would have been good to at least do a comparison of the proposed approach with such methods. finally, there is no comparison with any baseline. the current paper has not discussed any related work of cost sensitive learning although they want to study a problem in its field the paper also lacks the necessary references in many places.",meaningful-comparison [SEP] negative [SEP]  the paper not also lacks necessary references [SEP]  a least do comparison [SEP]  any baseline current paper not [SEP]  any paper has not not not discussed related work [SEP]  a study problem
ICLR_2020_1729,40,and introducing a reject option to flag potential attacks seems a sensitive choice for many applications. the considered problem is well motivated and introduced.,motivation [SEP] positive [SEP]  a introducing reject option [SEP]  flag potential attacks [SEP]  a seems sensitive choice
ICLR_2020_1729,41,the paper fails to realize that the motivated application is actually called.,motivation [SEP] negative [SEP]  the paper fails [SEP]  the realize motivated application
ICLR_2020_1729,42,it is important to investigate this aspect.,substance [SEP] negative [SEP]  it important [SEP]  investigate this aspect
ICLR_2020_1729,43,the paper also has problems in writing. the paper should be also improved in writing in the following aspects. there is a lot of inaccurate statements in the paper. so inaccurate unclear statements that will mislead readers should be avoided. in writing the organization is also problematic. i still think this paper has not been ready to be published yet ..,clarity [SEP] negative [SEP]  paper still think this not [SEP]  the paper also should be improved following aspects [SEP]  the paper also has problems [SEP]  statements unclear will mislead readers [SEP]  the should be inaccurate avoided organization problematic
ICLR_2018_724,108,"it is a very interesting problem and application in reality though, many works in that area are highly relevant and should be discussed in the context of what the authors are trying to achieve ..",motivation [SEP] positive [SEP]  are the authors trying [SEP]  it very interesting problem [SEP]  a very interesting problem application [SEP]  many works that area [SEP]  should be discussed the context
ICLR_2018_724,109,and the approach is interesting but the application is novel.,originality [SEP] positive [SEP]  the approach is interesting [SEP]  the approach is interesting interesting application
ICLR_2018_724,110,"the authors show that it learns co bindings already known in the literature which is a good sanity check but does not offer any new biological insight the model itself is an incremental work ,.",originality [SEP] negative [SEP]  the an model incremental work [SEP]  the authors show [SEP]  the already known literature [SEP]  does not not offer any new biological insight
ICLR_2018_724,111,"as such, in order to establish its broader applicability there should be additional evaluation on other benchmark datasets ..",substance [SEP] negative [SEP]  order establish applicability [SEP]  establish its broader applicability [SEP]  such should be additional evaluation
ICLR_2018_724,112,"the mnist performance comparison is inadequate and there are other papers that do better on it. they should clearly list what the contributions are w.r.t to the work by vinyals et al 2016. they should also cite works that learn embeddings in a multi label setting such as starspace. however, there is no comparison to the exact networks used in the prior works deepbind deepsea danq basset deeplift or bidirectional lstms. further there is no comparison to existing one shot learning techniques either. the empirical evaluation itself is not very strong as there are only modest improvements over simple baselines. authors do not compare their model s performance to the previously published tf binding prediction algorithms (deepbind, deepsea). comparing to it and directly to deepsee bind seems crucial to claim improvements on previous works.",meaningful-comparison [SEP] negative [SEP]  works improvements previous claim [SEP]  the mnist performance comparison inadequate [SEP]  are other papers [SEP]  the should clearly list contributions [SEP]  they should clearly list [SEP]  should also cite works [SEP]  the exact networks used [SEP]  comparison no exact networks [SEP]  existing one shot learning techniques empirical evaluation not [SEP]  s performance do not not not authors compare their model
ICLR_2018_724,113,"the authors claim they can learn tf tf interactions and it is one of the main biological contributions, but there is no evidence of why the prototype loss is too simplistic to capture co binding tendencies and the combinationlstm is not well motivated. one of the main drawbacks is the lack of interpretability of their model where approaches like danq deeplift etc benefit. various choices are not well motivated the fourth claim about the biological relevance of the network is not sufficiently explored ..",soundness [SEP] negative [SEP]  the claim can learn interactions fourth [SEP]  the no evidence prototype loss [SEP]  the lack interpretability
ICLR_2018_724,114,"the paper can benefit from more clarity in the technical aspects. it is hard to follow for anyone not already familiar with matching networks. the objective function, parameters need to be clearly introduced in one place. 2 .the authors miss important context and make some inaccurate statements overall, this manuscript is not well written. clarification is needed in the method and data sections ..",clarity [SEP] negative [SEP]  the is and clarification needed method data sections [SEP]  the paper can benefit [SEP]  paper can benefit more clarity [SEP]  follow anyone [SEP]  not already familiar matching networks [SEP]  parameters need [SEP]  be one clearly introduced place [SEP]  not authors miss important context [SEP]  make some inaccurate statements overall [SEP]  not some inaccurate statements this manuscript [SEP]  not well written clarification
ICLR_2018_724,115,3 .the learning setup seems problematic 1 .it is unclear how the prototype of a tf is learned ..,replicability [SEP] negative [SEP]  learning setup seems is [SEP]  the unclear prototype
ICLR_2018_495,456,while the idea is novel and i do agree that i have not seen other works along these lines the work presented is novel but there are some notable omissions.,originality [SEP] positive [SEP]  the idea novel [SEP]  is have not not seen other works [SEP]  are some notable omissions
ICLR_2018_495,457,the method lacks algorithmic novelty severely lacks algorithmic novelty.,originality [SEP] negative [SEP]  the method lacks novelty [SEP]  method lacks algorithmic novelty [SEP]  method lacks algorithmic novelty
ICLR_2018_495,458,there are a few things that are missing and hinder this paper significantly it's not clear what the actual loss the authors are trying to minimize 2 .the experiments show almost no discernable practical gains over 'random' baseline which is the baseline for random minibatch selection and the proposed approach shows no empirical gains over random mini batch sampling.,soundness [SEP] negative [SEP]  s not not clear what [SEP]  are experiments show gains [SEP]  are no experiments show almost discernable practical gains [SEP]  the gains proposed approach shows [SEP]  no gains approach shows empirical
ICLR_2018_495,459,"2 .the experiments are still at the toy level, the authors can tackle more challenging datasets where sampling goes from easy to hard examples like birdsnap. authors should be motivated to run the large scale experiments ..",substance [SEP] negative [SEP]  the experiments run large scale [SEP]  the experiments toy level [SEP]  hard examples birdsnap
ICLR_2018_495,460,and the exposition of the method severely inhibits the reader from understand the proposed idea the method is poorly written.,clarity [SEP] negative [SEP]  the the exposition method [SEP]  the exposition severely inhibits reader [SEP]  the understand proposed idea
ICLR_2018_495,461,there is no comparison to a baseline in which the additional learning cycles used for learning the embedding are used for training the student model.,meaningful-comparison [SEP] negative [SEP]  no comparison a baseline [SEP]  the additional learning cycles used [SEP]  the cycles used embedding
ICLR_2020_568,616,"it would be useful as a comparison to duplicate the analysis of unit tuning, connectivity, etc ..",substance [SEP] negative [SEP]  it would be useful [SEP]  duplicate the analysis
ICLR_2020_568,617,there were important details that i couldn't find ..,replicability [SEP] negative [SEP]  important details couldn't find
ICLR_2020_568,618,"it would be even more compelling if, wherever possible, these comparisons were made to be quantitative.",meaningful-comparison [SEP] negative [SEP]  it would be compelling
ICLR_2020_568,619,the layout in fig 2a is a little misleading it looks as if the panels themselves are organized according to angular velocity and head direction.,clarity [SEP] negative [SEP]  the layout fig [SEP]  the looks panels
ICLR_2020_568,620,"it was a pleasure to read, the data was very clear ,.",clarity [SEP] positive [SEP]  it a pleasure [SEP]  a pleasure read [SEP]  read the data
ICLR_2020_568,621,and the results very interesting.,soundness [SEP] positive [SEP]  the results results very interesting
ICLR_2020_2174,726,the whole pipeline is clear and makes sense ..,clarity [SEP] positive [SEP]  the whole pipeline clear [SEP]  makes sense
ICLR_2020_2174,727,some of its main parts are unclearly explained. but a bit confusing for me.,clarity [SEP] negative [SEP]  its main parts are unclearly explained [SEP]  me bit confusing
ICLR_2020_2174,728,"however, in my eyes, it's almost like an extension of vade which combines vib and gmm too. all of those make sense but may not contribute much to the research field. the idea of using a latent mixture of gaussian's to variationally encode high dimensional data is not new. my only concern is novelty ..",originality [SEP] negative [SEP]  make sense
ICLR_2020_2174,729,while the framework and the performance of the proposed method are interesting and promising.,originality [SEP] positive [SEP]  the the framework performance [SEP]  the the framework performance
ICLR_2020_2174,730,"little is discussed how this difference affects the learnt model although this approximation is one of the main parts of the proposed method, little is discussed on the influence of this approximation ..",soundness [SEP] negative [SEP]  the the proposed method influence [SEP]  how difference affects the learnt model [SEP]  the main parts proposed
ICLR_2020_2174,731,"the author (s) derivation was sound ,.",soundness [SEP] positive [SEP]  the author s derivation [SEP]  the author s derivation
ICLR_2020_2174,732,but without knn based accuracies for their model it is hard to compare to cited works.,meaningful-comparison [SEP] negative [SEP]  knn based accuracies their model [SEP]  it their model [SEP]  compare cited works
ICLR_2019_1320,1027,their method is simple and clearly explained. this paper is of reasonable quality and clarity the paper is well written ..,clarity [SEP] positive [SEP]  their method simple [SEP]  clearly explained this paper [SEP]  reasonable quality clarity
ICLR_2019_1320,1028,maths in this paper is mostly decorative. can you elaborate on what is meant here.,clarity [SEP] negative [SEP]  maths this paper [SEP]  can you elaborate [SEP]  can elaborate what
ICLR_2019_1320,1029,the experimental results are interesting ..,substance [SEP] positive [SEP]  the experimental results interesting
ICLR_2019_1320,1030,some more ablation studies and negative results will be insightful and here are few suggestions in that direction.,substance [SEP] negative [SEP]  some more ablation studies negative results [SEP]  here are few suggestions
ICLR_2019_1320,1031,"these results can seem questionable as both the architectures and training routines are being varied and hence the precise contribution of the layerwise training is unclear to round the analysis, it should also be extended to the representations learned by end to end trained networks. all in all, while the paper raises some its execution in terms of a method that learns a classifier on each individual layer is rather simplistic. from reading the paper it is not clear what is the main ingredient that makes this layer wise training successful.",soundness [SEP] negative [SEP]  these results can seem questionable is contribution [SEP]  the architectures are being varied varied hence precise contribution [SEP]  some its execution terms [SEP]  clear what
ICLR_2019_1320,1032,the experiments seem to be conducted correctly ..,soundness [SEP] positive [SEP]  the experiments seem
ICLR_2019_1320,1033,"further, i would like to know how their work compares to the following but at the minute the comparisons are not very convincing i would like to see a wall clock time comparison between this and end to end training ..",meaningful-comparison [SEP] negative [SEP]  a comparison see wall clock time [SEP]  how their work compares [SEP]  the how work compares following [SEP]  further i would like
ICLR_2019_1320,1034,interesting ideas rather modest originality.,originality [SEP] positive [SEP]  interesting ideas rather modest originality
ICLR_2019_1320,1035,but this method is just not that novel.,originality [SEP] negative [SEP]  this method not that novel [SEP]  this method not that novel
ICLR_2019_1320,1036,perhaps considerable significance in some applications ..,motivation [SEP] positive [SEP]  perhaps considerable significance some applications
ICLR_2019_1320,1037,the authors should make their code available to the community to confirm and reproduce their findings.,replicability [SEP] negative [SEP]  the authors should make available [SEP]  their reproduce findings
ICLR_2018_54,1253,"very extensive experiments on a wide variety of tasks cons the experiments in this paper are very exhaustive, covering nearly every major application of deep learning. the experimental evaluation is fairly exhaustive on a large number of deep networks, tasks and datasets and the proposed training preserves the accuracy of all the tested networks at half the memory cost ..",substance [SEP] positive [SEP]  the tested half memory cost [SEP]  experiments a wide variety the [SEP]  experiments this paper exhaustive [SEP]  covering nearly every major application [SEP]  a the large number networks all tested [SEP]  experiments tasks cons are [SEP]  the proposed training preserves accuracy
ICLR_2018_54,1254,"my first concern with the paper is that there are no experiments to demonstrate the necessity of fp32 accumulation. the paper is missing results comparing training and testing speeds in all these models, to illustrate the benefits of using the proposed techniques ..",substance [SEP] negative [SEP]  the using proposed techniques [SEP]  no experiments demonstrate necessity [SEP]  the demonstrate necessity [SEP]  paper is missing results [SEP]  comparing training and testing speeds [SEP]  the illustrate benefits
ICLR_2018_54,1255,experiments do not validate the necessity of fp32 accumulation no comparison of training time speedup from mixed precision with new hardware (such as nvidia s volta architecture) providing large computational speedups for mp computation my second concern is that there is no comparison of training time speedup using mp ..,meaningful-comparison [SEP] negative [SEP]  comparison training time speedup [SEP]  providing large computational speedups concern
ICLR_2018_54,1256,the overall technical contribution is fairly small and are ideas that are regularly implemented when optimizing systems ..,originality [SEP] negative [SEP]  the overall technical contribution fairly small [SEP]  are ideas [SEP]  when optimizing systems
ICLR_2019_356,1730,the idea of using discriminators for separating the labeled samples from unlabeled ones that most likely belong to extra classes is interesting. a new generalization bound for mdl is introduced ..,originality [SEP] positive [SEP]  the idea using discriminators [SEP]  using discriminators
ICLR_2019_356,1731,"the paper was clear, well written, well motivated and nicely structured. very well written, and clear paper cons.",clarity [SEP] positive [SEP]  the paper clear written [SEP]  paper clear nicely structured cons
ICLR_2019_356,1732,"although the paper introduces the generalization bound for mdl, it does not give new formulation or algorithm to handle mdl (mulann handles only the class asymmetry when domains involve distinct sets of classes and it has nothing to do with mdl since each domain may have different number of classes, it is not clear how the number of classes (l) is set in the classification module (maximum number of classes in all domain ).",clarity [SEP] negative [SEP]  the paper introduces generalization not [SEP]  when domains involve distinct sets [SEP]  has nothing [SEP]  domain may have different number [SEP]  it does not not not give formulation [SEP]  the number clear [SEP]  distinct sets classes
ICLR_2019_356,1733,"the authors perform numerous empirical experiments on several types of problems on various datasets (digit, office, cell) successfully showing how the mulann can reduce the nasty effects of the adversarial domain discriminator and repulse (a fraction of) unlabeled examples from labeled ones in each domain. validation of the approach, improving on the state of the art on two standard image benchmarks.",substance [SEP] positive [SEP]  authors perform numerous empirical experiments [SEP]  numerous empirical experiments several types [SEP]  the successfully showing mulann [SEP]  the how can reduce nasty effects [SEP]  the validation approach
ICLR_2019_356,1734,"all the experiments except the last row of table 2 concern adaptation between two domains. given the paper title, the reviewer would have expected more experiments in a multiple domain context. more precisely, for the digit datasets, the reviewer was interested to see how the proposed mdl performs on jointly adapting svhn, mnist, mnist m, and usps or jointly adapting dslr, amazon, and webcam for office dataset. its performance vary with the noisy signals conveyed in those false pseudolabeled samples. and some analysis discussion should be included for the unsupervised one.",substance [SEP] negative [SEP]  the experiments last row more [SEP]  experiments reviewer would have expected more [SEP]  a experiments domain reviewer would have expected more multiple context [SEP]  its performance vary
ICLR_2019_356,1735,"moreover, comparison with some of the da baselines (adda 1, dsn 2) is missing. .the reviewer is also interested to see how the the generalization bound introduced in this paper is related to the recent theoretical works 3 , 4 on mdl. comparison with other methods did not take into account a variety of hyperparameters ..",meaningful-comparison [SEP] negative [SEP]  a not account variety [SEP]  is the related recent theoretical works [SEP]  comparison other methods did not not not take variety
ICLR_2019_356,1736,obviously there must be some false ranking (specially at the initial stages of updating the classifier) for the unlabeled samples (e.g .the classifier may output high entropy for the unlabeled samples of the classes with labeled samples) and they may harm the performance of adaptation. the biggest problem for me was the unconvincing results the results on cell were not convincing.,soundness [SEP] negative [SEP]  obviously must be some false ranking [SEP]  the may harm performance [SEP]  the the biggest problem unconvincing results
ICLR_2019_356,1737,"this paper has a clear logic to explain and prove the problem to be solved, and has ample experimental evidence ..",soundness [SEP] positive [SEP]  problem be solved ample experimental evidence [SEP]  paper a has clear logic [SEP]  prove the problem
ICLR_2019_356,1738,it is not clear how mulann can work in this situation and how.,replicability [SEP] negative [SEP]  it not clear [SEP]  not how can work this situation
ICLR_2019_356,1739,this paper did a meaningful work.,motivation [SEP] positive [SEP]  this paper did work [SEP]  paper a did meaningful work
ICLR_2020_749,1900,this paper raises an interesting point about missing data imputation via generative models this is a nice piece of incremental work on top of previously published gan imputation methods. uncertainty of the.,originality [SEP] positive [SEP]  imputation previously published gan methods uncertainty [SEP]  is paper raises an interesting point [SEP]  a nice piece incremental work [SEP]  incremental work top
ICLR_2020_749,1901,but i do feel it is a bit incremental over the gain approach. the overall gan architecture is very similar to gain's and although stochastic prediction shows clear improvements it is a bit straightforward.,originality [SEP] negative [SEP]  bit incremental the gain approach [SEP]  stochastic prediction shows improvements [SEP]  prediction shows clear improvements
ICLR_2020_749,1902,and well written overall the paper is clearly written ..,clarity [SEP] positive [SEP]  well written overall the paper
ICLR_2020_749,1903,try to switch up the phrasing and move away from repetition. there are several parts that are confusing missing in the paper can you explain the difference between the results in figure 7 and table 2 i think the paper would benefit if the authors could explain show.,clarity [SEP] negative [SEP]  the paper would benefit authors [SEP]  are several parts confusing [SEP]  the can explain difference [SEP]  the the difference results
ICLR_2020_749,1904,this paper could benefit tremendously from both better evaluation and discussion. i suggest the authors to extend this part with more detailed analysis.,substance [SEP] negative [SEP]  this authors extend part [SEP]  this paper could benefit tremendously [SEP]  both better evaluation discussion [SEP]  i suggest [SEP]  suggest the authors
ICLR_2020_749,1905,"if so, can you be more specific when characterizing related work for table 2, please provide accuracy without missing values as a baseline. add mice or some other standard imputation method as a baseline ..",meaningful-comparison [SEP] negative [SEP]  so can you be specific [SEP]  when characterizing related work [SEP]  provide accuracy [SEP]  accuracy missing values
ICLR_2020_749,1906,"i think this is a mistake, likely motivated by the proposed method doing worse under the rmse metric. its effect on smoothing noisy missing pixels is not clear.",soundness [SEP] negative [SEP]  i think is [SEP]  think is a mistake [SEP]  the proposed method doing worse
ICLR_2020_749,1907,imputations and its effect on the final prediction is interesting.,motivation [SEP] positive [SEP]  imputations its effect [SEP]  imputations its effect
ICLR_2020_1744,2083,i found that the authors made the case for rotation equivariance well and i liked the analysis of the dynamic routing approach and its mapping to the generalized weiszfeld iterations. the approach of aggregating pose agreement with quaternion averages makes intuitive sense.,soundness [SEP] positive [SEP]  approach makes intuitive sense [SEP]  the authors made case [SEP]  the liked analysis [SEP]  the the analysis dynamic routing approach [SEP]  approach quaternion averages makes sense
ICLR_2020_1744,2084,would be worthy of more discussion and an empirical presentation of their different merits.,soundness [SEP] negative [SEP]  would be worthy worthy more discussion [SEP]  more discussion an empirical presentation
ICLR_2020_1744,2085,"the preparation of the local patches and the estimation of the rotations seems very important to these applications to me and invariances and equivariances are very important in dnn for classification detection, so extending these properties to 3d point clouds based applications is interesting and important ..",motivation [SEP] positive [SEP]  applications 3d point clouds based is interesting [SEP]  the preparation rotations seems important are [SEP]  seems very important these applications
ICLR_2020_1744,2086,"my biggest concern about the paper is the presentation of the results and its not clear what the illustrations are meant to represent. i think there is a lot of material in the appendix that should really be in the main paper i'm happy for the proofs to be in the appendix but i think it is a bit wrong to essentially violate the page restrictions by moving important related work into the appendix. there also seems to be a mixing of notations for inner products through out the paper and it might be helpful to standardize this unfortunately, i found too many important parts of the method difficult to understand, enumerated below, and it isn't clear what computes the activations alpha ..",clarity [SEP] negative [SEP]  concern the is presentation [SEP]  the paper should really be main [SEP]  m the be happy proofs [SEP]  the essentially violate page restrictions [SEP]  moving important related work [SEP]  concern the paper is presentation [SEP]  important found too many parts difficult [SEP]  the found method difficult understand [SEP]  presentation not not clear what meant
ICLR_2020_1744,2087,the quaternion average step itself is described well.,clarity [SEP] positive [SEP]  the quaternion average step is described well
ICLR_2020_1744,2088,the use of a single dataset makes it hard to identify the efficacy of the approach especially when.,substance [SEP] negative [SEP]  the use single dataset [SEP]  use a single dataset makes hard when [SEP]  the identify efficacy
ICLR_2020_1744,2089,it is not clear how the training and test data are set up. am also not very clear on the details of how they fit together the first is that the details of the architecture are very unclear ..,replicability [SEP] negative [SEP]  the very architecture unclear [SEP]  it not clear [SEP]  how the details fit together first
ICLR_2020_1744,2090,"the proposed approach is novel and seems to be equivariant to so (3) rotations, translations, and set permutations ..",originality [SEP] positive [SEP]  the proposed approach novel [SEP]  set permutations
ICLR_2019_1326,2278,a severe technical problems arises but on the other hand i am not fully convinced it seems that neither these two conclusions are convincing.,soundness [SEP] negative [SEP]  not seems neither these two conclusions [SEP]  problems arises the other hand [SEP]  am not not fully convinced it
ICLR_2019_1326,2279,"i honestly think that on the conceptual side, this work does not make that many really interesting contributions ..",originality [SEP] negative [SEP]  i honestly think [SEP]  that work does not not not make many really interesting contributions
ICLR_2019_1326,2280,about the significance and relevance of the findings.,motivation [SEP] negative [SEP]  the significance relevance
ICLR_2019_1326,2281,the paper carefully constructs a method to estimate the mutual information dimensional variables and address the infinite mutual information issue by adding noise to the output.,motivation [SEP] positive [SEP]  paper a carefully constructs method [SEP]  the estimate mutual information dimensional variables [SEP]  the mutual information address infinite issue
ICLR_2019_1326,2282,the scope of the paper is unclear ..,clarity [SEP] negative [SEP]  the the scope paper
ICLR_2019_1326,2283,"for the layer wise training, the paper only compares the layer wise ib objective with the cross entropy loss ..",meaningful-comparison [SEP] negative [SEP]  the layer wise paper only compares ib objective
ICLR_2018_317,2599,i think overall it is a good idea. i think the idea of the paper is interesting and i'm willing to increase the method is simple but novel ..,originality [SEP] positive [SEP]  the increase method [SEP]  idea the the paper [SEP]  the paper interesting [SEP]  i think is
ICLR_2018_317,2600,"but i find the paper lacking a lot of details and to some extend confusing. but i want to make sure the authors put a bit more effort into cleaning up the paper, making it more clear and easy to read. figure 2 the plots are too small. the method is clear but not precisely described. i find figure 1 (c) somewhat confusing ..",clarity [SEP] negative [SEP]  read figure [SEP]  paper a lacking lot [SEP]  a authors put bit more effort [SEP]  find the paper [SEP]  it making clear [SEP]  the too small method
ICLR_2018_317,2601,also more baselines are needed. providing at least one more baseline (if not more considering the other things cited by them). no comparisons with prior work are provided. the paper cites many previous approaches to this but does not compare against any of them ..,meaningful-comparison [SEP] negative [SEP]  cited them [SEP]  considering the other things [SEP]  no comparisons prior work [SEP]  the paper cites approaches [SEP]  paper cites many previous approaches
ICLR_2018_317,2602,the results support the method's utility. the results are promising. i think that this is a good approach to the problem that could be used in real world scenarios ..,soundness [SEP] positive [SEP]  could be used real world scenarios [SEP]  the results support utility [SEP]  i is think [SEP]  the a good approach problem
ICLR_2018_317,2603,and it is not clear whether the method is applicable beyond this well understood case.,soundness [SEP] negative [SEP]  it not clear [SEP]  clear the method [SEP]  applicable this well understood case
ICLR_2018_317,2604,the method lacks details how were the network architecture and network size chosen.,replicability [SEP] negative [SEP]  network architecture size chosen [SEP]  method lacks details [SEP]  the how were network architecture
ICLR_2020_187,2620,overall opinion while i believe the general idea indeed has merit and empirically shows great promise using the structural similarity makes a lot of sense.,soundness [SEP] positive [SEP]  a opinion makes lot [SEP]  overall opinion believe [SEP]  i believe [SEP]  believe the general idea [SEP]  idea indeed has merit [SEP]  empirically shows great promise [SEP]  the using structural similarity
ICLR_2020_187,2621,i believe the paper in its current state is not ready for publication ..,clarity [SEP] negative [SEP]  i believe is [SEP]  believe the paper is not [SEP]  ready publication
ICLR_2020_187,2622,"the paper is easy to read. while the language is clear and easy to follow well explained, and overall the paper is well written ..",clarity [SEP] positive [SEP]  the paper easy read [SEP]  the read language clear [SEP]  the paper well explained overall
ICLR_2020_187,2623,3 .really good empirical results on the 3 datasets that were presented ..,substance [SEP] positive [SEP]  3 3 really good empirical results the datasets
ICLR_2020_187,2624,i believe the paper is not well motivated from an applications perspective. but very heuristical ..,motivation [SEP] negative [SEP]  i believe is [SEP]  believe the paper is not [SEP]  not well motivated an applications perspective
ICLR_2020_187,2625,the approach is well motivated.,motivation [SEP] positive [SEP]  the approach well motivated
ICLR_2020_187,2626,"i believe the experimental section is missing an important amount of details for reproducibility purposes and also for explaining how certain parameters have been chosen there are no details on the model size and training procedure (hidden units, optimizer, learning rate schedule)..",replicability [SEP] negative [SEP]  learning rate schedule [SEP]  believe the experimental section are [SEP]  section is missing an important amount [SEP]  an important amount details [SEP]  explaining certain parameters [SEP]  the model size training procedure
ICLR_2020_187,2627,i found the idea to be elegant and this seems to be a solid contribution (even if the i recommend acceptance.,originality [SEP] positive [SEP]  even recommend acceptance [SEP]  found the idea [SEP]  a seems solid contribution
ICLR_2020_1183,2730,"overall, my primary concern with the paper is a lack of context in the larger field of model based optimization. the motivation is not well justified by the experiments.",motivation [SEP] negative [SEP]  my primary concern the paper [SEP]  a the paper lack [SEP]  the context larger field
ICLR_2020_1183,2731,"much of the discussion contrasting arbitrary action spaces with handcrafted ones are somewhat lost in the actual experimental setup, i believe the framing of the paper needs substantial imrpovement ..",clarity [SEP] negative [SEP]  much the are somewhat lost actual experimental setup [SEP]  the framing paper needs imrpovement
ICLR_2020_1183,2732,in general the paper is well written and easy to follow ..,clarity [SEP] positive [SEP]  general the paper
ICLR_2020_1183,2733,"additionally in the same context, a significant amount of related work is missing. the comparison on nasbench 101 is not convincing lack of the main comparison. the comparison of nasbench 101 is not convincing ..",meaningful-comparison [SEP] negative [SEP]  the same context significant amount
ICLR_2020_1183,2734,"the use of tree models for model based optimization have been considered before (e.g. , smac), although the mcts acquisition with a single tree surrogate is novel as far as i am aware. as far as i know, the mcts approach for the nas problem is not a standard solution for nas (which is not proved to be practically useful in other people which diminishes the contribution of the improvements of mcts in nas.",originality [SEP] negative [SEP]  the mcts approach nas problem not [SEP]  the a nas problem not standard solution [SEP]  the the contribution improvements
ICLR_2020_1183,2735,the experimental performance of the authors' method seems quite good on the tasks considered.,soundness [SEP] positive [SEP]  the the experimental performance authors method [SEP]  the performance authors method seems good [SEP]  the tasks considered
ICLR_2020_1183,2736,"some important explanation of the method is missing. some important explanation of the methods is missing. however, i am not entirely convinced by the empirical results ..",soundness [SEP] negative [SEP]  the however am not not not entirely convinced empirical results [SEP]  some important explanation the methods [SEP]  explanation the is missing methods [SEP]  i however am not not not not entirely convinced
ICLR_2020_1183,2737,"to show the effectiveness of mcts, it is recommended to experiment on different values of c..",substance [SEP] negative [SEP]  show the effectiveness [SEP]  experiment different values
ICLR_2020_1293,3424,the title on mild over parameterized network is a bit misleading. i feel it would be worth trying to provide a rough proof sketch in the main paper to highlight the difficulty of the analysis ..,clarity [SEP] negative [SEP]  the highlight difficulty [SEP]  it feel [SEP]  a provide rough proof sketch
ICLR_2020_1293,3425,"however, this comparison seems to be a bit unfair, i have some doubts regarding the comparison to prior work.",meaningful-comparison [SEP] negative [SEP]  comparison regarding prior work [SEP]  however this comparison seems [SEP]  comparison regarding the
ICLR_2020_1293,3426,the result on 3 layer projection with smoothed analysis is theoretically interesting.,substance [SEP] positive [SEP]  the result 3 layer projection
ICLR_2020_1293,3427,"however, the 3 layer result is mainly for technical purpose (restore representation power), and does not provide much extra insight on algorithm performance i think this discussion is largely missing in the paper but another way to prove the same result would be to focus on showing that the loss surface is.",soundness [SEP] negative [SEP]  the 3 layer result technical purpose [SEP]  technical purpose restore power [SEP]  restore representation power [SEP]  does not not provide much extra insight [SEP]  i not think [SEP]  not think this discussion [SEP]  the is discussion largely missing paper [SEP]  the result prove same
ICLR_2020_1293,3428,i agree that the smoothed analysis makes more sense than my original understanding ..,soundness [SEP] positive [SEP]  i agree [SEP]  the smoothed analysis makes sense [SEP]  analysis makes more sense
ICLR_2020_1293,3429,"in general, i think this is an interesting direction ..",motivation [SEP] positive [SEP]  i think is [SEP]  think is an interesting direction
ICLR_2020_1293,3430,as well as some technical details that need some clarification.,replicability [SEP] negative [SEP]  as as well some technical details need clarification [SEP]  some need clarification
ICLR_2019_121,3571,the proposed approach seems interesting. i found the idea of traversing a parse tree of a formula top down and converting it to a vector very interesting ..,originality [SEP] positive [SEP]  the proposed approach seems interesting [SEP]  the found idea
ICLR_2019_121,3572,"it seems to outperform the state of the art, but the authors do not give any explanations why. there is no theoretical or intuitive explanation of why the model works. i am hesitant to be a strong supporter for this paper. i feel that the cons and pros of the model and its design decisions are not fully analyzed or explained in the paper.",soundness [SEP] negative [SEP]  it seems [SEP]  authors do not not not not give any explanations why [SEP]  or the no explanation theoretical intuitive model [SEP]  not not not cons its design decisions are fully analyzed
ICLR_2019_121,3573,"however, i think that the approach is compelling and 6 .the results are impressively strong ..",soundness [SEP] positive [SEP]  however i think is [SEP]  the 6 results are strong
ICLR_2019_121,3574,the model should be better explained ..,replicability [SEP] negative [SEP]  the model should be better explained
ICLR_2019_121,3575,"cons 1 .there is no study of the representations developed by the model, which is unfortunate because this is a conference on learning representations and because there is little light shed on how the network achieves its rather high level of performance.",substance [SEP] negative [SEP]  how network achieves its rather high level [SEP]  cons is no study [SEP]  the developed model [SEP]  representations a conference learning [SEP]  representations developed
ICLR_2019_121,3576,pros 3 .the paper is quite clear ..,clarity [SEP] positive [SEP]  pros 3 the paper [SEP]  pros 3 the paper
ICLR_2019_121,3577,4 .the problem is important ..,motivation [SEP] positive [SEP]  problem important
ICLR_2020_1966,3725,the paper is well written and the contributions are stated clearly. overall the paper is well written and easy to follow ..,clarity [SEP] positive [SEP]  the paper well written [SEP]  the well written contributions [SEP]  the paper well written
ICLR_2020_1966,3726,the exploration on the layer division is really insightful. although the insight is interesting.,originality [SEP] positive [SEP]  the the exploration layer division [SEP]  the insight interesting
ICLR_2020_1966,3727,"3 .the proposed mdm method seems to be incremental. although this bound involves new insight, the novelty is limited if it is looser than existing upper bound. the novelty of this paper is not enough for being accepted by iclr. my major concern is that the paper, including the motivation and illustrative example, are too similar to previous work.",originality [SEP] negative [SEP]  too similar previous work [SEP]  the proposed mdm method seems [SEP]  involves new insight [SEP]  this paper enough [SEP]  the paper including motivation [SEP]  the including motivation
ICLR_2020_1966,3728,"the proposed upper bound is insightful, but it has several limitations. however, they do not validate this regularization effect. there is no proof that this new bound is better than classic domain adaptation theory there is no analysis about the generalization when estimating this upper bound from finite samples ..",soundness [SEP] negative [SEP]  has several limitations [SEP]  however they do not not not not validate effect [SEP]  however do not not not validate this regularization effect [SEP]  bound no proof new
ICLR_2020_1966,3729,"theoretical analysis or experimental results would be helpful. the empirical evaluation is relatively weak. there is no experiment based on convolutional networks, which are widely used on the digit and office 31 datasets ..",substance [SEP] negative [SEP]  theoretical analysis experimental results [SEP]  the analysis would be helpful helpful empirical evaluation [SEP]  experiment no based
ICLR_2020_1966,3730,the experiments on using different number of layers of the network as feature extractors are quite interesting.,substance [SEP] positive [SEP]  the experiments using number [SEP]  using different number [SEP]  different number layers
ICLR_2020_1966,3731,this paper proposes an interesting insight that the complexity of embeddings is also important in domain adaptation.,motivation [SEP] positive [SEP]  is important domain adaptation [SEP]  paper proposes an interesting insight [SEP]  an interesting insight the complexity
ICLR_2020_1966,3732,1 2. more detailed discussions are needed to highlight the difference of this work compared with 1 2 ..,meaningful-comparison [SEP] negative [SEP]  more detailed discussions are needed [SEP]  highlight the difference [SEP]  this work compared
ICLR_2020_1454,3739,"this is an interesting direction for dealing with label noise. the motivation is rational with a good theoretical guarantee, i.e .theorem 1. moreover, the tackled problem, i.e .avoiding specifying the noise rates, is significant to the community ..",motivation [SEP] positive [SEP]  the significant community [SEP]  an interesting direction dealing [SEP]  a rational good theoretical guarantee [SEP]  i e the tackled problem avoiding [SEP]  noise the avoiding specifying rates
ICLR_2020_1454,3740,"the paper is not well presented. i tried several times to go through the details but failed. lots of details can be put on the appendix nevertheless, some parts of this paper may be confusing the authors should clarity the connection to and the difference from the loss correction approach ..",clarity [SEP] negative [SEP]  the authors should clarity connection difference [SEP]  the paper is not well presented [SEP]  the be confusing authors
ICLR_2020_1454,3741,this paper is well written ..,clarity [SEP] positive [SEP]  this is paper well written
ICLR_2020_1454,3742,provide strong theoretical guarantees of the proposed erm framework ..,soundness [SEP] positive [SEP]  provide strong theoretical guarantees
ICLR_2020_1454,3743,the motivating claim existing approaches require practitioners to specify noise rates is wrong ... similar to many theory.,soundness [SEP] negative [SEP]  is similar many theory [SEP]  motivating claim existing approaches [SEP]  approaches require practitioners
ICLR_2020_1454,3744,the computation of the scoring matrix delta is not that clear.,replicability [SEP] negative [SEP]  the the computation scoring matrix delta not
ICLR_2020_1454,3745,"the paper introduced peer prediction, an area in computational economics and algorithmic game theory, to learning with noisy labels. this should be novel (to the best of my knowledge) and i like it.",originality [SEP] positive [SEP]  it like [SEP]  best my knowledge
ICLR_2020_1454,3746,the obtained loss is very similar to the general loss correction approach this fact undermines the novelty of the paper.,originality [SEP] negative [SEP]  the obtained loss very similar [SEP]  the fact undermines novelty
ICLR_2020_1454,3747,"papers, the experiments are too simple, where single hidden layer neural networks were trained on 10 uci benchmark datasets ..",substance [SEP] negative [SEP]  where networks were trained 10 uci benchmark datasets [SEP]  papers the experiments [SEP]  where single hidden layer neural networks were trained
ICLR_2020_522,4792,this work is interesting as it seems to provide a simple way to obtain reasonable uncertainty estimates. for this reason it can potentially serve as a strong baseline for this field. obtaining uncertainty estimates for predictions of deep neural networks is an important and open research question ..,motivation [SEP] positive [SEP]  an deep neural networks important and open research question [SEP]  this work interesting [SEP]  a provide simple way [SEP]  it seems [SEP]  a can potentially serve strong baseline [SEP]  obtain reasonable uncertainty estimates [SEP]  predictions deep networks
ICLR_2020_522,4793,the theoretical considerations also help in providing some guarantees about such an approach ..,soundness [SEP] positive [SEP]  the theoretical considerations also help [SEP]  providing some guarantees
ICLR_2020_522,4794,make the results more convincing i believe these points should be discussed in more detail. although the paper does not seem to discuss its significance and implications enough ..,soundness [SEP] negative [SEP]  believe these points [SEP]  more be points should discussed detail [SEP]  discuss not its significance enough
ICLR_2020_522,4795,"in my opinion the writing could use some more work in order to make things more clear i also believe that some clarifications on the theoretical aspects of this work, will help in boosting its quality. overall, the paper is relatively well written, although it might be at times hard to follow, especially for someone who is not familiar with the original work that used randomized prior functions the paper was difficult to read and unclear in explanations. the current presentation is a bit misleading here, as the presented method seems to have moved the most mass under this chart scaling ..",clarity [SEP] negative [SEP]  writing could use some more work [SEP]  make things clear [SEP]  i clear also believe [SEP]  the some clarifications theoretical aspects [SEP]  be might times hard hard [SEP]  used randomized prior functions [SEP]  read unclear explanations [SEP]  the presented method seems
ICLR_2020_522,4796,as some critical experimental details and baselines are missing and thus do not make the method as convincing ..,replicability [SEP] negative [SEP]  thus do not not not make the method
ICLR_2020_522,4797,"i believe that a comparison against a simple variationally trained bnn would the experimental evaluation is very limited, training only on cifar 10 ..",substance [SEP] negative [SEP]  i believe is [SEP]  believe a comparison is [SEP]  a simple variationally trained bnn the experimental evaluation
ICLR_2020_522,4798,i find the core idea behind the paper quite interesting.,originality [SEP] positive [SEP]  i find idea interesting [SEP]  find the core idea interesting
ICLR_2018_590,5031,this is a nice idea i like the idea and the proposed applications. some of the suggested insights in the analysis of defense techniques are interesting.,originality [SEP] positive [SEP]  the the suggested insights analysis [SEP]  idea like the [SEP]  idea like the proposed applications
ICLR_2018_590,5032,"the experiments are quite small scale the long runtime does not permit to analyse large amounts of input samples, which it is also unclear whether it is possible to include distance metrics that capture more sophisticated attacks that fool network even under various transformations of the input ..",substance [SEP] negative [SEP]  network various transformations [SEP]  the experiments quite small scale [SEP]  not analyse large amounts
ICLR_2018_590,5033,"it is certainly highly relevant, both in terms of assessing models for critical use cases as well as a tool to better understand the phenomenon ..",motivation [SEP] positive [SEP]  better understand the phenomenon [SEP]  it highly relevant [SEP]  assessing models
ICLR_2018_590,5034,the practical application of the method is very limited since the search is very slow and is only feasible at all for relatively small models.,motivation [SEP] negative [SEP]  is only feasible all relatively small models [SEP]  the the practical application method [SEP]  the application method is limited [SEP]  the very limited search
ICLR_2018_590,5035,makes the analysis in terms of the increase in robustness rather weak i don t fully agree with the conclusion that the defense of madry does not overfit to the specific method of creating adversarial examples.,soundness [SEP] negative [SEP]  creating adversarial examples [SEP]  makes the analysis weak [SEP]  the analysis terms [SEP]  the terms increase [SEP]  the fully agree conclusion [SEP]  the the conclusion defense not [SEP]  the defense does not not overfit specific method
ICLR_2018_590,5036,the paper does not consider the more recent and highly relevant moosavi dezfooli et al.,meaningful-comparison [SEP] negative [SEP]  the paper does not not consider [SEP]  the paper does not not not consider more recent and highly relevant moosavi dezfooli
ICLR_2018_590,5037,the term ground truth example seems very misleading to me.,clarity [SEP] negative [SEP]  the term ground truth example seems misleading [SEP]  seems very misleading me
ICLR_2020_233,5322,the comparison with baselines in section 4.2 seems to be unclear. some notations are very confusing. 2 .there are many typos in the paper ..,clarity [SEP] negative [SEP]  2 there many typos [SEP]  the comparison baselines [SEP]  2 very confusing there
ICLR_2020_233,5323,the paper is easy to follow ..,clarity [SEP] positive [SEP]  the paper easy follow
ICLR_2020_233,5324,it would also be beneficial to see the comparison with the original ghost batch normalization in the final evaluation (section 4.2.,meaningful-comparison [SEP] negative [SEP]  it would also be beneficial [SEP]  see the comparison [SEP]  the the comparison original ghost batch normalization
ICLR_2020_233,5325,"the empirical evaluation of this effect is needed to justify this intuition. the paper mentions theory multiple times, but lacks sufficient justification to support these theories ..",soundness [SEP] negative [SEP]  support these theories [SEP]  the empirical evaluation this effect [SEP]  this justify intuition [SEP]  the paper mentions theory times [SEP]  lacks sufficient justification
ICLR_2020_233,5326,experimental evidence seems sufficient and there are some theoretical derivations.,soundness [SEP] positive [SEP]  experimental evidence seems sufficient [SEP]  are some theoretical derivations
ICLR_2020_233,5327,"overall, the newly proposed method is a minor update, and novelty is limited. the novelty of this paper seems very limited 2 .the proposed inference example weighing method seems very similar to batch renormalization. but it looks incremental that the paper presents some techniques in improving batch normalization only ..",originality [SEP] negative [SEP]  the newly proposed method minor update [SEP]  a the proposed method minor update limited very 2 inference example weighing [SEP]  novelty this paper seems [SEP]  the proposed method novelty limited seems very 2 inference example weighing [SEP]  it looks incremental [SEP]  paper presents some techniques
ICLR_2020_233,5328,"however, the thorough empirical study of existing improvement techniques would be a good addition to the conference ..",substance [SEP] positive [SEP]  the thorough empirical study existing [SEP]  however a study would be good addition
ICLR_2020_233,5329,"and more experiments are required however, all the experiments in section 4 are performed on three small datasets. it is necessary and important to provide imagenet results to show the effectiveness of the other three techniques in section 4 ..",substance [SEP] negative [SEP]  experiments are section performed [SEP]  more experiments are required however [SEP]  experiments all the section [SEP]  experiments are performed three small datasets [SEP]  provide imagenet results [SEP]  the show effectiveness
ICLR_2020_233,5330,"in general, the paper is of values to the community ..",motivation [SEP] positive [SEP]  general the paper
ICLR_2020_1685,5590,the problems are significant.,motivation [SEP] positive [SEP]  the problems significant
ICLR_2020_1685,5591,"thus, the impact of this contribution is not clear.",motivation [SEP] negative [SEP]  the impact this contribution not
ICLR_2020_1685,5592,"but the approach rather superficial i think that the paper in its present state have low novelty ,.",originality [SEP] negative [SEP]  the approach approach rather superficial [SEP]  the approach think paper [SEP]  paper its present state have novelty
ICLR_2020_1685,5593,"moreover, the paper presentation needs improvement bad quality of illustrations and images be coherent with the position of captions also not clear what outcome masking refers to.",clarity [SEP] negative [SEP]  not outcome masking refers [SEP]  moreover presentation needs improvement bad quality not clear [SEP]  images be coherent
ICLR_2020_1685,5594,although the paper explain clearly the intuition and the motivation of the proposed technique.,clarity [SEP] positive [SEP]  the paper explain clearly intuition [SEP]  the paper explain clearly intuition [SEP]  the the intuition motivation
ICLR_2020_1685,5595,the authors should highlight better their main contribution novelty of the proposed method compared to their baseline the results reported in tables 1 and 2 are not convincing when compared to existing approaches there is no qualitative comparison to other algorithms for two of the problems considered and the comparison with other algorithms for unconditional image generation is limited to cifar 10.,meaningful-comparison [SEP] negative [SEP]  the authors should highlight better novelty is [SEP]  authors should highlight better their main contribution novelty is [SEP]  the proposed method compared [SEP]  the problems considered
ICLR_2020_1685,5596,the correctness of the proposed approach is not proved.,soundness [SEP] negative [SEP]  the correctness proposed not
ICLR_2020_1685,5597,by the conducted experiment in fact.,substance [SEP] negative [SEP]  the conducted experiment fact
ICLR_2020_1685,5598,the experiments do not provide the details of the used architecture compared to your baseline there are so many missing details specially to validate image to image translation figure 3 is confusing and not clear.,replicability [SEP] negative [SEP]  the experiments do not not not provide details [SEP]  the not used architecture compared [SEP]  details are so many missing specially
ICLR_2018_432,5735,"mnist, cifar 10 are too simple tasks perhaps suitable for debugging but not for a comprehensive validation of quantization compression techniques. also, it would be good to have an ablation test on different parts of the objective function and the two optimization stages to show the importance of each part would be helpful to show if the proposed technique work well on sequential models like lstms ..",substance [SEP] negative [SEP]  mnist too simple tasks [SEP]  too simple tasks tasks perhaps suitable [SEP]  tasks perhaps suitable debugging [SEP]  a not comprehensive validation quantization compression techniques [SEP]  it also would be good [SEP]  an ablation test different parts [SEP]  the show importance
ICLR_2018_432,5736,any comparison to a classic compression technique would be beneficial. it is much less convincing with no comparison result of compression on large neural networks and large datasets. the only compression result on large neural network (vgg 11) comes with no baseline comparisons. there are many references and comparisons missing soft to hard vector quantization for end to end learning compressible representations in nips 17 for instance.,meaningful-comparison [SEP] negative [SEP]  any comparison classic technique [SEP]  comparison would be beneficial beneficial it [SEP]  comparison less convincing no result [SEP]  no result comes baseline comparisons [SEP]  many references missing soft
ICLR_2018_432,5737,weight sharing and pruning are not new to neural network compression ..,originality [SEP] negative [SEP]  weight sharing pruning not [SEP]  new neural network compression
ICLR_2018_432,5738,the idea is sort of interesting.,originality [SEP] positive [SEP]  the idea of interesting
ICLR_2018_432,5739,but there is no quantitative results shown to support the claims ..,soundness [SEP] negative [SEP]  no quantitative results shown [SEP]  the support claims
ICLR_2018_432,5740,and the reported experimental results appear to be supportive ..,soundness [SEP] positive [SEP]  the reported experimental results appear
ICLR_2018_432,5741,1 .the roles played by k means and l1 regularization are a little confusing from the paper ..,clarity [SEP] negative [SEP]  the confusing paper [SEP]  played k means [SEP]  l1 regularization little
ICLR_2020_775,5841,"pruning methods are important for real time applications of cnns on low resourced devices, so the paper addresses a genuine need ..",motivation [SEP] positive [SEP]  pruning methods important [SEP]  are the paper addresses need [SEP]  a are paper addresses genuine need
ICLR_2020_775,5842,"the paper is poorly written majority of the description of the models and architecture is written in text and is very difficult to parse, while this could've been avoided by usage of mathematical notations for operations. one thing that is not clear in the text is the computation taken by the runtime pruner architecture. some of the algorithmic details could benefit from some clarification. sections 3.3 up to section 5 need lots of rewriting section 4.1 is extremely difficult to read and so i don't really understand how you train the pruning policies. please improve the writing and summarize the process in pseudocode or illustrate it ..",clarity [SEP] negative [SEP]  paper is poorly written majority [SEP]  the poorly written majority description [SEP]  usage mathematical notations [SEP]  the is text not not clear [SEP]  the could algorithmic details benefit [SEP]  is sections need lots [SEP]  i read n't [SEP]  the writing improve
ICLR_2020_775,5843,and the experimental results are not as convincing. it's not clear why the baseline performances in the experimental section are different across different methods ..,soundness [SEP] negative [SEP]  different different methods [SEP]  the experimental results not not as convincing [SEP]  not not as convincing it [SEP]  the clear baseline performances
ICLR_2020_775,5844,the drl approach is reasonable and it seems to do well in practice ..,soundness [SEP] positive [SEP]  the drl approach reasonable [SEP]  it seems [SEP]  do well practice
ICLR_2020_775,5845,the empirical results demonstrate the capability of the framework but would benefit from some clarification and additional ablations it could be clearer if the ablation of r r also demonstrated a storage accuracy tradeoff ..,substance [SEP] negative [SEP]  the empirical results demonstrate capability [SEP]  the results demonstrate capability [SEP]  a ablation also demonstrated storage accuracy tradeoff
ICLR_2020_775,5846,proposed an rl formulation of a unified framework for static and dynamic channel pruning. i do like the idea of combining static and dynamic pruning.,originality [SEP] positive [SEP]  static and dynamic pruning combining [SEP]  proposed an rl formulation [SEP]  do the idea
ICLR_2020_775,5847,it is unclear how speed up calculated ..,replicability [SEP] negative [SEP]  it unclear
ICLR_2020_2032,5859,i think this is a reasonable direction as it shows the necessity of using multi level attention.,motivation [SEP] positive [SEP]  using multi level attention [SEP]  i think is [SEP]  think is a reasonable direction [SEP]  shows the necessity
ICLR_2020_2032,5860,the performance is impressive and could be a better baseline for the future work. the experimental evaluation is convincing ..,soundness [SEP] positive [SEP]  the performance impressive [SEP]  a could be better baseline
ICLR_2020_2032,5861,"i suggest the author to provide more ablation analysis to the experiment section. another problem is that there is only few qualitative results, i will recommend to standardize the evaluations it will be good to also analyze failure cases 3 .for evaluation part, one important ablation study is missing.",substance [SEP] negative [SEP]  evaluation also analyze failure cases 3 for part [SEP]  author provide more ablation analysis [SEP]  is only few qualitative results will recommend [SEP]  i suggest
ICLR_2020_2032,5862,very good performance on both dataset ablation study of the moving parts interesting use of positional embeddings for multi modal learning weaknesses.,substance [SEP] positive [SEP]  very good performance dataset ablation [SEP]  very good performance both dataset ablation study
ICLR_2020_2032,5863,"the main contribution of the paper is incremental (specially respect to mithun et al. , 2019), i do not see a ground breaking contribution. one of the main novelties with respect to previous text to clip models is the use of co attention schemes at the level of words and frames. however, the idea of co attention at different grain levels have been proposed before the overall novelty of the proposed methods is limited. so in this way, the novelty is only marginal ..",originality [SEP] negative [SEP]  the the main contribution paper [SEP]  the contribution paper is respect not [SEP]  a contribution is do not not see ground breaking [SEP]  the main novelties previous text [SEP]  contribution is incremental respect not [SEP]  co attention schemes [SEP]  the attention schemes level [SEP]  the frames idea [SEP]  however idea different grain levels have been proposed [SEP]  the however idea have been proposed overall novelty
ICLR_2020_2032,5864,"it is not clear to me what is the role of the word to video representation in eqs. 2 .paper writing can be improved. however, the caption doesn't explain all the notations in the figure, such as wcvg, and the equations. the reference is very far away from figure 2, which makes the whole paper hard to read ..",clarity [SEP] negative [SEP]  the the role word [SEP]  the word video representation [SEP]  the caption doesn't n't n't explain notations [SEP]  the doesn't n't explain all notations
ICLR_2020_2032,5865,"5 and 6 .in general, the paper is well written ..",clarity [SEP] positive [SEP]  general the paper is well written
ICLR_2020_2032,5866,it is not clear why authors change the structure of the evaluation among the experiments ..,replicability [SEP] negative [SEP]  the the structure evaluation [SEP]  it not clear [SEP]  not why authors change the structure
ICLR_2019_20,5906,"the paper is very readable, so i think i understand its overall gist. overall, i found the paper to be very well written and easy to digest, and.",clarity [SEP] positive [SEP]  the paper very readable [SEP]  understand its overall gist [SEP]  i think
ICLR_2019_20,5907,i found the approach to be novel and novel approach to achieve these important goals by allowing a trusted.,originality [SEP] positive [SEP]  achieve these important goals [SEP]  found the approach [SEP]  approach be novel novel and
ICLR_2019_20,5908,the results convincing simple yet effective approach to achieve the goals laid out in the problem statement thorough experiments and benchmarks strong results cons overall this is a strong paper which presents good ideas that have influence in ml and beyond. the basic idea to be simple the authors strike a nice balance between details left to the appendix and the high level overview explained in the paper ..,soundness [SEP] positive [SEP]  the results convincing approach [SEP]  convincing simple yet effective approach [SEP]  results benchmarks strong [SEP]  a strong paper presents ideas [SEP]  presents good ideas [SEP]  the simple be idea basic [SEP]  a idea authors strike nice balance [SEP]  the high level overview explained
ICLR_2019_20,5909,"to me, the biggest missing piece is a discussion of the limitations of the approach. it's also not clear why integrity checks are required ..",soundness [SEP] negative [SEP]  the a discussion limitations [SEP]  me biggest missing [SEP]  the biggest missing piece a discussion
ICLR_2019_20,5910,"it would be interesting to see throughput results on these networks ,.",substance [SEP] negative [SEP]  it would be interesting [SEP]  see throughput results
ICLR_2019_1180,6219,"there is only a very few number of experiments per analysis, making it virtually impossible to infer reliably any trends in the data ..",substance [SEP] negative [SEP]  infer reliably any trends [SEP]  only a very few number experiments [SEP]  making it impossible
ICLR_2019_1180,6220,the authors appear to get great results in table 1.,substance [SEP] positive [SEP]  the authors appear [SEP]  get great results
ICLR_2019_1180,6221,"clarity the paper is difficult to follow. introduction gives too much details and even contains methodological all of which obfuscates the main message which does get more clear in the latter sections the sections 2 and 3 are confusing because they do not follow the logic presented in the abstract but the paper is poorly written and organized which makes its through evaluation difficult. i found the description n lr later but the naming is rather confusing i understand this is a hyper parameter for your framework but i am confused how it is being set for n lr method. with respect to the writing, i m a bit uncertain as to the primary message of the paper ..",clarity [SEP] negative [SEP]  clarity the paper [SEP]  introduction gives too much details [SEP]  the get more clear latter sections [SEP]  the logic not presented [SEP]  the presented abstract [SEP]  difficult makes evaluation [SEP]  the respect writing [SEP]  i found description later
ICLR_2019_1180,6222,originality using low rank representation is not something new and has already been explored in 1 i cannot really gauge the significance of the result against other existing approaches towards low dimensional representations because of my limited familiarity with the relevant literature.,originality [SEP] negative [SEP]  the result other existing approaches [SEP]  originality using representation not [SEP]  using low rank representation [SEP]  not something new [SEP]  is not not not can really gauge the significance
ICLR_2019_1180,6223,"the idea introduced in this paper is interesting overall, this paper was fairly well written and seems to have an original approach towards inducing low rank structure on the space of activations in some intermediate layer in a computationally efficient way without changing the underlying model ..",originality [SEP] positive [SEP]  the changing underlying model [SEP]  the idea introduced [SEP]  an have original approach [SEP]  the low rank structure space
ICLR_2019_1180,6224,i don't understand motivation for l n (a)..,motivation [SEP] negative [SEP]  i don't n't n't understand motivation [SEP]  don't n't understand motivation
ICLR_2019_1180,6225,i thought the augmented optimization problem used to induce low rank structure on the space of activations was interesting and worthy of investigation. i didn t fully understand the extent to which the results are intriguing or helpful in understanding neural networks.,motivation [SEP] positive [SEP]  thought the augmented optimization problem was [SEP]  the low rank structure space [SEP]  worthy investigation [SEP]  i thought was [SEP]  the fully understand extent [SEP]  the extent results results intriguing
ICLR_2019_1180,6226,this is not correct. the results in table 1.b shows that their framework is not doing good for transfer learning i didn t feel quite convinced by the discussion in the paper that low rank activations were superior to other kinds of low rank approximations i think the discussion on this topic could be a bit improved ..,soundness [SEP] negative [SEP]  this discussion topic could be improved [SEP]  not results shows their framework [SEP]  is not not not framework doing good [SEP]  t didn feel convinced [SEP]  superior other kinds [SEP]  the feel quite convinced discussion
ICLR_2019_1180,6227,i am not sure if the heuristic procedure introduced in page 4 is well justifed ..,replicability [SEP] negative [SEP]  i not sure [SEP]  the heuristic procedure introduced [SEP]  introduced page
ICLR_2020_891,6523,this paper is an interesting approach to provide a reinforcement learning paradigm for training deep networks.,motivation [SEP] positive [SEP]  this paper interesting approach [SEP]  a provide reinforcement learning paradigm [SEP]  training deep networks
ICLR_2020_891,6524,", it is well written the paper is fairly clear.",clarity [SEP] positive [SEP]  it is is well written [SEP]  is is well written the paper
ICLR_2020_891,6525,"but the explanation of the algorithm could be further streamlined and condensed. although it is possible to understand the algorithm based on the provided textual description, it would not hurt to provide a more formal presentation of the main update equation (1). overall, i think the paper is not ready for publication at iclr.",clarity [SEP] negative [SEP]  the based provided textual description [SEP]  a provide not more formal presentation [SEP]  the is not overall think paper
ICLR_2020_891,6526,and the experiments are convincing.,soundness [SEP] positive [SEP]  the experiments are convincing
ICLR_2020_891,6527,"although more explanation about why these specific architectures were tested would be more convincing. these intuitive judgements can be misleading 1 .authors do not clearly pose what are the properties of back propagation that they find biologically non plausible and how exactly their algorithm is making progress on them. 3 .the experiments are not convincing to me, as the considered network architectures are quite shallow and thus the ability to perform credit assignment cannot be demonstrated. the locally connected architecture has only the first layer locally connected and it does not make much sense to me, as it does not factor out the impact of weight sharing ..",soundness [SEP] negative [SEP]  it not not not does make sense [SEP]  although more explanation specific architectures [SEP]  these convincing intuitive judgements misleading [SEP]  authors do not not not clearly pose what are [SEP]  they find plausible [SEP]  is algorithm making progress [SEP]  the architectures not are considered network quite shallow [SEP]  me considered
ICLR_2020_891,6528,i also think the assumptions about feedback connections in real neurons should be visited and more neuroscientific evidence from the literature should be included in the paper the paper could be strengthened by studying the speed of learning as a function of the number of output classes and the need to conduct larger experiments in future work.,substance [SEP] negative [SEP]  conduct larger experiments [SEP]  i also think need [SEP]  also think the assumptions need [SEP]  assumptions should be visited more neuroscientific evidence [SEP]  the should be evidence included paper [SEP]  the studying speed [SEP]  a learning function [SEP]  a the function number
ICLR_2020_891,6529,"the method is built upon existing ideas, however.",originality [SEP] negative [SEP]  the method is built however [SEP]  method is built existing ideas however
ICLR_2020_891,6530,", the exact algorithm seems to be novel.",originality [SEP] positive [SEP]  the exact algorithm seems
ICLR_2020_2074,6772,this paper addresses a very good question.,motivation [SEP] positive [SEP]  this paper addresses question [SEP]  paper a addresses very good question
ICLR_2020_2074,6773,the paper lacks precision in key areas the motivation is not too convincing without showing some results on hard tasks the motivation for the proposed method avoids explicit model learning which is a similar motivation as model free methods.,motivation [SEP] negative [SEP]  motivation model similar free methods [SEP]  motivation showing some results [SEP]  the proposed method avoids learning [SEP]  avoids explicit model learning
ICLR_2020_2074,6774,"this is timely and the general thrust of the thinking, in terms of learning from perturbation around trajectories, is good but i am not sure the proposed methods are sufficiently well developed to merit publication.",soundness [SEP] positive [SEP]  sufficiently well developed merit publication [SEP]  terms learning [SEP]  i am not not not sure
ICLR_2020_2074,6775,i find the evaluation really weak 4 .some of the discussion comes across as a bit naive it would be extremely helpful to validate how well the physical derivatives are estimated in terms of how useful they are for a downstream task the zero shot planning experiment in section 4.4 seems very contrived. it does not seem like a useful task to adjust the parameters of the pd controller in order to reach a state that isn't the target ..,soundness [SEP] negative [SEP]  i find [SEP]  find the evaluation [SEP]  the discussion comes [SEP]  well derivatives are estimated terms [SEP]  how are useful they [SEP]  the a useful task zero shot planning experiment [SEP]  it naive would be helpful not
ICLR_2020_2074,6776,"i don't doubt the result but in the way it is presented here it does not appear to be referenced in the text and it is not clear what is being shown further, it fails to communicate key ideas (particularly in the experiments) to a non robotics reader. without sufficient clarity and background, it is not suited to a general machine learning conference. spelling errors throughout the captions labels etc many of the figures are out of order w.r.t .their introduction in the text but there are a few reasons why i believe this work is not ready for publication.",clarity [SEP] negative [SEP]  communicate key ideas [SEP]  sufficient clarity background [SEP]  a is not suited general machine learning conference [SEP]  spelling errors [SEP]  the many figures are [SEP]  t r w order introduction [SEP]  t r w their introduction [SEP]  the not be referenced text [SEP]  i don't n't doubt result [SEP]  is not why believe this work
ICLR_2020_2074,6777,"without much more extensive experimental validation with limited experiments on a single very low dimensional domain and no comparisons against any alternative methods, there is little evidence demonstrating the actual effectiveness of the proposed method, especially on more complex domains and for downstream tasks. i would appreciate more extensive evaluation across multiple different (simulated) domains and assessing the effectiveness of gradient estimation along random parameters there are no experiments involving such policy gradient updates as far as i can tell it would be good to understand the effect of this design decision better with an ablation.",substance [SEP] negative [SEP]  the effect understand better [SEP]  much more extensive experimental validation limited experiments [SEP]  no comparisons domains multiple different simulated [SEP]  little evidence demonstrating effectiveness [SEP]  the demonstrating actual effectiveness [SEP]  more extensive would appreciate evaluation are [SEP]  the effectiveness assessing [SEP]  gradient estimation random parameters [SEP]  experiments no gradient involving [SEP]  gradient involving such policy
ICLR_2020_2074,6778,"while i am not aware of any prior work on learning physical derivatives, the actual methods used are not novel in of themselves beyond being applied towards learning derivatives with respect to the policy ..",originality [SEP] negative [SEP]  the respect policy [SEP]  not the actual methods used [SEP]  learning physical derivatives
ICLR_2020_2074,6779,while the idea is interesting the method to estimate gradients by shaking in a probabilistic way by fitting a gp to noisy trajectories is clever and interesting ..,originality [SEP] positive [SEP]  the idea is interesting [SEP]  the idea is interesting interesting method
ICLR_2020_2074,6780,"right now, experimental results lack any comparisons to other methods or any other way to assess the effectiveness of estimating physical derivatives. and the method is not placed in context among related work ..",meaningful-comparison [SEP] negative [SEP]  estimating physical derivatives [SEP]  now results lack any comparisons [SEP]  the assess effectiveness
ICLR_2020_539,7749,which is of limited contribution and novelty.,originality [SEP] negative [SEP]  limited contribution novelty
ICLR_2020_539,7750,"proposes a simple and effective defense based on different combinations of input transformation and its performance even surpasses some sota at models with less computation a new method that shows a clear improvement over with thorough experiments ,.",soundness [SEP] positive [SEP]  proposes a simple and effective defense method [SEP]  even surpasses some sota [SEP]  a shows clear improvement
ICLR_2020_539,7751,a defense based on the at framework like doa may not be a good choice.,soundness [SEP] negative [SEP]  a defense based not [SEP]  a defense may not not not be good choice
ICLR_2020_539,7752,it has clear motivation.,motivation [SEP] positive [SEP]  it has motivation [SEP]  has clear motivation
ICLR_2020_539,7753,", is very clearly written, evaluates proper benchmarks from overall this is a strong paper part carefully written.",clarity [SEP] positive [SEP]  evaluates proper benchmarks
ICLR_2020_539,7754,"overall the prose in that paragraph is turgid, due to too many action phrases being turned into nouns ..",clarity [SEP] negative [SEP]  the prose that paragraph [SEP]  too many action phrases being turned [SEP]  phrases being turned nouns
ICLR_2020_539,7755,"recent literature, and benchmarks in literature ..",meaningful-comparison [SEP] positive [SEP]  literature benchmarks [SEP]  recent literature literature
ICLR_2020_539,7756,the assertion that rectangular occlusions might be a fruitful model for realizable attacks is only lightly tested.,substance [SEP] negative [SEP]  the assertion rectangular occlusions [SEP]  a occlusions might be fruitful model
ICLR_2020_301,7980,"i believe it is a good addition to the community of continual learning. the paper presents a simple yet effective way to avoid catastrophic forgetting in a continual learning setting. this indicates that the proposed method will be relevant to the community. in my opinion, this work is highly significant ..",motivation [SEP] positive [SEP]  this my opinion work [SEP]  believe it is [SEP]  a paper presents simple yet effective way [SEP]  the indicates proposed method
ICLR_2020_301,7981,"1 .the proposed method is simple but effective. the proposed method is well justified and the experiments performed clearly illustrate but the experiments show that the proposed method, despite.",soundness [SEP] positive [SEP]  the experiments performed illustrate [SEP]  the proposed method simple [SEP]  the proposed method effective
ICLR_2020_301,7982,i do not see any analysis of the method that explains this improvement. but i don't see an explanation of why this is the case i am not sure why weighting the learning rate would be a good idea i am not fully convinced that this method should do better than existing approaches ..,soundness [SEP] negative [SEP]  not not am fully convinced existing approaches [SEP]  an is n't explanation why case [SEP]  a would be good idea [SEP]  not not method this am fully convinced
ICLR_2020_301,7983,"an ablation study with different choices of the importance measure the paper reports decent empirical results in some challenging settings which might be useful to the continual learning community. the gains with respect to previous methods being very simple, works very well in practice.",substance [SEP] positive [SEP]  gains works well practice [SEP]  an ablation study different choices [SEP]  study reports decent empirical results results [SEP]  the might be useful useful continual learning community [SEP]  the the continual learning community gains [SEP]  previous methods being simple
ICLR_2020_301,7984,2 .survey and comparison with memory based methods are limited. my main concern with the paper is that it fails to justify the superiority of the method over other baselines ..,meaningful-comparison [SEP] negative [SEP]  the justify superiority [SEP]  2 survey comparison [SEP]  limited my main concern
ICLR_2020_301,7985,overall i think the idea of using uncertainties for continual learning is interesting. the proposed method is novel up to my knowledge ..,originality [SEP] positive [SEP]  novel my knowledge [SEP]  overall think the idea is [SEP]  the interesting proposed method
ICLR_2020_301,7986,the methodological contributions do not seem very sophisticated.,originality [SEP] negative [SEP]  the methodological do contributions not not not seem sophisticated
ICLR_2020_301,7987,the paper is clearly written and easy to read. the method proposed is well described and it would be easy to.,clarity [SEP] positive [SEP]  the paper is clearly written easy [SEP]  the method proposed [SEP]  it well described
ICLR_2020_1854,9044,the idea is straightforward and easy to follow. though method is well presented.,clarity [SEP] positive [SEP]  the idea straightforward [SEP]  follow method
ICLR_2020_1854,9045,the use of shap as the only explanation method presentation i think the authors used a wrong template to generate the article. the paper contains many typos and even the title contains a misspelling ..,clarity [SEP] negative [SEP]  paper contains many typos [SEP]  the think authors [SEP]  a authors used wrong template [SEP]  the generate article
ICLR_2020_1854,9046,is not well explained. doubts on the effectiveness of the proposed method. the reported values of other methods are not correct. the threat model of the oblivious adversary is unconvincing ..,soundness [SEP] negative [SEP]  is not not well explained doubts [SEP]  doubts the effectiveness [SEP]  the correct threat model
ICLR_2020_1854,9047,"why not to conduct ablation study on the different choice of explainer i encourage the authors to provide more results on this challenging scenario i would also like to see how these results hold good for a complicated dataset like imagenet the authors should investigate the white box accuracy of their detection system, or at the very least try black box attacks against the detector. and all the experiments are conducted in a relatively small dataset, it is also suggested to do experiments on large datasets, e.g .imagenet.",substance [SEP] negative [SEP]  experiments are conducted [SEP]  why not not not conduct ablation study [SEP]  ablation study the different choice [SEP]  provide more results [SEP]  results how these hold good [SEP]  the authors should investigate white box accuracy [SEP]  a dataset experiments are conducted relatively small
ICLR_2020_1854,9048,the evaluation is substantial good results are demonstrated compared with other comparators.,substance [SEP] positive [SEP]  the evaluation substantial results [SEP]  compared other comparators
ICLR_2020_1854,9049,"therefore, i think the comparison is invalid. the comparators listed in the experiments are not state of art or common baselines. the paper does not have the literature review for work related to the model interpretation ..",meaningful-comparison [SEP] negative [SEP]  the related model interpretation [SEP]  the therefore think comparison is [SEP]  the not not not paper does have literature review [SEP]  work related
ICLR_2020_1854,9050,overall i think the paper made a valuable contribution to the adversarial ml literature ..,motivation [SEP] positive [SEP]  overall i think [SEP]  overall think the paper [SEP]  a paper made valuable contribution
ICLR_2020_1854,9051,the contribution of the paper is rather incremental. weakness the idea of this paper is based on the interpretation method of dnn.,originality [SEP] negative [SEP]  the contribution paper this [SEP]  the weakness idea
ICLR_2020_1854,9052,strength the method is easy to implement and using the idea of interpretation for detecting adversarial examples seems interesting ..,originality [SEP] positive [SEP]  strength the method [SEP]  the using idea [SEP]  detecting adversarial examples
ICLR_2020_1854,9053,"in the experiments, many details are omitted ..",replicability [SEP] negative [SEP]  the experiments many details
ICLR_2020_716,9139,"i think the writing can be improved and explanations can be clarified, especially for people less familiar with the field like myself. i feel that a few things should be modified for clarity. i would recommend that the authors proofread for english grammar and style in updated versions of the paper.",clarity [SEP] negative [SEP]  style updated versions [SEP]  think the writing [SEP]  writing can be improved explanations [SEP]  the people less familiar field [SEP]  a feel few things [SEP]  be things should modified clarity
ICLR_2020_716,9140,"overall, i think the structure of the paper is fairly good ..",clarity [SEP] positive [SEP]  overall i think is [SEP]  overall think the structure is
ICLR_2020_716,9141,i did not find what activation function the authors end up using in their experiments.,replicability [SEP] negative [SEP]  using their experiments [SEP]  did not find what activation [SEP]  not activation function the authors
ICLR_2020_716,9142,but the theory does not seem to match the proposed method exactly ..,soundness [SEP] negative [SEP]  the theory does not not seem [SEP]  the not match proposed method exactly
ICLR_2020_716,9143,"the experimental results are good overall, as the proposed method tends to give the best results (by a small margin ).",substance [SEP] positive [SEP]  a results best small margin [SEP]  the proposed method tends [SEP]  the results good overall best
ICLR_2020_716,9144,and i hope the cleaned datasets will be useful for the research community.,motivation [SEP] positive [SEP]  i hope [SEP]  hope the cleaned datasets [SEP]  the datasets will be useful useful research community
ICLR_2020_716,9145,the conceptual contribution therefore seems incremental ..,originality [SEP] negative [SEP]  the conceptual contribution therefore seems incremental
ICLR_2020_716,9146,"drgcn is only compared to other normalization schemes (batch normalization and layer normalization) on one dataset, and so there is insufficient evidence to conclude that drgcn generally works better than existing methods empirically.",meaningful-comparison [SEP] negative [SEP]  generally works better existing methods empirically [SEP]  insufficient evidence conclude
ICLR_2020_2064,9160,the proposed approach is single and elegant ..,originality [SEP] positive [SEP]  the proposed approach single
ICLR_2020_2064,9161,it is not clear that the universality is what makes it work it is not clear that universality is the important advantage of mint ..,originality [SEP] negative [SEP]  the important advantage mint [SEP]  clear the universality makes [SEP]  what makes
ICLR_2020_2064,9162,"problem formulation is far from clear, perhaps because of the lack of clarity in writing. some notations are confusing there for instance the notations are loosely used in nature the authors are overly emphasizing what they want to do (interpolating between independent networks and shared network)..",clarity [SEP] negative [SEP]  problem formulation clear [SEP]  the lack clarity [SEP]  notations are confusing there instance [SEP]  are authors overly emphasizing what
ICLR_2020_2064,9163,"the super short section 2 did not clearly illustrate what's being trained and what's being tested, and whether we care about the generalization performance of each task ,.",replicability [SEP] negative [SEP]  the not care generalization performance [SEP]  the super short section did not not not clearly illustrate [SEP]  section did not not not clearly illustrate what
ICLR_2020_2064,9164,"theoretical justification is at best shallow, or at least in the context that the authors have put it it is hard to understand whether the experiments are reasonably and there is little information on why those competitors are selected, whether they represent state of the art it looks a bit strange to me that there is no discussion on regularizing the linear transformation matrices, as it seems possible to embed the task relations through the regularization. the interpretation of why mint works is not clear.",soundness [SEP] negative [SEP]  theoretical justification is is [SEP]  the least context [SEP]  the understand experiments are [SEP]  little information those competitors
ICLR_2020_2064,9165,"it is strongly suggested to introduce film in more detail and compare it with the proposed approach more clearly in design it would be better for authors to give more detailed comparisons with models that work on combining both joint training and independent training. it is most closely related to mtl factorization methods, but does not discuss this literature, or provide these experimental comparisons they should to make it a clear comparison ..",meaningful-comparison [SEP] negative [SEP]  it is strongly suggested [SEP]  compare the proposed approach clearly [SEP]  design would be better [SEP]  more authors give detailed comparisons [SEP]  does not not discuss this literature [SEP]  comparisons not provide these experimental [SEP]  comparison experimental they make
ICLR_2020_2064,9166,it is suggested to analyze the matrices learned by the proposed approach and there are no experimental analyses of what mint learns the non synthetic experiments in the paper are only performed on tasks that are closely related ..,substance [SEP] negative [SEP]  are only performed tasks [SEP]  the learned proposed approach [SEP]  are no experimental analyses
ICLR_2020_159,9285,"matching density ratios is a novel and interesting idea. to the best of my knowledge, the ratio model is obtained by minimizing the distance between true ratio function and its ratio model (something similar to (4) )..",originality [SEP] positive [SEP]  something similar [SEP]  matching a density ratios novel and interesting idea [SEP]  best my knowledge
ICLR_2020_159,9286,the paper needs to be more careful with mathematical expressions. some derivation of density ratio estimation is not clear could you explain the derivation in detail.,clarity [SEP] negative [SEP]  derivation not could explain detail [SEP]  the paper needs [SEP]  be more careful mathematical expressions [SEP]  mathematical expressions some derivation not
ICLR_2020_159,9287,"therefore, more empirical comparisons should be made with mmd gan. but it does not compare to more recent (last 2 years) models in this space or very thoroughly establish the applicability.",meaningful-comparison [SEP] negative [SEP]  therefore more empirical comparisons should be made [SEP]  therefore comparisons should be made mmd gan [SEP]  it does not not not compare models [SEP]  more not recent last 2 years models
ICLR_2020_159,9288,and inception scores should also be reported for better validating the effectiveness of the proposed method but could be much more convinced with some additional work some important density ratio based gan methods are missing ..,substance [SEP] negative [SEP]  inception scores be [SEP]  better validating the effectiveness [SEP]  be more convinced some additional work
ICLR_2020_159,9289,"experimentally, the proposed model performs pretty nicely ..",substance [SEP] positive [SEP]  experimentally the proposed model performs nicely
ICLR_2020_159,9290,the derivation is not certain and some important density ratio based gan is missing ..,soundness [SEP] negative [SEP]  the derivation not certain
ICLR_2020_1303,9891,"evaluations seem rather noisy to make a reliable judgement unlike dual policy iteration, there is no theoretical justification why doing these heuristics are good convincible. 2 .as a paper focusing on experiments, the results are not enough the current experiments are not convincing to claim the proposed tpo method is a better choice over other existing methods. the learning efficiency, proposed objective algorithm are questionable the proposed method is not really a method that makes mcts work for continuous action spaces.",soundness [SEP] negative [SEP]  a make reliable judgement [SEP]  the the experiments results not current [SEP]  the experiments not enough current [SEP]  the is claim proposed tpo method [SEP]  the not proposed method questionable [SEP]  a not method makes
ICLR_2020_1303,9892,the proposed tpo is better than other baselines experimental results are quite promising as expected ..,soundness [SEP] positive [SEP]  the proposed tpo better are [SEP]  other baselines experimental results are promising
ICLR_2020_1303,9893,how many trials were performed.,substance [SEP] negative [SEP]  how many trials were performed
ICLR_2020_1303,9894,the algorithm is not compared to any other approach. without comparing with other baselines there is no intuition or comparison to support it ..,meaningful-comparison [SEP] negative
ICLR_2020_1303,9895,"overall, this paper has no contributions on theory ..",originality [SEP] negative [SEP]  overall this paper has contributions [SEP]  overall paper has no contributions
ICLR_2020_1303,9896,"overall, this paper pursues an interesting research problem ..",motivation [SEP] positive [SEP]  overall this paper pursues problem [SEP]  overall paper pursues an interesting research problem
ICLR_2020_1303,9897,"in addition, some of the descriptions in the paper are unclear that makes it hard to understand ..",clarity [SEP] negative [SEP]  the the descriptions paper
ICLR_2020_1303,9898,"there are many technical details missing, hence making it difficult to understand how a search tree can be built for continuous domains.",replicability [SEP] negative [SEP]  many technical details missing [SEP]  a understand search tree [SEP]  how tree can be built continuous domains
ICLR_2020_1808,10116,the experiments are small (on two small and one slightly larger dataset) and inconclusive the problem of small evaluation datasets make the results the experiments are very thin ..,substance [SEP] negative [SEP]  the experiments small [SEP]  are small evaluation datasets make [SEP]  the are make results
ICLR_2020_1808,10117,"the paper needs to include stronger baselines. but the way that the comparison is currently set up doesn't seem to facilitate a clear comparison of the pros and cons of this method versus other ones in the literature for future submissions, it would be good to see a more comprehensive empirical comparison of the proposed method compared to others, and also to the authors only compare their results to treecnn and gated graph nn (ggnn). it's unclear if treecaps is better than other existing models.",meaningful-comparison [SEP] negative [SEP]  is other better existing models [SEP]  the paper needs [SEP]  the comparison is [SEP]  a comparison n't facilitate clear [SEP]  the method other ones proposed [SEP]  a comparison see more comprehensive empirical [SEP]  the method proposed compared [SEP]  compared others [SEP]  compare only their results
ICLR_2020_1808,10118,the variable to static capsule routing indeed appears novel.,originality [SEP] positive [SEP]  the variable static
ICLR_2020_1808,10119,"given a graph capsule network is in place, i found the contribution of this paper (tree capsule network) is limited ..",originality [SEP] negative [SEP]  given a graph capsule network is [SEP]  i found contribution limited [SEP]  found the contribution limited
ICLR_2020_1808,10120,but i was a bit confused by its internal details ..,clarity [SEP] negative [SEP]  bit confused its internal details
ICLR_2020_1808,10121,have more explanations about the design of the network the idea of incorporating tree structures into the design for capsule networks is not wrong ..,soundness [SEP] negative [SEP]  idea capsule networks is not not not wrong [SEP]  more explanations the design
ICLR_2020_890,10173,"the paper focuses on a novel constraining approach with seemingly superior scalability, and this is potentially a significant contribution. the method is interesting, novel and seemingly efficient the contributions claimed are novel technique to impose inequality constraints on neural network activations ..",originality [SEP] positive [SEP]  paper a focuses novel constraining approach [SEP]  a is potentially significant contribution [SEP]  novel contributions are technique
ICLR_2020_890,10174,without justification and motivation the method has no merit and won t have any impact in the machine learning community. the method is not motivated.,motivation [SEP] negative [SEP]  have any impact [SEP]  justification motivation [SEP]  method has no merit
ICLR_2020_890,10175,"the monotonicity constraint could have a huge impact for mcmc sampling of neural parameters since it can reduce away all multimodalities of the posterior caused by reordering nodes or layers although the contribution of the paper is potentially significant overall, the approach is well motivated, and.",motivation [SEP] positive [SEP]  the is potentially significant approach [SEP]  the monotonicity constraint could have impact [SEP]  constraint a could have huge impact [SEP]  can reduce away all multimodalities [SEP]  the contribution paper is significant overall
ICLR_2020_890,10176,"i had hard time following the method, and i do not understand the procedure of the proposed method.",clarity [SEP] negative [SEP]  the do not not understand procedure [SEP]  had hard time [SEP]  following the method
ICLR_2020_890,10177,the method is clear.,clarity [SEP] positive [SEP]  the method clear
ICLR_2020_890,10178,"i its not clear how the neural network is modified and how backpropagation is performed with the contraints. it s also not explained how are modelling domain constraints different. the paper also does not make very clear the different constraining approach advantages and tradeoffs. but it is insufficiently defined, some details are not clearly described. however, the computation performed in the constraint layer is not clear ..",replicability [SEP] negative [SEP]  not not is insufficiently defined some details [SEP]  i clear [SEP]  not the constraints different paper
ICLR_2020_890,10179,"the paper does not compare to the earlier constrained methods (marquaz neila or optnet),.",meaningful-comparison [SEP] negative [SEP]  the paper does not not compare
ICLR_2020_890,10180,well placed in the literature.,meaningful-comparison [SEP] positive [SEP]  well placed the literature
ICLR_2020_890,10181,"and experiments are quite weak with little comparisons and no experiments with practical value. the evaluation is limited to a checkerboad constraint, and other examples of practical linear constraints are not clear. but it would be better to show more examples of linear constraints the authors should provide more experiments to explain that trade off ..",substance [SEP] negative [SEP]  experiments are weak [SEP]  quite weak little comparisons [SEP]  a is evaluation limited checkerboad constraint [SEP]  it would be better [SEP]  examples show more [SEP]  experiments more authors should provide
ICLR_2020_890,10182,the experimental analysis does not support all the claims made by the authors as it focuses on a single dataset (mnist) and single constraint.,soundness [SEP] negative [SEP]  the analysis does not not not not support all claims constraint [SEP]  the made authors
ICLR_2020_890,10183,and the idea of using softmax to get a convex combination of the vertices of the v representation to guarantee constraint satisfaction is reasonable ..,soundness [SEP] positive [SEP]  the idea using softmax
ICLR_2019_1490,10300,i find that the paper addresses a relevant problem and try to.,motivation [SEP] positive [SEP]  i find [SEP]  the paper addresses problem [SEP]  a paper addresses relevant problem
ICLR_2019_1490,10301,apply a novel approach.,originality [SEP] positive [SEP]  a apply novel approach
ICLR_2019_1490,10302,"but, in general, i find the paper is not easy to follow and to grasp the main ideas. besides the paper is hard to follow.",clarity [SEP] negative [SEP]  find the paper is [SEP]  i find is [SEP]  the grasp main ideas
ICLR_2019_1490,10303,"are not convincing to me. the proposed method is not convincing, but i am not absolutely sure ..",soundness [SEP] negative [SEP]  convincing me proposed [SEP]  not convincing the proposed method [SEP]  not not not i am sure
ICLR_2019_1490,10304,the current experiments might be weak. additional experiments on popular image datasets are recommended ..,substance [SEP] negative [SEP]  the current experiments might be weak [SEP]  experiments might be weak weak additional [SEP]  experiments popular image datasets are recommended
ICLR_2020_590,10363,the paper addresses an important and timely problem ..,motivation [SEP] positive [SEP]  the paper addresses problem [SEP]  paper addresses an important and timely problem
ICLR_2020_590,10364,it is a pity that the code is not provided ..,replicability [SEP] negative [SEP]  it a pity [SEP]  a pity the code
ICLR_2020_590,10365,"as far as i know, this work is among the earliest works to think about gnn pre training ..",originality [SEP] positive [SEP]  think gnn pre training [SEP]  know this work [SEP]  the earliest works think
ICLR_2020_590,10366,these strategies are not surprising for me and the novelty is incremental ..,originality [SEP] negative [SEP]  these strategies not surprising [SEP]  surprising me [SEP]  the not is novelty incremental
ICLR_2020_590,10367,the experiments are overall good. experimental construction and analysis also seems sound ..,soundness [SEP] positive [SEP]  the experiments overall good
ICLR_2020_590,10368,i would have liked to see a bit more analysis as to why some pre training strategies work over others ..,soundness [SEP] negative [SEP]  why strategies work others [SEP]  i would have liked
ICLR_2020_590,10369,"the writing is good and easy to follow. overall, this paper was well written with useful illustrations and clear motivations ..",clarity [SEP] positive [SEP]  the writing good [SEP]  overall this paper was well written
ICLR_2020_590,10370,i would like to see more discussion about difference between this work and.,meaningful-comparison [SEP] negative [SEP]  i would like [SEP]  see more discussion [SEP]  more discussion difference
ICLR_2018_483,10415,"i find the paper interesting but not very clearly written in some sections, for instance i would better explain what is the main contribution and devote some more text to the motivation. section 2.2 requires some polishing as i found hard to follow the main story the authors wanted to tell. overall i found the paper interesting but also not very clear at pointing out the major contribution and the.",clarity [SEP] negative [SEP]  the contribution devote text major [SEP]  not not clearly written some sections [SEP]  would better explain what is [SEP]  some devote more text [SEP]  the main follow story [SEP]  i find interesting
ICLR_2018_483,10416,the paper is clearly written and well illustrated by figures and examples. the paper is easy to follow.,clarity [SEP] positive [SEP]  the paper is clearly written [SEP]  the paper is clearly written
ICLR_2018_483,10417,the proposed idea is not exceptional original.,originality [SEP] negative [SEP]  the proposed idea not exceptional
ICLR_2018_483,10418,although it is on an adequate technical level. the relation between the vertex and spectrum domain is well elaborated and nice (the experimental evaluation appears to be sound ..,soundness [SEP] positive [SEP]  it adequate level [SEP]  an adequate technical level the relation [SEP]  the experimental evaluation appears
ICLR_2018_87,10934,two strategies are proposed and the ideas are reasonable and.,soundness [SEP] positive [SEP]  two strategies are
ICLR_2018_87,10935,the differentiable quantization strategy seems not to be consistently better than the straightforward quantized distillation which may need more research. and it seems to need a lot of more work to make the idea really practical. overall i am mostly ok with this paper but not impressed by it this needs more discussion.,soundness [SEP] negative [SEP]  more needs discussion [SEP]  the better straightforward quantized distillation may need research [SEP]  may need more research [SEP]  i make idea really practical
ICLR_2018_87,10936,"clearly introduced the paper is well written ,.",clarity [SEP] positive [SEP]  clearly introduced the paper
ICLR_2018_87,10937,3 .i am a little bit confused by how the bits are redistributed in the second method this needs more clarification. 4 .the writing can be improved ..,clarity [SEP] negative [SEP]  writing can be improved [SEP]  how the bits are redistributed second method [SEP]  needs more clarification
ICLR_2018_87,10938,the review of distillation and quantization is clear.,meaningful-comparison [SEP] positive [SEP]  the review distillation
ICLR_2018_87,10939,this makes the comparison a little bit unfair it will be better if the authors could discuss the connections between distillation and the recent work for the learning using privileged information setting.,meaningful-comparison [SEP] negative [SEP]  makes the comparison unfair [SEP]  it unfair will be better [SEP]  the authors could discuss connections [SEP]  the distillation recent work
ICLR_2018_87,10940,extensive experiments on vision and neural machine translation are conducted. detailed discussions about implementations are provided ..,substance [SEP] positive [SEP]  extensive experiments vision
ICLR_2018_87,10941,the actual speedup is not clearly calculated ..,replicability [SEP] negative [SEP]  the actual speedup is not not not clearly calculated
ICLR_2018_87,10942,2 .the idea of using the gradient with respect to the quantization points to learn them is interesting.,originality [SEP] positive [SEP]  learn them [SEP]  the using gradient [SEP]  the gradient respect
ICLR_2018_87,10943,but not entirely new i believe this idea is quite similar to the idea of learning using privileged information.,originality [SEP] negative [SEP]  not believe this is idea [SEP]  using privileged information
ICLR_2018_87,10944,i like this paper very much as it is in good motivation to utilize the distillation framework for the task of model compression. the starting point is quite interesting the information from the teacher network is useful for constructing a better compressed model.,motivation [SEP] positive [SEP]  a model constructing better compressed [SEP]  like this paper much [SEP]  is good motivation [SEP]  the quite interesting information information
ICLR_2020_144,11136,quality the quality of the submission is extremely low.,originality [SEP] negative [SEP]  quality the the submission [SEP]  quality quality the submission low
ICLR_2020_144,11137,originality the idea of visualizing states that reveal interesting insights about an agent's behavior based on a user defined target function sounds interesting. while i do agree that the paper proposes an interesting idea the saliency based vae objective is new to me as well ..,originality [SEP] positive [SEP]  originality the idea [SEP]  reveal interesting insights [SEP]  an agent's behavior based [SEP]  a interesting user defined target function sounds [SEP]  idea interesting an paper proposes [SEP]  the is based saliency vae objective new well
ICLR_2020_144,11138,the optimization objectives chosen by the authors seem very ad hoc to me and how the motivation relates to the objectives is hard to comprehend the technical presentation of the work is simply too poor and not convincing at this stage. it is pretty obvious that the paper in its current form simply does not adhere to scientific standards for technically reporting machine learning algorithms in a proper way ..,soundness [SEP] negative [SEP]  the objectives authors seem [SEP]  the objectives is hard [SEP]  convincing this stage [SEP]  the not pretty obvious paper [SEP]  simply not not not paper does adhere scientific standards
ICLR_2020_144,11139,the approach seems reasonable and the experiments seem reasonable as well ..,soundness [SEP] positive [SEP]  the approach seems reasonable [SEP]  the seem reasonable experiments well
ICLR_2020_144,11140,the experimental results have very low quality as well results are mainly depicted as images with a verbal explanation.,substance [SEP] negative [SEP]  the experimental results have quality well [SEP]  results have very low quality well [SEP]  results are mainly depicted images
ICLR_2020_144,11141,and the experiments are well done and demonstrate the potential of the method.,substance [SEP] positive [SEP]  the experiments are well done [SEP]  the demonstrate potential
ICLR_2020_144,11142,"clarity the clarity of the paper is extremely poor. in general, i found the entire writing from section 3 onward a bit wordy and i do not think that nine pages are required to deliver the message of the paper in its current form the reparameterization trick is not required for the technical explanation of the involved random variables and how they relate to each other. please organize the figures better in relation to the text there are also a number of unclear details i'd want clarified.",clarity [SEP] negative [SEP]  i found writing wordy [SEP]  clarity the the paper [SEP]  do not think nine pages [SEP]  the paper extremely poor [SEP]  the technical explanation involved variables [SEP]  the organize figures better [SEP]  a number unclear details
ICLR_2018_612,11394,i am a bit surprised that you have not discussed it in the paper not to mention provided a baseline to compare your method to it's not clear if pruned fnns are the most suitable baseline for evaluating the results.,meaningful-comparison [SEP] negative [SEP]  the evaluating results [SEP]  have not discussed the paper [SEP]  not compare your method
ICLR_2018_612,11395,the main strengths of the paper are the supporting experimental results in comparison to plain feed forward networks (fnns)..,substance [SEP] positive [SEP]  the the main strengths paper [SEP]  the the paper supporting experimental results
ICLR_2018_612,11396,"however the structure learning is not performed end to end and in conjunction with the parameters in terms of experiments, there is not enough exploration of simpler sparse learning methods such as heavy regularization of the weights ..",substance [SEP] negative [SEP]  the structure learning is not not [SEP]  however learning is not not not performed end [SEP]  the conjunction parameters [SEP]  the parameters terms [SEP]  not enough exploration simpler methods [SEP]  learning simpler sparse methods such
ICLR_2018_612,11397,the main weakness of the paper is lack of cohesion in contributions.,originality [SEP] negative [SEP]  the the main weakness paper [SEP]  the paper lack [SEP]  lack cohesion
ICLR_2018_612,11398,and difficulty in delineating the scope of there needs to be a cohesive story that puts the elements together. the paper is not self contained in terms of methodology.,clarity [SEP] negative [SEP]  the puts elements together
ICLR_2018_612,11399,where is this method most applicable and where is it not applicable it does not adequately motivate the skip path connections or applications of the method to supervised tasks ..,soundness [SEP] negative [SEP]  where is this method applicable [SEP]  most applicable it not [SEP]  not not not does adequately motivate the skip path connections
ICLR_2019_709,11586,i think the ideas presented in this paper are interesting i like the new ideas in this paper.,originality [SEP] positive [SEP]  the ideas like new [SEP]  think the ideas are [SEP]  i think are
ICLR_2019_709,11587,and on its own is somewhat incremental in nature.,originality [SEP] negative [SEP]  somewhat incremental nature
ICLR_2019_709,11588,"but i think their presentation could be a bit clearer. the writing and structure of the paper can be improved. it is difficult to read without first reading gygli et al .2017, and this paper should be more self contained. there are also many parts that are not clear 1. overall this paper gives a useful but incremental improvement over the deep value network proposed by gygli et al .2017 .however, the writing should be substantially improved to make the paper more self contained and to it is very confusing for me to understand the proposed formulation as an adversarial framework.",clarity [SEP] negative [SEP]  the proposed understand formulation [SEP]  think their presentation [SEP]  paper this more self [SEP]  but a paper overall gives useful incremental improvement [SEP]  first reading gygli gygli et al
ICLR_2019_709,11589,i do not think you adequately explained why you chose to use a gan like loss to learn these models ..,soundness [SEP] negative [SEP]  learn these models [SEP]  do not think you
ICLR_2019_709,11590,you make appropriate comparisons against previous structured prediction models as well as against different types of gan like losses ..,meaningful-comparison [SEP] positive [SEP]  you make comparisons [SEP]  make appropriate comparisons [SEP]  different types gan
ICLR_2019_709,11591,"but, as i mentioned before, i think you needed to have more comparisons against different ways of training these networks that do not follow a gan inspired framework ..",meaningful-comparison [SEP] negative [SEP]  a do not not follow gan inspired framework [SEP]  i mentioned before [SEP]  have more comparisons
ICLR_2019_709,11592,but i think a few more experimental settings are required before they should be published.,substance [SEP] negative [SEP]  i think [SEP]  think a few more experimental settings [SEP]  settings are required they
ICLR_2019_709,11593,include missing experiment details.,replicability [SEP] negative [SEP]  include missing experiment details
ICLR_2018_4,11821,other works has more to offer but this is a promising technique for learning.,originality [SEP] positive [SEP]  other works has more [SEP]  a is promising technique
ICLR_2018_4,11822,it hard to be sure whether the proposed methods meaningfully improve existing methods.,originality [SEP] negative [SEP]  it hard [SEP]  methods meaningfully improve existing
ICLR_2018_4,11823,the things that are still missing in this work are some power reduction estimates as well as area reduction estimations ..,substance [SEP] negative [SEP]  the things are still missing [SEP]  are still missing this work [SEP]  this work some power reduction estimates
ICLR_2018_4,11824,"in general, the paper was written in good quality and in detail.",clarity [SEP] positive [SEP]  paper was written good quality
ICLR_2018_4,11825,it is not clear if this work obtains significant improvements over previous works. in this paper seems rather high in comparison to previous works.,meaningful-comparison [SEP] negative [SEP]  seems rather high comparison [SEP]  not work obtains significant improvements [SEP]  this paper seems high
ICLR_2018_4,11826,so it is hard to.,soundness [SEP] negative [SEP]  it hard
ICLR_2018_4,11827,quantify what is the contribution of the proposed method.,motivation [SEP] negative [SEP]  quantify what is [SEP]  quantify is the contribution
ICLR_2019_1033,11846,"the overall contribution makes sense. within this, the technical theoretical results presented in the paper are sensible. results on both synthetic dataset and benchmarks justify the theoretical observation and advantages. and implemented with both theoretical study and empirical justification ..",soundness [SEP] positive [SEP]  the theoretical results justify observation [SEP]  contribution makes sense [SEP]  the technical theoretical results presented [SEP]  results benchmarks justify observation
ICLR_2019_1033,11847,the theoretical study can be better organized ..,soundness [SEP] negative [SEP]  the theoretical study can be better organized
ICLR_2019_1033,11848,it is unclear what the aim of simulations is the write up can be improved too at some places.,clarity [SEP] negative [SEP]  write can be improved too some places [SEP]  unclear what [SEP]  the simulations write
ICLR_2019_1033,11849,the paper is generally clearly written.,clarity [SEP] positive [SEP]  the paper is generally clearly written
ICLR_2019_1033,11850,it makes sense to do a repeatability experiment here with multiple sets of simulated datasets cons some interesting cases not tested presentation could be improved the analysis is limited to a simple two layer linear network ..,substance [SEP] negative [SEP]  a analysis is limited simple two layer linear network [SEP]  multiple sets simulated [SEP]  cases not not tested presentation [SEP]  not presentation could be improved the analysis
ICLR_2019_1033,11851,pros novel treatment and formulation of meta learning from the perspective of fast and slow learning process the paper approaches the recently popular meta learning from a novel perspective by decomposing the learning process into slow and fast ones ..,originality [SEP] positive [SEP]  and fast slow process decomposing ones [SEP]  meta learning the paper approaches recently popular [SEP]  novel a perspective process decomposing
ICLR_2019_1033,11852,the technique used in this work is a mix of sgd and.,originality [SEP] negative [SEP]  the technique used [SEP]  used this work [SEP]  this work a mix
ICLR_2019_1033,11853,the paper is well motivated the paper brings in an interesting perspective to meta learning. the paper has a clear motivation. it is easy to read. training slow fast learners using different strategies is an interesting idea ..,motivation [SEP] positive [SEP]  an interesting different strategies idea [SEP]  the paper well motivated brings [SEP]  paper a has clear motivation [SEP]  using different strategies
ICLR_2019_1033,11854,"quantitative results did not compare to recent results such as reptile 1 or mt nets 2. i am wondering why the comparison to andrychowicz et al. , 2016 is missing ..",meaningful-comparison [SEP] negative [SEP]  am wondering the comparison is [SEP]  quantitative results did not not compare [SEP]  results did not compare recent such
ICLR_2019_380,11966,"i would have liked to see more discussion about why the two results differ to give readers intuition about where the extra flexibility comes from. saying that they consider all possible equivariant networks is not correct. therefore, i feel that the model used in this paper is rather uninteresting and irrelevant for practical purposes ..",soundness [SEP] negative [SEP]  irrelevant practical purposes [SEP]  the extra flexibility comes [SEP]  is they consider [SEP]  is consider all possible equivariant networks not [SEP]  i would have liked
ICLR_2019_380,11967,"the proof of this result is simple, but elegant ..",soundness [SEP] positive [SEP]  the proof this result
ICLR_2019_380,11968,i would have also liked to see a comparison to these methods in the the classification results ..,meaningful-comparison [SEP] negative [SEP]  i would have also liked [SEP]  a see comparison [SEP]  a comparison these methods
ICLR_2019_380,11969,this is particularly useful and important due to its applications to graphs and hyper graphs.,motivation [SEP] positive [SEP]  its applications graphs
ICLR_2019_380,11970,"overall, i enjoyed reading the paper.",clarity [SEP] positive [SEP]  overall i enjoyed [SEP]  reading the paper
ICLR_2019_380,11971,my only concern is the experiments some of the benchmark datasets for the proposed task as well as some well known methods.,substance [SEP] negative [SEP]  my only concern the experiments [SEP]  my only concern the experiments [SEP]  the the benchmark datasets proposed task
ICLR_2020_668,12022,i think this is one of the weaknesses of the paper. the writing and clarity could be significantly improved ..,clarity [SEP] negative [SEP]  i think is [SEP]  the the weaknesses paper
ICLR_2020_668,12023,"but very few details are given. my impression is that the reproducibility of the results could be very hard, because of the lack of details of the specific implementation ..",replicability [SEP] negative [SEP]  few details are given [SEP]  my impression the reproducibility [SEP]  very the be hard lack
ICLR_2020_668,12024,"i feel that, to better understand the method, the authors should include experiments in simple and easy to understand synthetic environments which can be more illustrative than atari ..",substance [SEP] negative [SEP]  better understand the method [SEP]  authors should include experiments
ICLR_2020_668,12025,as illustrated by the experimental results and the.,substance [SEP] positive [SEP]  illustrated the experimental results
ICLR_2020_668,12026,"the proposed approach is novel up to my knowledge. i find the idea of parameterizing the successor features in terms of the policy parameters very innovative. i vote for accept as this paper proposes a novel technique to combine mutual information based intrinsic control objectives with successor features, which allow for combining the benefits of both in a complementary way the technique for enforcing the restriction in eq .10, as well as being able to use it with generalized policy improvement is a good novel contribution in the paper ..",originality [SEP] positive [SEP]  a novel policy generalized improvement good contribution [SEP]  i find idea [SEP]  a novel paper proposes technique [SEP]  combine mutual information [SEP]  based intrinsic control objectives [SEP]  the technique combining benefits [SEP]  the a technique complementary way
ICLR_2020_668,12027,the proposed approach seems well justified and the experiments performed indicate that the method can be useful in practice. novel methodological contributions. the fact that fast task inference is sufficient to get good performance is impressive i.e .without the need to fine tune the best inferred policy.,soundness [SEP] positive [SEP]  get good performance [SEP]  the proposed approach seems justified [SEP]  the indicate method [SEP]  method can be useful useful practice [SEP]  fast task inference is sufficient
ICLR_2020_668,12028,the proposed contribution seems significant.,motivation [SEP] positive [SEP]  the proposed contribution seems significant
ICLR_2020_668,12029,the detailed comparison with baselines on the full atari suite is sufficient to back the claims in the paper that the strengths of bmi and sfs do complement each other.,meaningful-comparison [SEP] positive [SEP]  the detailed comparison baselines [SEP]  the back claims [SEP]  the the paper strengths
ICLR_2020_143,12697,so the idea itself is novel.,originality [SEP] positive [SEP]  the idea novel
ICLR_2020_143,12698,"while the idea is interesting this paper can be regarded as an engineering work for a new domain of problem with little technical novelty. from the perspective of nas research, the proposed approach has little technical novelty given that the nas is only applied to cnn backbones in this paper, the novelty (of proposing a new task) may be further weakened. the novelty of this work over existing works of nas on detection (is not justified mainly due to lack of technical novelty.",originality [SEP] negative [SEP]  little technical novelty novelty [SEP]  the idea is interesting [SEP]  paper can an be regarded engineering work [SEP]  a new domain existing works [SEP]  the perspective nas [SEP]  the novelty proposed approach has [SEP]  the nas given [SEP]  idea is interesting interesting this paper [SEP]  this work existing [SEP]  existing works detection
ICLR_2020_143,12699,", the limited improvement is hurting the significance of the work ..",motivation [SEP] negative [SEP]  the limited improvement is hurting significance [SEP]  the improvement is hurting significance
ICLR_2020_143,12700,it is a new application for nas research ..,motivation [SEP] positive [SEP]  it new application [SEP]  a new application nas research
ICLR_2020_143,12701,4.3.2 is a bit misleading. 3 .the paper is written poorly. there are many grammatically wrong and awkward expressions. limited experiments and poor writing.,clarity [SEP] negative [SEP]  many grammatically wrong and awkward expressions limited experiments
ICLR_2020_143,12702,"this is a great, well written paper overall. the design and experiment settings are well described with details ..",clarity [SEP] positive [SEP]  well settings are described details
ICLR_2020_143,12703,and the searched architecture also performs well on other tasks or datasets. the proposed approach shows some marginal improvement of object detection accuracy across multiple backbones and datasets ..,substance [SEP] positive [SEP]  approach shows some marginal improvement [SEP]  the searched architecture also performs well [SEP]  the proposed approach shows improvement
ICLR_2020_143,12704,"2 .experimental results are rather weak. given that the proposed approach is applicable to any backbones and detectors, more experiments should be done using recent stronger baselines.",substance [SEP] negative [SEP]  2 experimental results rather weak [SEP]  using recent stronger baselines
ICLR_2020_143,12705,overall it is a valid paper with reasonable ideas and decent results. the experiment results have quite nice improvements on several standard data sets ..,soundness [SEP] positive [SEP]  results have quite nice improvements [SEP]  it valid paper [SEP]  a valid paper reasonable ideas [SEP]  results the experiment have improvements
ICLR_2020_143,12706,the results are not exciting enough. the improvements of adding dilation on earlier layers are not exciting ..,soundness [SEP] negative [SEP]  the results not not exciting enough [SEP]  the not improvements adding dilation [SEP]  adding dilation
ICLR_2020_143,12707,the authors do not compare to any other neural architecture search methods the improvements less convincing. this paper does not compare its performance with other sota detection methods but only compare with some baselines instead. another experimental weakness is lack of comparison with existing nas methods on object detections such as they should be compared in any reasonable ways ..,meaningful-comparison [SEP] negative [SEP]  any should be compared reasonable ways [SEP]  the authors do not not compare [SEP]  not methods improvements less convincing this paper [SEP]  another experimental weakness lack [SEP]  methods comparison existing nas
ICLR_2020_143,12708,i hope the author could have more details in these two figures with more analysis ..,replicability [SEP] negative [SEP]  i hope [SEP]  hope the author [SEP]  author could have more details
ICLR_2018_119,13078,"the authors show a good awareness of the recent literature, and to the best of my knowledge, their empirical characterization of the number of latent parameters is original. and the idea looks original ..",originality [SEP] positive [SEP]  the original idea looks [SEP]  a authors show good awareness [SEP]  best my knowledge [SEP]  my knowledge their empirical characterization [SEP]  characterization latent parameters is original
ICLR_2018_119,13079,the proposed measures seem very practical with results that greatly strengthen their results and provide a much better justification of their approach.,soundness [SEP] positive [SEP]  a provide much better justification [SEP]  the proposed measures seem practical [SEP]  results greatly strengthen their
ICLR_2018_119,13080,"the authors perform experiments and draw conclusions without taking into account the variability of performance across different random projections however, i don't think that they make a convincing case for this approach ..",soundness [SEP] negative [SEP]  a n't make convincing case [SEP]  they make
ICLR_2018_119,13081,"except for the occasional typo or grammatical error the revisions seem somewhat rushed, due to the many typos and grammatical errors in the updated sections. not clear how you got to that number of parameters overall.",clarity [SEP] negative [SEP]  the occasional typo grammatical error [SEP]  the grammatical many typos errors [SEP]  not how you got overall
ICLR_2018_119,13082,", the paper is well written and organized. the issues are clearly identified, for the most part the method is clearly written.",clarity [SEP] positive [SEP]  the paper well written [SEP]  the organized issues
ICLR_2018_119,13083,"the experimental validation of their measure of intrinsic dimension could be made more extensive. for now, more work is needed ..",substance [SEP] negative [SEP]  the experimental validation their measure [SEP]  more work is needed
ICLR_2020_1672,13301,"in terms of significance, i think this paper is slightly incremental. results on both convergence and generalization have already been established in earlier works even for deep networks.",originality [SEP] negative [SEP]  results have already been established earlier works [SEP]  terms significance [SEP]  i think is [SEP]  think this is paper [SEP]  slightly incremental results
ICLR_2020_1672,13302,"moreover, the authors should probably add comparison to cao gu , 2019b in table 1. my major concern is that the comparison with allen zhu et al and cao gu seem somewhat unfair ..",meaningful-comparison [SEP] negative [SEP]  comparison al allen zhu et seem unfair [SEP]  moreover authors should probably add comparison [SEP]  the comparison my major concern
ICLR_2020_1672,13303,overall this paper is well written and easy to follow ..,clarity [SEP] positive [SEP]  this paper well written easy
ICLR_2020_1672,13304,the theoretical results on the neural network width and iteration complexity are interesting.,substance [SEP] positive [SEP]  the theoretical results neural network
ICLR_2020_1672,13305,another concern is that whether the derived theoretical results can be generalized to relu network.,substance [SEP] negative [SEP]  another concern derived [SEP]  the derived theoretical results can be generalized [SEP]  results can be generalized relu network
ICLR_2020_1672,13306,"this paper appears to be a significant contribution to the field of convergent gradient descent algorithms because of the introduction of a weaker condition that guarantees convergence while the work only applies to smooth activations and to logistic loss classification problems, it can inspire additional work both in rigorous guarantees for training neural nets in regression and classification ..",motivation [SEP] positive [SEP]  this paper appears [SEP]  a be significant contribution [SEP]  a significant contribution the field [SEP]  can work inspire additional
ICLR_2018_466,13325,but the pseudocode appears broken.,replicability [SEP] negative [SEP]  the pseudocode appears
ICLR_2018_466,13326,"i am surprised that there is only a comparison to tpot, not one to auto sklearn missing baseline comparison to auto sklearn the experiment compares with a weak baseline and a baseline that is unknown to me ..",meaningful-comparison [SEP] negative [SEP]  a is only comparison
ICLR_2018_466,13327,the data sets used in olson et al are very small. it would be helpful to include basic characteristics of the datasets used in this study final statistical significance test should be provided e.g .sign test the datasets are all small scale which is not representative of modern machine learning ..,substance [SEP] negative [SEP]  small is scale not not representative [SEP]  the data sets used [SEP]  sets et al are small [SEP]  include basic characteristics [SEP]  e be sign g test should provided
ICLR_2018_466,13328,i am unsure about the domain for the hillclimber. there are also several english grammar mistakes the references are inconsistently and incorrectly formatted this leaves me very uncertain about the actual quality of the proposed algorithm. finally the writing of the paper could be highly improved ..,clarity [SEP] negative [SEP]  the the proposed algorithm writing [SEP]  are several english grammar mistakes [SEP]  the are grammar mistakes references [SEP]  the uncertain actual quality proposed
ICLR_2018_466,13329,while the idea of autostacker is presented clearly the paper has numerous typos and needs thorough editing.,clarity [SEP] positive [SEP]  needs thorough editing
ICLR_2018_466,13330,"some parts of the paper feel unscientific neither paper offers any compelling theoretical results the paper lacks any discussion about how the architectures may change during search, as well as what sorts of architectures are learned. the novelty here is how exactly it is performed, which is a bit ad hoc ..",soundness [SEP] negative [SEP]  paper offers any compelling theoretical results [SEP]  parts the paper feel unscientific [SEP]  paper any lacks discussion [SEP]  how architectures may change search
ICLR_2018_466,13331,automl is a topic of high importance to both academia and industry.,motivation [SEP] positive [SEP]  a topic high importance
ICLR_2018_466,13332,the current presentation does not relate to learning representations in any meaningful way ..,motivation [SEP] negative [SEP]  the current presentation does not not relate [SEP]  learning representations
ICLR_2018_466,13333,cascading is not new the contribution itself is fairly minimal even if the contribution were more substantial this algorithm is not highly innovative ..,originality [SEP] negative [SEP]  new the contribution [SEP]  new the contribution
ICLR_2020_1478,13936,this argument is not new the proposed network is not much different from what several other sr methods used before my main concern on this work is its novelty seems to be limited ..,originality [SEP] negative [SEP]  not its novelty seems [SEP]  several other sr methods used [SEP]  used my main concern
ICLR_2020_1478,13937,training details are missing ..,replicability [SEP] negative [SEP]  training details are missing
ICLR_2020_1478,13938,the paper does not provide any comparisons with the top ranking methods in the ntire 2019 single image super resolution challenge leaderboard. no comparasions with previous ista methods (are conducted and discussed ..,meaningful-comparison [SEP] negative [SEP]  no challenge comparasions previous [SEP]  paper does not not not provide any comparisons [SEP]  the any comparisons top ranking methods
ICLR_2020_1478,13939,the use of an unfolding algorithm similar to lista is not clearly motivated and explained.,motivation [SEP] negative [SEP]  the use unfolding not [SEP]  an unfolding algorithm algorithm similar [SEP]  algorithm similar lista
ICLR_2020_1478,13940,finally the latex formatting suffers from many issues and typos ..,clarity [SEP] negative [SEP]  the latex formatting
ICLR_2020_1478,13941,this paper is well written and easy to follow ..,clarity [SEP] positive [SEP]  this paper well written easy
ICLR_2020_357,13942,no experimental comparison is given with regards to the time it takes to train a model with adversarial training discussion and comparison to very significant related work is missing and experimental measurement of any advantages of the proposed method vs. adversarial training is lacking. it would be great if the authors can provide the training time comparison between jarn and some state of the art robust training methods ..,meaningful-comparison [SEP] negative [SEP]  comparison is given regards missing [SEP]  experimental comparison is given missing [SEP]  given very significant related work missing measurement lacking [SEP]  experimental given missing measurement measurement lacking [SEP]  the any advantages proposed method [SEP]  comparison the time training can authors provide
ICLR_2020_357,13943,why not test simpler jacobian regularization method as proposed by other papers (see below). there are too many works on robustness defense that have been proven ineffective.,substance [SEP] negative [SEP]  why not not not test simpler jacobian regularization method [SEP]  not proposed other papers [SEP]  too many works robustness defense
ICLR_2020_357,13944,"the paper provides an interesting i think the main contribution of this paper is that it introduces a new way of robust training by encouraging jacobian saliency. in general, i like the intuition behind this paper, since it introduces a new perspective of robust training. this is an amusing original idea.",originality [SEP] positive [SEP]  the paper provides interesting [SEP]  the think main contribution is [SEP]  the like intuition
ICLR_2020_357,13945,"proof of concept for a method, showing that it is feasible ..",soundness [SEP] positive [SEP]  proof concept [SEP]  proof concept
ICLR_2020_357,13946,"it however doesn't make the the case for why it is a good idea. although this whole setup seems to be a little i would have liked to see more discussion in the paper of why jacobian saliency should confer robustness there's some discussion of the theory behind the method in section 3.1, but it's not very intuitive to the situation at hand (non linear neural networks.",soundness [SEP] negative [SEP]  it doesn't n't make case not [SEP]  a why is good idea [SEP]  this whole setup seems [SEP]  the the theory method
ICLR_2020_357,13947,another concern is reproducibility since the training process of gan is sensitive to hyperparameter selection.,replicability [SEP] negative [SEP]  is sensitive hyperparameter selection [SEP]  the reproducibility training process
ICLR_2020_357,13948,i think this is a very interesting work.,motivation [SEP] positive [SEP]  i think is [SEP]  think is a very interesting work
ICLR_2020_1753,14156,the principled approach followed to achieve the objective is solid and elegant. it is also intuitive and matches nicely with some valid observations highlighted.,soundness [SEP] positive [SEP]  some valid observations highlighted [SEP]  the principled approach followed [SEP]  the achieve objective
ICLR_2020_1753,14157,one major weakness of the paper is that it lacks a sufficient argumentation about how it differentiates from earlier attempts to nest wasserstein distances. another major weakness is that the paper lacks a quantitative evaluation scheme for its success ..,soundness [SEP] negative [SEP]  a quantitative evaluation scheme its success [SEP]  a lacks sufficient argumentation
ICLR_2020_1753,14158,in the paper such as insufficiency of by passing intermediate latent variables.,substance [SEP] positive [SEP]  the paper such [SEP]  such insufficiency passing variables [SEP]  passing intermediate latent variables
ICLR_2020_1753,14159,"having said that the proposed method is novel and elegant i think the idea of viewing the divergence in wae as a relaxed ws distance and then minimising it with another wae structure is interesting, intuitive and straightforward ..",originality [SEP] positive [SEP]  wae then minimising another structure interesting [SEP]  the is think idea
ICLR_2020_2131,14222,"the paper addresses an important problem, while i think that the practical significance of the proposed approach is i think that overall it makes an interesting contribution to the domain of udt which can be useful for future work. udt is a relevant and up to date problem. the design of the cost function is sensitive.",motivation [SEP] positive [SEP]  the problem date design [SEP]  paper addresses an important problem [SEP]  the think practical significance is [SEP]  i think is [SEP]  an overall makes interesting contribution [SEP]  the an interesting contribution domain [SEP]  can be useful useful future work
ICLR_2020_2131,14223,"which could explain its practical success the main problem that remains unsolved is how to choose the cost function the paper would have been much stronger if the proposed approach solves a more practical problem. in this sense, i think that the paper fails in giving convincing arguments that advocate the use of ot here. the experimental section is not convincing in explaining why the ot formulation is better than variants of cyclegan or also other schemes for computing ot than the dynamical formulation minor remark.",soundness [SEP] negative [SEP]  could explain its practical success problem is [SEP]  the how choose cost function [SEP]  a practical problem approach solves more [SEP]  this sense think [SEP]  i think [SEP]  giving convincing arguments
ICLR_2020_2131,14224,"i like the proposed dynamical formulation for solving ot and the link to resnets, which provides an interesting practical algorithm. and the proposition is reasonable.",soundness [SEP] positive [SEP]  the proposition reasonable [SEP]  i like formulation [SEP]  an provides interesting practical algorithm
ICLR_2020_2131,14225,overall the paper is well written the paper is fairly well written cons the paper helps to clarify some shortcomings of previous approaches and proposes a new solution. the paper is well written ..,clarity [SEP] positive [SEP]  overall the paper is is well written [SEP]  paper well written fairly cons helps [SEP]  clarify some shortcomings
ICLR_2020_2131,14226,at least the contributions should be clarified.,clarity [SEP] negative [SEP]  least the contributions clarified
ICLR_2020_2131,14227,a nice interpretation of cyclegan with ot.,originality [SEP] positive [SEP]  a nice interpretation cyclegan
ICLR_2020_2131,14228,"overall the quantity of novelties is, in the eyes of the reviewer, somehow limited ..",originality [SEP] negative [SEP]  the quantity novelties [SEP]  the the eyes reviewer
ICLR_2020_2131,14229,support the proposed approach.,substance [SEP] positive [SEP]  support the proposed approach
ICLR_2020_2131,14230,the design of the cost function is left open ..,replicability [SEP] negative [SEP]  the the design cost function
ICLR_2020_540,14521,"without any formal definition of the so called unordered set policy gradient estimation problem provided concrete examples such as those studied in the experiments to give a more complete picture of the problem in study w4 .the paper presentation quality can be improved i found the paper a bit hard to follow smoothly. treatments are lacking in explanation i think this paper should be reasonably self contained the account of the sum and sample estimator is somewhat misleading. the plots could use some improvement. it took me a lot of squinting at figures 2 and 3 to figure out what's going on, since the lines overlap too much.",clarity [SEP] negative [SEP]  the lines overlap much [SEP]  any formal definition so called [SEP]  the so called unordered set policy gradient estimation problem provided examples [SEP]  a give more complete picture [SEP]  a the problem more complete picture [SEP]  the study w4 paper presentation quality be [SEP]  the paper found [SEP]  treatments are lacking explanation [SEP]  paper think this [SEP]  reasonably self contained account [SEP]  the contained account
ICLR_2020_540,14522,"all in all, the paper is substantially improved in presentation the paper is very easy to understand and well written. and easy to read and it is written well the method derivation is generally well written and easy to follow ..",clarity [SEP] positive [SEP]  the read method derivation [SEP]  paper is substantially improved presentation [SEP]  it read
ICLR_2020_540,14523,"why this problem is important and challenging so, it may inspire future work ..",motivation [SEP] positive [SEP]  why this is problem important so [SEP]  it may inspire work [SEP]  may inspire future work
ICLR_2020_540,14524,w2 .the motivation of study is not clearly elaborated ..,motivation [SEP] negative [SEP]  motivation study not
ICLR_2020_540,14525,it will be better to provide one or two there are also additional baselines that should be considered.,meaningful-comparison [SEP] negative [SEP]  it will be better [SEP]  are also additional baselines
ICLR_2020_540,14526,"the justification of using the without replacement sampling strategy so far remains largely unconvincing. concerning the strength of theory, however, i am still not convinced that the current analysis is strong enough to thoroughly justify the benefit of the proposed estimator. .while it is possible that none of those methods are applicable in the experimental setting chosen in the paper, the authors should be very clear about how broadly they claim superiority of their method.",soundness [SEP] negative [SEP]  broadly claim superiority [SEP]  the justification using far [SEP]  using replacement sampling strategy far [SEP]  the concerning strength [SEP]  the thoroughly justify benefit [SEP]  it possible [SEP]  possible none
ICLR_2020_540,14527,"the derivations are all correct from what i can tell, while the derivations and theorems presented in the paper are correct, the experiments are sensible and support the claims made.",soundness [SEP] positive [SEP]  the support claims [SEP]  correct what can tell [SEP]  the are experiments sensible
ICLR_2020_540,14528,w3 .the overall novelty of theory is limited. the overall degree of novelty in theory is still relatively low.,originality [SEP] negative [SEP]  overall novelty novelty [SEP]  overall novelty theory [SEP]  the overall limited degree
ICLR_2020_540,14529,"and the proposed gradient estimator seems to be a novel and more attractive alternative to the existing ones in a number of popular dl rl applications this idea is original and quite nice. this paper has some interesting ideas ,.",originality [SEP] positive [SEP]  paper has some interesting ideas [SEP]  the proposed gradient estimator seems is [SEP]  a and be novel more attractive alternative
ICLR_2020_540,14530,too much space is spent on presenting the technical details while the principles intuitions behind these fancy mathematical but i could not find where the authors report which optimizer was used and how the hyperparameters were set. also figure captions could be a little more self contained ..,replicability [SEP] negative [SEP]  too much space is spent [SEP]  presenting the technical details intuitions
ICLR_2020_540,14531,the experiments are all reasonably well done.,substance [SEP] positive [SEP]  the experiments are all well done
ICLR_2020_540,14532,the experiments only test the proposed method in very low k settings.,substance [SEP] negative [SEP]  the experiments only test method [SEP]  the experiments only test proposed method
ICLR_2020_2030,14595,"flow loss in cv to encourage exploration in an environment with sparse rewards to the best of my knowledge, this was the first paper proposed to use moving patterns in two consecutive observations to motivate agent exploration. paper proposes a novel way to formulate intrinsic reward based on optical flow prediction error the scientific value of this work is appreciated and this work adds a lot to the community.",originality [SEP] positive [SEP]  a work adds lot [SEP]  an environment sparse rewards [SEP]  best my knowledge [SEP]  use moving patterns [SEP]  flow the optical prediction error scientific value
ICLR_2020_2030,14596,and the novelty was somewhat limited.,originality [SEP] negative [SEP]  the novelty was somewhat limited
ICLR_2020_2030,14597,"the authors discussed both the advantages of ficm and settings that ficm might fail to perform well, and conducted experiments to better help the readers understand such nuances ..",substance [SEP] positive [SEP]  the authors discussed both advantages [SEP]  conducted experiments [SEP]  the better help readers
ICLR_2020_2030,14598,"experiments were conducted only using a few recent results as baselines (icm, forward dynamics, rnd). but the experiments were analysis is need on how the method deals with known optical flow problems occlusion, large displacements, matching ambiguities. it would be helpful to have a better evaluation of this paper if the games in their empirical study.",substance [SEP] negative [SEP]  a have better evaluation [SEP]  experiments were conducted [SEP]  only using a few recent results [SEP]  experiments the analysis [SEP]  analysis is need [SEP]  the how method deals
ICLR_2020_2030,14599,such balanced view should be valuable to rl communities in both academia and industry. the proposed method (ficm) was clearly motivated this is a very important question and i hope the authors will address this while i find this study interesting and valuable.,motivation [SEP] positive [SEP]  such balanced view should be valuable [SEP]  a method was clearly motivated is very important question [SEP]  the hope authors
ICLR_2020_2030,14600,the motivation for this work is not fully clear.,motivation [SEP] negative [SEP]  the motivation this work not
ICLR_2020_2030,14601,"in general this was a very well written paper, i had no difficulty in following the paper throughout. while the paper is nicely written.",clarity [SEP] positive [SEP]  paper following the [SEP]  was had no difficulty
ICLR_2020_2030,14602,figures are very small and the font in them is not readable. figure 2 is especially difficult to read because the axes titles are tiny. authors could clarify and motivate the choice of it would also be useful to explicitly explain the advances of this approach over the next frame predictions approaches in stochastic environments ..,clarity [SEP] negative [SEP]  figure is not not readable [SEP]  the explicitly explain advances
ICLR_2020_2030,14603,and the authors provided good coverage of related works ..,meaningful-comparison [SEP] positive [SEP]  the authors provided coverage [SEP]  authors provided good coverage
ICLR_2020_2030,14604,it would be interesting to compare ficm against simpler exploration baselines such as epsilon greedy or entropy regularization. i d also like to see more extensive comparisons between ficm and icm across different datasets those results are not great compared to the results of episodic curiosity.,meaningful-comparison [SEP] negative [SEP]  it would be interesting [SEP]  see more extensive comparisons [SEP]  compare ficm
ICLR_2020_2030,14605,the choice of tasks where the largest improvement is shown (i.e .5 atari games) seems not well motivated and rather crafted for the proposed method ..,soundness [SEP] negative [SEP]  the choice tasks [SEP]  e i where improvement is shown 5 atari games [SEP]  the not rather crafted proposed method
ICLR_2018_761,15442,"the paper proposes a solution to an important problem of model parallel training especially over dynamic batching that is increasingly important as we see more complex models where batching is not straightforward overall it seems like a valuable area for exploration, especially given the growing interest in dynamic neural networks ..",motivation [SEP] positive [SEP]  the especially given growing interest [SEP]  paper a proposes solution [SEP]  a solution an important problem [SEP]  an important problem model parallel training [SEP]  see more complex models [SEP]  important dynamic batching is not [SEP]  it seems
ICLR_2018_761,15443,the paper can be a little dense read for the iclr audience ..,clarity [SEP] negative [SEP]  the paper can be read [SEP]  paper a can be little dense read
ICLR_2018_761,15444,paper seems to cover and contrast well with the existing approaches and is able to clarify where it differs from existing papers. the paper is clearly written and easy to follow ..,clarity [SEP] positive [SEP]  existing where differs papers [SEP]  paper seems [SEP]  the existing is approaches able
ICLR_2018_761,15445,the new approach seems to show positive results on certain dynamic neural network problems ..,soundness [SEP] positive [SEP]  the new approach seems [SEP]  show positive results
ICLR_2018_761,15446,the empirical results are less convincing. it makes the computational result less convincing ..,soundness [SEP] negative [SEP]  the empirical results less convincing [SEP]  convincing it makes [SEP]  the result convincing makes computational
ICLR_2018_761,15447,"while the paper mentions support for it, the results are only showed on a toy problem, and it is unclear that it will work well for real problems. it will be great to see more results that use multiple replicas.",substance [SEP] negative [SEP]  use multiple replicas [SEP]  a results are only showed toy problem [SEP]  will work well real problems [SEP]  results see more
ICLR_2018_761,15448,comparisons with dynet (somewhat hidden away) that offers auto batching in a dynamic mode aren't very positive ..,meaningful-comparison [SEP] negative [SEP]  comparisons dynet n't [SEP]  offers auto batching
ICLR_2018_761,15449,"so in this sense, the framework proposed by the authors is different and original ..",originality [SEP] positive [SEP]  the framework proposed
ICLR_2020_451,15480,1.lord achieves significantly better performance than the state of the art baseline on non adversarial disentanglement methods. i find the experimental results in this paper very appealing. 4 .unsupervised domain translation the result looks very good ..,soundness [SEP] positive [SEP]  the find experimental results appealing [SEP]  1 lord achieves significantly better performance [SEP]  significantly better performance the state
ICLR_2020_451,15481,2 .cost of training one thing i feel should be made more clear in the paper is the training cost of glo v. amortized i would like the authors to dig deeper into what exactly is the inductive bias conferred by latent optimization ..,soundness [SEP] negative [SEP]  the would like authors
ICLR_2020_451,15482,"authors should verify their assumption by quantitative results and illustrate the importance of inter intra class variation which only has a small handful of factors of variation anyway 3 .ablation study first, i think the authors should show us the actual visualizations for the amortized models. however, the experimentation is too limited. i recommend that the authors try at least one other dataset ..",substance [SEP] negative [SEP]  authors at try least one other dataset [SEP]  authors should verify their assumption anyway study [SEP]  a small handful factors [SEP]  authors should the show actual visualizations [SEP]  the experimentation too limited
ICLR_2020_451,15483,"some problematic claims put forth in the paper, which i worry might mislead the reader and 2) lack of clarity in describing the procedure in the unsupervised domain translation setting ..",clarity [SEP] negative [SEP]  the describing procedure [SEP]  the might mislead reader lack [SEP]  lack clarity
ICLR_2019_884,15806,"overall, this paper is well written i think figure 1 is great and helps a lot to distinguish the different domain translation paradigms ..",clarity [SEP] positive [SEP]  distinguish the different domain translation paradigms [SEP]  overall i is paper well written [SEP]  is think figure
ICLR_2019_884,15807,it would be better if the authors were a little more careful in their use of terminology here. do not make much sense and should probably be reformulated to enhance readability i found the description in section 3.1 a bit confusing as it initially seems that the approach requires paired data i think the wording is a bit too strong here ..,clarity [SEP] negative [SEP]  the not think wording is [SEP]  the authors were careful [SEP]  do not not make much sense [SEP]  the found description [SEP]  it would be better [SEP]  approach requires paired data
ICLR_2019_884,15808,and the various design choices seem well motivated.,motivation [SEP] positive [SEP]  the various design choices seem motivated
ICLR_2019_884,15809,the empirical comparisons to unit are reasonably.,meaningful-comparison [SEP] positive [SEP]  the empirical comparisons unit
ICLR_2019_884,15810,though i would have preferred more in depth evaluation of the move model as well. but it would be instructive to see the results without this additional input why not use more dimensions and project them down to 3 for visualisation and interpetation purposes with e.g .pca or t sne not matched with the practice environment ..,substance [SEP] negative [SEP]  the not matched practice environment [SEP]  i would have preferred more well [SEP]  would have more more depth evaluation [SEP]  the see results
ICLR_2019_884,15811,"unfortunately, the results are quite disappointing in terms of sound quality, and feature many artifacts. i think the choice of a 3 dimensional latent space is poorly justified. 2 the experimental settings are not reasonable.",soundness [SEP] negative [SEP]  the think choice [SEP]  the results quite disappointing [SEP]  quite disappointing terms [SEP]  i think
ICLR_2019_884,15812,"1 the implementation steps of the proposed method (move) are not clear. some details are missing, which is hardly reproduced by the other researchers. . the current experimental settings are for the model, the optimization details or inferring details are missing, which are important for the proposed model ..",replicability [SEP] negative [SEP]  the implementation steps proposed not [SEP]  the is hardly reproduced other researchers [SEP]  the proposed are model important
ICLR_2019_579,15980,the paper is well written and concise. it's organized well the paper is well written with good clarity ..,clarity [SEP] positive [SEP]  the paper well written concise [SEP]  the paper well written concise [SEP]  s organized good clarity
ICLR_2019_579,15981,"i suggest the authors to clarify this, and possibly discuss the relation with this alternative approach ..",clarity [SEP] negative [SEP]  i suggest [SEP]  suggest the authors [SEP]  the possibly discuss relation
ICLR_2019_579,15982,the various components of their model are straightforward and well motivated ..,motivation [SEP] positive [SEP]  the various components their model
ICLR_2019_579,15983,"they validate their model on multiple synthetic to real segmentation tasks, demonstrating strong performance relative to existing baselines, and they also provide a thorough ablation study showing that each of the components of their proposed model is an important part of their final product, which further convinces the reader that the model is sound ..",substance [SEP] positive [SEP]  performance relative existing baselines [SEP]  they validate model [SEP]  a also provide thorough ablation study [SEP]  the components proposed
ICLR_2019_579,15984,"a more rigorous exploration of the clustering process, such as visualizations of learned clusters and a study of how the number of clusters affects performance would serve to further validate the model it will be great if a formal sensitivity analysis on the parameters can be conducted. but a more thorough evaluation of the influence of the hyper parameters would be useful ..",substance [SEP] negative [SEP]  a more the thorough evaluation influence [SEP]  a more rigorous exploration the clustering process [SEP]  a clusters study [SEP]  how number affects performance [SEP]  the further validate model [SEP]  a be will great great formal sensitivity analysis
ICLR_2019_579,15985,this paper has a good experimental validation of proposed module. the proposed method achieves good results on standard benchmarks ..,soundness [SEP] positive [SEP]  good method achieves results [SEP]  paper a has good experimental validation [SEP]  proposed the method achieves results
ICLR_2019_579,15986,i am not convinced by the claimed relationship to methods that learn disentangled representations. i acknowledge however that their results are not as good as the one reported here.,soundness [SEP] negative [SEP]  not acknowledge however their results are [SEP]  learn disentangled representations [SEP]  i am not convinced
ICLR_2019_579,15987,the idea of using patches in domain adaptation is not completely new. the idea of relying on patches to model the structure is not new. there is some novelty in the proposed approach.,originality [SEP] negative [SEP]  some novelty proposed [SEP]  using patches [SEP]  the model structure
ICLR_2019_579,15988,modeling the structure via patches is an interesting idea ..,originality [SEP] positive [SEP]  modeling the structure [SEP]  patches an interesting idea
ICLR_2019_579,15989,"this paper should at least cite and compare this work. a major concern of this work is the lack of citation and direct comparison to multiple previous sotas. for example, the paper should compare the end system performance with several published works such as.",meaningful-comparison [SEP] negative [SEP]  several published works such [SEP]  this paper should least least cite [SEP]  this compare work [SEP]  the lack citation [SEP]  the end system performance several published
ICLR_2019_579,15990,there are some details missing in the paper too ..,replicability [SEP] negative [SEP]  some details missing [SEP]  the missing paper
ICLR_2018_515,16004,"but i found it quite hard to follow, especially section 4, which i thought was quite unstructured. also section 3 could be improved and simplified. find much difference between the generator and the discriminator of the gan the clarity of the writing could be improved grammatical and spelling mistake are frequent. in summary, the paper is not ready for publication in its current form.",clarity [SEP] negative [SEP]  quite section unstructured also [SEP]  find much difference [SEP]  spelling mistake are frequent
ICLR_2018_515,16005,"it would be also good to add some more related work. they are missing a reference to beta vae (higgins et al , 2017) when discussing vae based approaches to disentangled factor learning.",meaningful-comparison [SEP] negative [SEP]  it would be also good [SEP]  add some more related work [SEP]  a are missing reference [SEP]  vae when discussing based approaches
ICLR_2018_515,16006,"from my limited point of view, this seems like a sound, novel and potentially useful application of a interesting idea. sdr characterisation of the convolutional filters is interesting the authors show that filters with different characteristics are responsible for different aspects of image modelling cons.",originality [SEP] positive [SEP]  different characteristics responsible [SEP]  my limited point view [SEP]  seems a sound novel and potentially useful application [SEP]  a interesting idea sdr characterisation [SEP]  the authors show are
ICLR_2018_515,16007,the authors do not actually demonstrate how their analysis can be used to improve vaes or gans their proposed sdr analysis does not actually.,soundness [SEP] negative [SEP]  the authors do not not not actually demonstrate [SEP]  authors do not not not actually demonstrate their analysis [SEP]  analysis improve vaes
ICLR_2020_1602,16345,it is not clear whether the proposed labeling is a contribution from the work i understand the author's motivation for doing it.,motivation [SEP] negative [SEP]  it clear [SEP]  clear the proposed labeling [SEP]  a the proposed labeling contribution [SEP]  the understand author's motivation
ICLR_2020_1602,16346,"also, they have provided a new labelling for the mimic iii dataset, which is of great value the authors have done solid and valuable work in improving the accuracy detection. the sepsis detection problem is of paramount importance in the clinical domain and the authors rightly emphasized that point and well motivated.",motivation [SEP] positive [SEP]  authors rightly emphasized that point motivated [SEP]  have authors done solid and valuable work
ICLR_2020_1602,16347,"however, their approach is not sufficiently justified. the contributions of the present work are not sufficiently justified (labeling) the added value of the attention mechanism as a means to interpret predictions in terms of the journey of a patient is not clear. gaussian process by itself is not giving understanding nor interpretability as it is too general my main concern is the questionable role of attention in making the model more interpretable s not easy for an iclr reader without any medical background to evaluate the validity of the interpretability results provided in the paper.",soundness [SEP] negative [SEP]  their approach is not [SEP]  however the is not not not not sufficiently justified contributions [SEP]  predictions terms [SEP]  is not not giving understanding [SEP]  the my main concern questionable role [SEP]  the interpretability results provided
ICLR_2020_1602,16348,"the novelty of the proposed model is minor, relative to mgp tcn, and in terms of technical novelty and empirical evidence the paper can be further improved.",originality [SEP] negative [SEP]  the novelty proposed [SEP]  relative mgp tcn [SEP]  novelty terms technical
ICLR_2020_1602,16349,the authors should include a numerical table of their result comparison results. in terms of empirical evidence of the prediction accuracy the paper only compares with moor et al 2019 (which does not show a significant improvement in the realistic setting) and a much older insight paper (2016)..,meaningful-comparison [SEP] negative [SEP]  a paper does not not not show significant improvement [SEP]  the authors should include table [SEP]  a authors should include numerical table [SEP]  comparison results terms empirical [SEP]  terms empirical evidence [SEP]  al paper only compares et
ICLR_2020_1602,16350,they should have a more formal way to present the results and baseline comparisions as tables ..,clarity [SEP] negative [SEP]  they should have way [SEP]  should have a more formal way [SEP]  the present results
ICLR_2020_1602,16351,the paper is generally well written.,clarity [SEP] positive [SEP]  the paper is generally well written
ICLR_2020_469,16359,"conclusion overall, i like the idea of the paper the idea of converting a set of data points to one point and rehearse at a meta level is a smart and novel idea ..",originality [SEP] positive [SEP]  a a idea and meta level smart novel [SEP]  conclusion like the idea is [SEP]  a rehearse meta level
ICLR_2020_469,16360,"however, i found that the experiments of the paper where not well designed to verify the main contribution (hypernetworks), nor where they compared to the most relevant methods. 4 .also, more experiments on cifar would be welcome. 5 .i would like to see more analysis and results for the chunking ..",substance [SEP] negative [SEP]  more see analysis [SEP]  however i found experiments [SEP]  the not verify main contribution [SEP]  the where compared most relevant methods [SEP]  experiments 4 also more
ICLR_2020_469,16361,of details and additional experiments on generative models.,substance [SEP] positive [SEP]  details additional experiments
ICLR_2020_469,16362,2.i do not understand why the training is performed in two steps.,clarity [SEP] negative [SEP]  2 i do not not understand [SEP]  do not understand the training [SEP]  not why training is performed two steps
ICLR_2020_469,16363,"the work seems to be well written, and the motivation of using hypernetworks as a natural solution to avoid catastrophic loss is clearly described.",clarity [SEP] positive [SEP]  the work seems [SEP]  the motivation using hypernetworks [SEP]  using hypernetworks
ICLR_2020_469,16364,comparison with the closest methods like hat and packnet should be included.,meaningful-comparison [SEP] negative [SEP]  comparison closest methods [SEP]  comparison the closest methods
ICLR_2020_469,16365,the appendix contains a fair amount.,meaningful-comparison [SEP] positive [SEP]  the appendix contains amount [SEP]  a appendix contains fair amount
ICLR_2020_469,16366,". overall, i think this work is worthy of acceptance and should encourage more investigation into hypernetworks for cl and transfer learning going forward in the community ..",motivation [SEP] positive [SEP]  going forward the community [SEP]  overall think this is work [SEP]  worthy acceptance should encourage investigation transfer [SEP]  should encourage more investigation transfer
ICLR_2020_469,16367,"it shows significant improvement compared to baseline methods, especially for split cifar experiments ..",soundness [SEP] positive [SEP]  it shows improvement [SEP]  shows significant improvement [SEP]  compared baseline methods
ICLR_2020_467,16961,and the careful combination and integration of approaches from previous papers ..,meaningful-comparison [SEP] positive [SEP]  and the careful combination integration
ICLR_2020_467,16962,"it would be good to include a comparison to imagenet architectures that have computational and memory efficiency as a design goal. for re scaling, the authors did not give a detailed comparison between their approach and previous work, and it is not clear how the data driven way helps could you please draw a more precise comparison between ttq and your method.",meaningful-comparison [SEP] negative [SEP]  a comparison could draw more precise [SEP]  include a comparison [SEP]  a comparison scaling more precise [SEP]  a comparison authors did not not not give detailed [SEP]  their approach previous work [SEP]  it would be good not
ICLR_2020_467,16963,i believe that this is of significant practical importance to the field. this is very useful ..,motivation [SEP] positive [SEP]  i believe is [SEP]  significant practical importance the field
ICLR_2020_467,16964,"additionally, the specific choices for the new student teacher loss, and new scaling network architecture, seem fairly ad hoc. why the proposed methods would help increase the performance gain is not well demonstrated ..",soundness [SEP] negative [SEP]  the increase performance gain [SEP]  the specific choices new loss [SEP]  additionally choices new scaling network architecture seem [SEP]  the why proposed methods would help not
ICLR_2020_467,16965,"the experimental results seem promising. the outcome of the model is quite impressive 5 the strong baseline outperforms existing methods, which is impressive in itself ..",soundness [SEP] positive [SEP]  strong baseline outperforms existing methods [SEP]  the experimental results seem [SEP]  the promising outcome [SEP]  the is outcome model impressive
ICLR_2020_467,16966,very nice on the ablation studies the claims are supported by a comparison with a great variety of baselines and an ablation study ..,substance [SEP] positive [SEP]  a claims are supported comparison [SEP]  a a comparison great variety
ICLR_2020_467,16967,"however, the novelty of the paper is limited and.",originality [SEP] negative [SEP]  the the novelty paper
ICLR_2020_467,16968,"the authors introduce a novel layer wise objective that pushes the binary activations to match the real activations, which are given by a teacher model (real to binary)..",originality [SEP] positive [SEP]  a are given teacher model [SEP]  the authors introduce objective [SEP]  a authors introduce novel layer wise objective
ICLR_2020_467,16969,"the writing of the paper needs improvement. some notations need to be defined or clarified. however, the paper could be easier to read and some points remain unclear 1. 2 .the equation 2. is intuitive yet not perfectly clear ..",clarity [SEP] negative [SEP]  the the writing paper [SEP]  need some notations [SEP]  the writing paper needs improvement
ICLR_2020_467,16970,argumentation the paper clearly states the problem and what are the contributions ..,clarity [SEP] positive [SEP]  the are contributions [SEP]  argumentation the paper [SEP]  the paper clearly states problem
ICLR_2020_467,16971,and the methodology part in section 4 requires more details ..,replicability [SEP] negative [SEP]  the methodology part section [SEP]  part requires more details
ICLR_2018_21,17284,one of the main problems with imitation learning in general is the expense of expert demonstration the authors should consider exploring and discussing the effects of adding moving removing objects on the performance ..,substance [SEP] negative [SEP]  the discussing effects [SEP]  moving removing objects
ICLR_2018_21,17285,"the experiments show clearly that a) the components of the proposed pipeline are important since they outperform ablated versions of it and b) the system and its experiments show the effectiveness of the method i am very happy to see experimental evaluations on real robots, and even in two different application domains.",substance [SEP] positive [SEP]  see experimental evaluations [SEP]  the experiments show clearly are [SEP]  the components proposed [SEP]  the the effectiveness method
ICLR_2018_21,17286,in the rope knot tying task no slam based or other classical baselines are mentioned. it is difficult to compare the goal image and the video otherwise ..,meaningful-comparison [SEP] negative [SEP]  the compare goal image otherwise [SEP]  based other classical baselines
ICLR_2018_21,17287,the nice part of doing rl is that it provides ways of actively controlling the exploration. this line of work is specially relevant since it attacks one of the main bottlenecks in learning complex tasks learning both inverse and forward models is very effective.,motivation [SEP] positive [SEP]  learning complex tasks [SEP]  it provides ways [SEP]  the main bottlenecks learning tasks
ICLR_2018_21,17288,the relevance of the method to achieve a deeper sense of learning and performing more complex tasks is however unclear to me.,motivation [SEP] negative [SEP]  me however unclear [SEP]  the the relevance method [SEP]  a achieve deeper sense [SEP]  performing more complex tasks
ICLR_2018_21,17289,it should help make it clearer in the paper as well ..,clarity [SEP] negative [SEP]  it should help [SEP]  it should help [SEP]  make clearer the paper
ICLR_2018_21,17290,the paper is well written and clear to understand. the paper is easy to read the paper is well written and easy to follow ..,clarity [SEP] positive [SEP]  the paper well written clear [SEP]  the paper well written clear [SEP]  the paper well written clear
ICLR_2018_21,17291,but it is original afaik. the idea of learning the basic relations between actions and state through self exploration is definitely interesting. i think the paper presents an interesting idea which should be exposed to the community ..,originality [SEP] positive [SEP]  the learning basic relations [SEP]  the basic relations actions [SEP]  i think [SEP]  the think paper [SEP]  idea an interesting paper presents
ICLR_2018_21,17292,is better than previous work in those tasks negative aspects the proposed approach is well founded and the experimental evaluations are promising ..,soundness [SEP] positive [SEP]  the well founded experimental evaluations [SEP]  is better better previous work aspects [SEP]  those tasks negative aspects
ICLR_2018_21,17293,my main criticism to the paper is that the task learning achieved through self exploration seems relatively shallow another aspect that worries me about the system is how it can be extended to higher dimensional action spaces ..,soundness [SEP] negative [SEP]  how can be extended higher dimensional action spaces [SEP]  the task learning achieved [SEP]  is learning self exploration seems shallow
ICLR_2020_1025,17381,while the motivation and task setup is interesting the problem studied in this work is very interesting and important ..,motivation [SEP] positive [SEP]  motivation task setup is interesting [SEP]  studied this work
ICLR_2020_1025,17382,the paper is clearly unfinished ..,motivation [SEP] negative [SEP]  the paper clearly unfinished
ICLR_2020_1025,17383,we also need to see more details about where responses are retrieved from. to many such important details are missing. the related work does not provide details as to how the proposed model.,replicability [SEP] negative [SEP]  details the work does not not not provide how proposed model [SEP]  we also need [SEP]  details are many such important missing [SEP]  details are missing the related work not
ICLR_2020_1025,17384,there are many spelling grammar mistakes this paper is clearly not ready to submit as it contains a lot of grammar errors and lacks a lot of important details. there are too many such language errors in this paper. 2.2 table 2 is not finished yet the paper studies an interesting task however it is not ready for publication to prior work the figures are difficult to understand the manuscript should be carefully copy edited.,clarity [SEP] negative [SEP]  the understand manuscript [SEP]  lot lacks important details [SEP]  many errors important details too such language [SEP]  publication prior work
ICLR_2020_1025,17385,the high level idea also looks interesting ..,originality [SEP] positive [SEP]  the high level idea also looks interesting
ICLR_2020_1025,17386,empirical results of all baselines are missing (table 2.,substance [SEP] negative [SEP]  empirical results all baselines
ICLR_2020_786,17937,this paper should be rejected because it lacks originality.,originality [SEP] negative [SEP]  this paper should be rejected [SEP]  it lacks originality [SEP]  lacks originality
ICLR_2020_786,17938,"the assumptions are often too strong, and the rigor of some claims is questionable. the main reason is that the second part of the paper is not rigorous this statement in the introduction is not only incorrect but it is absurd ..",soundness [SEP] negative [SEP]  the assumptions too strong [SEP]  rigor some claims is questionable [SEP]  the rigor is questionable questionable main reason [SEP]  the the main reason second part not [SEP]  not rigorous this statement
ICLR_2020_786,17939,"but those works give rigorous proofs of their claims and even handle issues like step size, convergence rates, and precise conditions on the size and architecture of the neural network ..",soundness [SEP] positive [SEP]  works give rigorous proofs [SEP]  even handle issues [SEP]  convergence rates precise conditions [SEP]  the size precise conditions
ICLR_2020_786,17940,"as explained above, many details are omitted in favor of strong assumptions, but there are also some technical details that i think may be wrong ..",replicability [SEP] negative [SEP]  many details are [SEP]  details some technical think [SEP]  i think
ICLR_2020_786,17941,i saw a few spelling and grammatical errors. it is not clear what results are actually presented here nor how their results relate to other theoretical analyses of nns. unclear from the notation and definitions ..,clarity [SEP] negative [SEP]  results how their relate [SEP]  saw a few spelling [SEP]  clear results are actually presented
ICLR_2020_786,17942,while the analysis of nns is an extremely important problem.,motivation [SEP] positive [SEP]  the analysis nns [SEP]  an nns extremely important problem
ICLR_2020_1446,18064,"there are many grammar errors and typos in the current manuscript but overall, the paper is not well written 4 .i might be wrong but i didn t see any figures referenced in the main body. please add references and organize them better the written is poor, such as figure 6 table in the way it is presented, it is not clear contribution of the top part of figure 1 in proposed pipeline is not clear. table 2 is hard to interpret, improve the discussions regarding it. and should be re written. some references to the tables are wrong or some are missing , 4.7) paper contains several typos and grammatical mistakes. most of the points were not explained well ..",clarity [SEP] negative [SEP]  are many grammar errors [SEP]  i might be wrong wrong [SEP]  not add references [SEP]  the written poor [SEP]  the clear contribution top part [SEP]  the references some tables [SEP]  are typos paper contains several [SEP]  not not grammatical mistakes most explained
ICLR_2020_1446,18065,"some ablation study whether or not the normalization is missing. should be discussed and compared with ddl performing better than soa. in other words, the experimental analysis should be extended. one thing authors should consider is including more datasets, especially more challenging datasets i.e. , the ones not already saturated. i do not find using youtube face benchmark suitable as it is already saturated.",substance [SEP] negative [SEP]  not it using suitable [SEP]  ddl performing better [SEP]  other words experimental analysis [SEP]  is including more datasets ones
ICLR_2020_1446,18066,the implementation details of the proposed framework are unclear. and reproducible.,replicability [SEP] negative [SEP]  the implementation details proposed
ICLR_2020_1446,18067,the experimental results are comprehensive and convincing. the idea is simple yet interesting and the results are good support your statements with references and appropriate experimental analysis.,soundness [SEP] positive [SEP]  good support your statements [SEP]  the experimental results are comprehensive [SEP]  the convincing idea [SEP]  the results yet interesting
ICLR_2020_1446,18068,the methodology explained in section 3 should be improved. subsections 3.2 3.4 do not contain enough explanation to support equation of proposed method. it is not possible to figure out if the proposed method is really to better understand the necessity and effectiveness of proposed ddl more discussion is needed about that table.,soundness [SEP] negative [SEP]  do subsections not not not contain enough explanation [SEP]  support equation [SEP]  the method not proposed it [SEP]  the method not proposed is figure [SEP]  the better understand necessity
ICLR_2020_1446,18069,the novelty of the algorithm is limited it is hard to observe the contribution of ddl in terms of the performance.,originality [SEP] negative [SEP]  ddl terms [SEP]  it limited [SEP]  the observe contribution
ICLR_2020_1446,18070,"you should compare the performance with your methods of training under the manually designed features. the related work section should include studies more related to the motivation behind ddl .to select represent samples from the whole set efficiently for group understanding. therefore, many related works are missing. the experimental analysis should include comparisons with methodologies such as quality learning via attention mechanism, etc ..",meaningful-comparison [SEP] negative [SEP]  should compare the performance [SEP]  the performance your methods [SEP]  should section include studies [SEP]  are related therefore many works missing [SEP]  are the therefore works missing experimental analysis
ICLR_2020_2009,18286,this topic is actually very interesting so i enjoyed reading the paper.,motivation [SEP] positive [SEP]  this topic very interesting [SEP]  i is so enjoyed [SEP]  reading the paper
ICLR_2020_2009,18287,"some unclear points that need further clarification i fail to understand how is this related to q (attacker) in my perspective, the title is very misleading and does not properly justify the claims made in this paper. the paper is a bit difficult to understand (also not well structured)..",clarity [SEP] negative [SEP]  need further clarification [SEP]  the my perspective title [SEP]  this made paper
ICLR_2020_2009,18288,"2 .it is also very unclear how unrestricted attack plays a role in the studied problem. therefore, the performance evaluation is not fully justified. 2 .the results are not really validating the points they make in the analysis just claiming that none of the existing methods would work for unrestricted attacks will not work is not sufficient.",soundness [SEP] negative [SEP]  unrestricted none would work attacks [SEP]  2 is the therefore evaluation not not not not not fully justified results [SEP]  the not not not not results are really validating points [SEP]  the make analysis [SEP]  not just claiming none
ICLR_2020_2009,18289,3 .only two black box attacks were compared in this paper but some sort of empirical comparison with other certified defense strategies is necessary.,meaningful-comparison [SEP] negative [SEP]  3 only two black box attacks were compared [SEP]  attacks were compared this paper [SEP]  is sort other certified defense strategies necessary
ICLR_2020_2009,18290,the specific contributions are not quite clear with respect to the existing literature.,originality [SEP] negative [SEP]  the specific contributions not not quite clear [SEP]  clear respect existing
ICLR_2020_1042,18713,some details are not well specified clear in the work how this is accomplished.,replicability [SEP] negative [SEP]  some details are not well specified clear [SEP]  are well specified clear clear the work
ICLR_2020_1042,18714,"there is the possibility of testing different methods on own datasets. similarly, i would wish to maintain similar training and evaluation conditions for my model.",substance [SEP] negative [SEP]  similar maintain training and evaluation conditions [SEP]  the possibility testing methods [SEP]  testing different methods [SEP]  i similarly would wish
ICLR_2020_1042,18715,i find the experiments in sections 4.2 and 4.3 interesting.,substance [SEP] positive [SEP]  i find experiments interesting [SEP]  find the experiments interesting
ICLR_2020_1042,18716,i would also like to understand whether or not this is feasible and easy given the system's design. this experiment does not add any value to the paper ..,soundness [SEP] negative [SEP]  i would also like [SEP]  the not given system's design [SEP]  not not not experiment does add any value
ICLR_2020_1042,18717,and the results are supportive of the claims of the system's usefulness ..,soundness [SEP] positive [SEP]  the results supportive [SEP]  the supportive claims
ICLR_2020_1042,18718,"to me, the takeaway that pre processing is important and existing models are sensitive to pre processing is not a new finding ..",originality [SEP] negative [SEP]  me the takeaway [SEP]  pre processing is important [SEP]  a are sensitive sensitive not not new finding
ICLR_2020_1042,18719,"generally, i believe that the work is well motivated and timely.",motivation [SEP] positive [SEP]  generally i believe is [SEP]  generally believe the work is
ICLR_2020_1042,18720,the authors seem to have done a good job in citing related work.,meaningful-comparison [SEP] positive [SEP]  the authors seem [SEP]  a have done good job [SEP]  citing related work
ICLR_2018_64,19185,"the paper is clear, this article is really well written and clearly describes the proposed scheme. the paper is generally easy to follow.",clarity [SEP] positive [SEP]  the paper clear [SEP]  clear this article [SEP]  the clearly describes proposed scheme
ICLR_2018_64,19186,although there are many english mistakes but in several places the presentation can be further improved ..,clarity [SEP] negative [SEP]  many english mistakes several places
ICLR_2018_64,19187,the new method is motivated well and departs from prior.,motivation [SEP] positive [SEP]  the new method is motivated well departs [SEP]  method is motivated well departs
ICLR_2018_64,19188,the analysis of the results is interesting and largely convincing demonstrate solid positive results cons.,soundness [SEP] positive [SEP]  the the analysis results [SEP]  largely convincing demonstrate
ICLR_2018_64,19189,the paper also provides an interesting analysis of various design issues ..,substance [SEP] positive [SEP]  the paper also provides analysis [SEP]  paper also provides an interesting analysis
ICLR_2018_64,19190,this paper seems to me like an interesting and significant contribution ..,originality [SEP] positive [SEP]  this paper seems [SEP]  paper seems me [SEP]  paper seems an interesting and significant contribution
ICLR_2018_64,19191,"although the idea seems incremental, the experimental results do seem solid. the idea seems incremental 2.",originality [SEP] negative [SEP]  the idea seems incremental [SEP]  the idea seems incremental
ICLR_2020_1039,19345,these design choices are reasonably explained and the empirical gains due to these design choices are well documented (table 2 significant empirical advance.,soundness [SEP] positive [SEP]  these design choices are [SEP]  the choices are reasonably explained empirical gains [SEP]  these design choices are
ICLR_2020_1039,19346,2 .it is also unclear what kind of theoretical guarantees the proposed method could deliver. it seems that the adversarial training designed in ganite and consequently drgan provide no advantage in terms of accurate estimation of counterfactuals s estimation of the counterfactual outcome do improve prediction of the administered treatment i.e..,soundness [SEP] negative [SEP]  unclear what kind deliver [SEP]  it seems [SEP]  training provide no advantage [SEP]  terms accurate estimation [SEP]  the counterfactual outcome do improve prediction
ICLR_2020_1039,19347,good experiments in general ..,substance [SEP] positive [SEP]  good experiments general
ICLR_2020_1039,19348,novel neural network architectures used with counterfactual generator and counterfactual discriminator are interesting and these can be extended to other tasks.,originality [SEP] positive [SEP]  novel neural network architectures used [SEP]  used counterfactual generator [SEP]  can be extended other tasks
ICLR_2020_1039,19349,is there sufficient novelty in what they propose this paper falls under incremental improvement as it improves ganite framework to solve dose response estimation. as authors use gan for counterfactual estimation which is not novel (ganite) and estimating dose response estimation is not novel (.,originality [SEP] negative [SEP]  solve dose response estimation
ICLR_2020_1039,19350,yes it s useful for the community as this is a challenging problem and estimating dose response from observational data while this is a very interesting task.,motivation [SEP] positive [SEP]  s it useful [SEP]  s useful useful the community [SEP]  a is challenging problem
ICLR_2020_1039,19351,any odd design choices in the algorithm not explained well.,replicability [SEP] negative [SEP]  any odd design choices the algorithm not
ICLR_2020_1039,19352,the overall flow of the paper is a little hard to follow ..,clarity [SEP] negative [SEP]  the the overall flow paper
ICLR_2018_296,19639,theoretical contributions none. while the use of such convex combination (mixing features) is not new.,originality [SEP] negative [SEP]  the use such combination not [SEP]  mixing features not
ICLR_2018_296,19640,while the idea of mixing not only features but also labels is new and interesting.,originality [SEP] positive [SEP]  the idea mixing features [SEP]  mixing not only features [SEP]  labels new
ICLR_2018_296,19641,"moreover, there is no clear theoretical explanation for why this approach ought to work. and labels this way is a good approach. the authors motivate the proposed approach in the context of vicinal risk minimization, but the proposed approach is not well supported by theory. but it is not sufficiently convincing to me why a convex combination in euclidean space should produce good data distribution. the lack of sufficient theoretical justification and it will motivate more theoretical work.",soundness [SEP] negative [SEP]  why good not combination should produce data distribution [SEP]  moreover is no clear theoretical explanation [SEP]  the approach authors motivate proposed not [SEP]  well supported theory [SEP]  not sufficiently convincing me
ICLR_2018_296,19642,good results across the board. easy to implement. convincing theoretical arguments for why combining data a concrete strategy for obtaining good results using the proposed method. is now well complemented by extensive experiments.,soundness [SEP] positive [SEP]  is well complemented extensive experiments [SEP]  good results the board [SEP]  convincing theoretical arguments [SEP]  why combining data strategy [SEP]  a data concrete strategy [SEP]  the using proposed method
ICLR_2018_296,19643,"experiment hyperparameters are meticulously recorded in the paper a thorough discussion on mixing in feature space, as well as a baseline which mizes in feature space ..",substance [SEP] positive [SEP]  mixing feature space [SEP]  experiment hyperparameters are meticulously recorded discussion [SEP]  a the paper thorough discussion
ICLR_2018_296,19644,i enjoyed reading this well written and easy to follow paper ..,clarity [SEP] positive [SEP]  i enjoyed [SEP]  follow paper
ICLR_2018_296,19645,"this notion is definitely of interest to machine learning, and to the iclr community in particular.",motivation [SEP] positive [SEP]  this notion interest [SEP]  the iclr community particular
ICLR_2018_296,19646,and this should be compared against the proposed approach of mixing both features and labels.,meaningful-comparison [SEP] negative [SEP]  should be compared the proposed approach [SEP]  mixing both features
ICLR_2020_1553,19931,"the writing (including language etc) is of poor quality with unusual expressions, missing punctuations and wongly used words. given the poor writing and organization but the paper lacks in presentation.",clarity [SEP] negative [SEP]  paper lacks presentation [SEP]  the writing including [SEP]  poor quality unusual expressions [SEP]  the writing poor given [SEP]  the paper lacks
ICLR_2020_1553,19932,"and the derivation is of poor quality and sufficient empirical evidence is also lacking to get fully convinced by the claims. the authors should discuss the architecture design choices used for the synthetic data generating model. while it is a possibility, the amount of empirical evidence presented does not (at least to me) provide strong enough justification. i don't think this experiment is sufficiently large to convince me. i think the amount of empirical evidence you provide is insufficient to back the claims. i believe that the lack of a greater amount of empirical evidence is a significant deficiency of your otherwise very interesting work ..",soundness [SEP] negative [SEP]  a significant deficiency otherwise very interesting work [SEP]  the authors should discuss architecture design choices [SEP]  the used synthetic data generating model [SEP]  does provide strong enough justification [SEP]  do think this experiment [SEP]  a the possibility amount [SEP]  you insufficient back [SEP]  the fully convinced claims [SEP]  the is lack believe [SEP]  a the lack amount greater [SEP]  sufficient empirical evidence evidence
ICLR_2020_1553,19933,it is hard to observe anything new.,originality [SEP] negative [SEP]  it hard
ICLR_2020_1553,19934,i like the general idea of the paper and.,originality [SEP] positive [SEP]  i like idea [SEP]  like the general idea
ICLR_2020_1553,19935,it is hard to miss closely related works by simple searching.,meaningful-comparison [SEP] negative [SEP]  it hard [SEP]  miss closely related works
ICLR_2020_1553,19936,appreciate the very detailed exposition placing it in the context of other works ..,meaningful-comparison [SEP] positive [SEP]  appreciate the very detailed exposition [SEP]  it placing [SEP]  the placing context other
ICLR_2020_1553,19937,the motivation and the theoretical arguments are interesting.,motivation [SEP] positive [SEP]  the motivation theoretical arguments
ICLR_2020_1553,19938,in general i would like to see experiments on datasets and with architectures that are at least somewhat close to what people use in practice (at least in terms of the size of the task and the capacity of the net.,substance [SEP] negative [SEP]  see experiments [SEP]  terms the size
ICLR_2019_1031,20912,2.the novelty of the model gan models with multiple g ds or local global discriminators is not novel (see the references although the approach is not very novel by itself.,originality [SEP] negative [SEP]  2 the the novelty model gan models not [SEP]  novel novelty g multiple ds or local global discriminators is not not not [SEP]  the not see references
ICLR_2019_1031,20913,", the adaption and combination of existing methods for the proposed solution is interesting ..",originality [SEP] positive [SEP]  the adaption combination [SEP]  combination existing methods
ICLR_2019_1031,20914,3.do you have ablation study on the effects of conditional gan and compression part to the model i would like to request some more analysis of this or ablation study on different terms ..,substance [SEP] negative [SEP]  you have study [SEP]  have ablation study [SEP]  request some more analysis
ICLR_2019_1031,20915,"comprehensive set of results with kodak, raise1k and cityscapes datasets.",substance [SEP] positive [SEP]  comprehensive set results [SEP]  results cityscapes datasets
ICLR_2019_1031,20916,discrete latent variable is in itself an interesting problem.,motivation [SEP] positive [SEP]  discrete latent variable interesting problem [SEP]  itself interesting problem [SEP]  discrete latent variable an interesting problem
ICLR_2019_1031,20917,i'm not fully convinced by the claim of the noise that this paper uses to combine the code can act as a regularizer ..,soundness [SEP] negative [SEP]  i m not not not fully convinced [SEP]  m not not fully convinced the claim [SEP]  this paper uses
ICLR_2019_1031,20918,the reported compression results with a gan based framework for large images are impressive.,soundness [SEP] positive [SEP]  the reported compression results a gan based framework
ICLR_2019_1031,20919,the paper is well written with the core results and idea being well articulated cons.,clarity [SEP] positive [SEP]  the paper is well written [SEP]  idea being cons [SEP]  well idea being articulated cons
ICLR_2019_1031,20920,the quality metrics are unclear esp.,replicability [SEP] negative [SEP]  the quality metrics unclear
ICLR_2019_187,21151,"description of the reward is a bit unclear as well, especially when the model is trained without stop action ..",clarity [SEP] negative [SEP]  description the reward [SEP]  the is especially when model trained [SEP]  stop action
ICLR_2019_187,21152,the paper is very well written and it is clear what the authors did ..,clarity [SEP] positive [SEP]  the paper is [SEP]  is clear what [SEP]  the authors did
ICLR_2019_187,21153,"the approach seems sound, and the proposed method outperforms mnih 2016 by a significant margin the general ideas are reasonable. the experimental protocol is sound and uses recent best practices ..",soundness [SEP] positive [SEP]  uses recent best practices [SEP]  the approach seems sound are [SEP]  the approach sound sound proposed method outperforms [SEP]  a significant margin general ideas [SEP]  the reasonable experimental protocol
ICLR_2019_187,21154,"and while it combines two existing approaches (actor critic reinforcement learning for navigation, and belief propagation using graph convolution networks) is sufficiently novel to be of interest to at least some members of the community ..",originality [SEP] positive [SEP]  combines two existing approaches belief [SEP]  two existing approaches actor critic reinforcement learning
ICLR_2019_187,21155,the experimental evaluation is good a good ablation study is provided ..,substance [SEP] positive [SEP]  the experimental evaluation good [SEP]  a is good good ablation study provided
ICLR_2019_187,21156,and what the gcn is expected to do.,replicability [SEP] negative [SEP]  the gcn is expected
ICLR_2018_556,21179,while the idea is sound.,soundness [SEP] positive [SEP]  the idea sound
ICLR_2018_556,21180,many design choices of the system is questionable. more discussion is needed about the role of edges in e. equation 3 sparsifies (i.e .prunes the edges) of a graph namely.,soundness [SEP] negative [SEP]  many design choices the system [SEP]  the edges 3 sparsifies
ICLR_2018_556,21181,"the problem is particularly aggravated by the poor presentation of the paper, creating countless confusions for readers. the description of the architecture is confusing with design choices never clearly explained. the work has too many gaps for the reader to fill in. the paper organization needs work there are also some missing pieces to put the nn training together ..",clarity [SEP] negative [SEP]  the problem is particularly aggravated poor presentation [SEP]  the readers description [SEP]  confusing confusing design choices never never never never never clearly explained [SEP]  the paper work organization needs [SEP]  work has gaps
ICLR_2018_556,21182,"the evaluation remains superficial with minimal quantitative comparisons. there are many such ideas now on arxiv but it would be unfair to contrast this approach with unpublished work thus, the comparisons in tables 2 and 3 are not fair ..",meaningful-comparison [SEP] negative [SEP]  the comparisons tables not [SEP]  evaluation remains superficial superficial minimal quantitative comparisons [SEP]  are many such ideas now [SEP]  it would be unfair [SEP]  contrast this approach thus
ICLR_2018_556,21183,i am not sure how this is achieved in this work ..,replicability [SEP] negative [SEP]  i not not sure achieved [SEP]  how this is achieved work
ICLR_2018_556,21184,"the work proposes an interesting approach first cluster the network, then learning distinct gans over each cluster ..",originality [SEP] positive [SEP]  the work proposes approach cluster [SEP]  work proposes an interesting approach cluster [SEP]  learning distinct gans
ICLR_2018_556,21185,"there is no contribution in the gan neural network aspect. the contribution for iclr is rather minimal, unfortunately ..",originality [SEP] negative [SEP]  the no contribution gan neural network aspect [SEP]  the the contribution gan neural network aspect [SEP]  iclr rather minimal
ICLR_2018_556,21186,also unclear whether the model generalizes. no analysis is reported on how these affect the performance of gti ..,substance [SEP] negative [SEP]  the model generalizes [SEP]  model generalizes no analysis [SEP]  the how affect performance
ICLR_2018_556,21187,"generating graphs is an important task in in relational learning tasks, drug discovery, and in learning to generate new relationships from knowledge bases ..",motivation [SEP] positive [SEP]  generate new relationships [SEP]  generating graphs an important task [SEP]  relational learning tasks drug discovery
ICLR_2018_556,21188,"the work itself, however, falls short of the goal ..",motivation [SEP] negative [SEP]  the work however falls short [SEP]  the work however falls short short goal
ICLR_2019_621,21676,the paper is quite well written and easily readable. great work on explaining the motivation and the model the writing is clear and explains background knowledge extremely well. this is a well written paper.,clarity [SEP] positive [SEP]  well explains background knowledge [SEP]  the paper is well written readable [SEP]  the explaining motivation [SEP]  the the model writing
ICLR_2019_621,21677,clear to me where the limitation of fixed code length come into play from the architecture.,clarity [SEP] negative [SEP]  where limitation come play [SEP]  clear me come [SEP]  where limitation fixed code length come
ICLR_2019_621,21678,"however, i am uncertain about the novelty of this contribution. but the novelty is not apparent but hardly novel ..",originality [SEP] negative [SEP]  i uncertain [SEP]  uncertain the novelty [SEP]  uncertain the novelty not
ICLR_2019_621,21679,"the mutual information maximization approach is appropriate ,.",originality [SEP] positive [SEP]  the mutual information maximization approach appropriate
ICLR_2019_621,21680,"it strikes me that the main contribution of this work would be in comparing against the current best techniques for coding but doesn't do much better than a vaeldpc baseline comparing its performance on omniglot and celeba datasets is unfair wouldn't it be fairer towards ldpc to compare necst to a vaeldpc code with various amounts of redundancy could the authors please justify comparing runtime only against a fixed 50 iterations of ldpc, rather than comparing against a range of possible values to make sure they are giving ldpc the benefit of the doubt.",meaningful-comparison [SEP] negative [SEP]  the comparing current best techniques [SEP]  a vaeldpc compare necst code [SEP]  a vaeldpc code various amounts [SEP]  could authors justify runtime [SEP]  a range possible values [SEP]  make sure sure they
ICLR_2019_621,21681,"however, the experiments section is weak, and does not provide significant evidence that the necst and the experimental results are weak, and so i am not convinced this is suitable for iclr however, i find the paper quite limited both in terms of modeling choices as well as evaluation methodology. . the experimental setup is somewhat niche it's usually rather hard to reproduce results to help further research on this topic.",substance [SEP] negative [SEP]  help further research [SEP]  the experiments section weak [SEP]  does not not provide significant evidence [SEP]  the weak necst experimental results are [SEP]  the find paper [SEP]  terms modeling [SEP]  terms modeling choices [SEP]  the experimental setup somewhat niche
ICLR_2019_621,21682,model is better than the alternatives. it is unclear why adding random noise to the inputs would significantly improve some of the weaker classifiers. the authors however do not discuss why one should optimize for mutual information compared to marginal log likelihood. i find the claim that the model is competitive against industry standard compression hardly justified based on the presented data ..,soundness [SEP] negative [SEP]  the based presented data [SEP]  model is better better the alternatives [SEP]  do authors however not not not discuss one [SEP]  mutual information compared [SEP]  the find claim
ICLR_2019_621,21683,the method and results are good. this is very good results ihmo ..,soundness [SEP] positive [SEP]  the method results good very [SEP]  results good good very
ICLR_2019_621,21684,so that it's unclear why this particular case of joint source channel coding would be practically relevant.,motivation [SEP] negative [SEP]  it unclear [SEP]  unclear this particular case
ICLR_2019_621,21685,i really strongly advise the authors to provide fully reproducible code for this paper.,replicability [SEP] negative [SEP]  i really strongly advise authors [SEP]  really strongly advise the authors [SEP]  provide fully reproducible code
ICLR_2020_470,22030,"this observation deserves to be further explored and may be a key to a deeper understanding of neural networks overall, the reviewer believes that this work is a solid contribution to the ib principle ,.",motivation [SEP] positive [SEP]  this a work solid contribution [SEP]  is the reviewer believes [SEP]  this is work reviewer believes
ICLR_2020_470,22031,"however, i found that the motivation of this paper is not very clear ..",motivation [SEP] negative [SEP]  however i found is [SEP]  however found the motivation is not
ICLR_2020_470,22032,and thorough proofs are given.,meaningful-comparison [SEP] positive [SEP]  thorough proofs are given
ICLR_2020_470,22033,the experiments matches the theoretical findings ..,soundness [SEP] positive [SEP]  the experiments matches findings [SEP]  the experiments matches theoretical findings
ICLR_2020_470,22034,the quality of the mathematical statements is not satisfactory and can be largely improved.,soundness [SEP] negative [SEP]  the quality mathematical statements not
ICLR_2020_470,22035,"the paper is well organized. the problem formulation, definition, theorem, algorithm and application form a whole story about finding ib phase transition it is important to have good formulations and clear statements ..",clarity [SEP] positive [SEP]  the paper well organized [SEP]  form formulation application story [SEP]  a form formulation whole story
ICLR_2020_320,22185,"after reading the paper, i am left a little unsure of what to make of the results ..",clarity [SEP] negative [SEP]  reading the paper [SEP]  a am left little unsure [SEP]  the make results
ICLR_2020_320,22186,"i especially enjoyed the writing, the problem statement and exposition were clear and easy to follow. the paper is clearly written and is easy to follow for the most part ..",clarity [SEP] positive [SEP]  the paper is clearly written most part [SEP]  especially enjoyed the writing [SEP]  the the writing problem statement
ICLR_2020_320,22187,"i would further like to know how the authors would deal with scalability issues if their analysis were to applied to more realistic (i.e .large) network architectures because the paper relies on geometrical reasoning, i wished there would be more visualisations that guide the reader ..",substance [SEP] negative [SEP]  would how authors deal scalability issues [SEP]  their analysis were [SEP]  i e applied more realistic large network architectures [SEP]  paper relies geometrical reasoning [SEP]  i would further like
ICLR_2020_320,22188,authors hope that their work will enable new ways of analysing ddns that will inspire new architectures and optimization techniques. the implications of linear regions on adversarial robustness can have an impact in the future ..,motivation [SEP] positive [SEP]  an implications can have impact [SEP]  authors hope their work [SEP]  work will enable new ways
ICLR_2020_442,22332,this makes a lot of sense especially given that cpc.,soundness [SEP] positive [SEP]  makes a lot [SEP]  especially given that cpc
ICLR_2020_442,22333,"i think this paper presents a useful contribution as far as improving speech phoneme recognition using self supervised learning goes, and also has useful engineering aspects in terms of combining cpc and bert. though rather dense in its exposition, this paper is an interesting contribution to the area of self supervised learning based on discrete representations ..",motivation [SEP] positive [SEP]  i think [SEP]  paper a presents useful contribution far [SEP]  improving speech phoneme recognition [SEP]  useful also has engineering aspects [SEP]  think this paper [SEP]  contribution the interesting area [SEP]  using self learning
ICLR_2020_442,22334,the motivation is weak or not exactly clear.,motivation [SEP] negative [SEP]  the motivation weak
ICLR_2020_442,22335,"the idea, which combines those of previous work (wav2vec and bert) synergetically, is intuitive this paper can be situated as a new contribution combining these two strands of research.",originality [SEP] positive [SEP]  the idea combines synergetically [SEP]  previous work wav2vec [SEP]  a new contribution combining strands
ICLR_2020_442,22336,some parts of the paper is not described in enough detail and.,clarity [SEP] negative [SEP]  some parts the paper not [SEP]  parts is not not described enough detail
ICLR_2020_442,22337,the main weakness of the paper is that it does not situate itself within existing literature in this area ..,meaningful-comparison [SEP] negative [SEP]  the the main weakness paper [SEP]  does not not situate itself
ICLR_2020_1031,22564,"however, it is very hard to verify the expected curvature assumption, and thus the theoretical results may be invalid. it is unclear what kind of loss functions will satisfy this assumption. 2 .again it is unclear how large will be compared to and thus the theoretical results can be useless. the reason and whether it is applied to other sgd method is not clear ..",soundness [SEP] negative [SEP]  verify the expected curvature assumption [SEP]  unclear what kind [SEP]  assumption kind will satisfy this [SEP]  the thus thus theoretical results may be invalid [SEP]  the be useless reason not
ICLR_2020_1031,22565,6 .the contribution of the current paper is very incremental ..,originality [SEP] negative [SEP]  6 the contribution current paper
ICLR_2020_1031,22566,using expected curvature is a pretty interesting idea novel utility analysis by taking the noise into account they obtain a better utility which is an interesting contribution.,originality [SEP] positive [SEP]  interesting utility an better contribution [SEP]  a is pretty interesting idea novel utility analysis [SEP]  a utility obtain better
ICLR_2020_1031,22567,"7 .there are several gradient perturbation based dp algorithms 1,2 for solving high dimensional problems are missing in the related work ..",substance [SEP] negative [SEP]  the are missing related work [SEP]  several gradient perturbation based [SEP]  solving high dimensional problems
ICLR_2020_1031,22568,the paper is well written and easy to follow ..,clarity [SEP] positive [SEP]  the paper well written easy
ICLR_2020_1031,22569,i didn t see typos or mistakes.,clarity [SEP] negative [SEP]  i see typos [SEP]  didn t see typos [SEP]  see typos
ICLR_2019_890,22618,"i think the work is quite novel, intuitively i like the idea of denoising. and the main idea is rather interesting and the idea is novel (to me) and worthy of exploration ..",originality [SEP] positive [SEP]  worthy exploration [SEP]  think the work is [SEP]  i think is [SEP]  the intuitively like idea
ICLR_2019_890,22619,and it also connects to bodies of literature.,meaningful-comparison [SEP] positive [SEP]  it also connects
ICLR_2019_890,22620,experiments should be comparisons to other denoising.,meaningful-comparison [SEP] negative [SEP]  experiments should be comparisons [SEP]  experiments should be comparisons
ICLR_2019_890,22621,"connecting to this, i would really love to see more analysis, going beyond measuring entropy. particularly since the problems are synthetic, not large scale more analysis should be possible. the types of tasks and datasets on which the proposed architecture is being tested are rather small. unfortunately, the experiments are seriously lacking in my opinion, as i believe the major focus of those.",substance [SEP] negative [SEP]  the believe major focus [SEP]  see more analysis [SEP]  analysis particularly the problems are [SEP]  more analysis particularly problems are synthetic not large scale [SEP]  are unfortunately experiments seriously lacking my opinion
ICLR_2019_890,22622,the paper is clear this paper is well written.,clarity [SEP] positive [SEP]  the paper clear [SEP]  paper clear this
ICLR_2019_890,22623,it would help to clarify the training procedure to explicitly mention in step 3 that training proceeds on sequences with added noise but it would be useful to clarify.,clarity [SEP] negative [SEP]  it would help [SEP]  clarify the training procedure [SEP]  explicitly mention step proceeds
ICLR_2019_890,22624,but the presented experimental validations are arguably weak ..,soundness [SEP] negative [SEP]  the presented experimental validations arguably weak
ICLR_2020_770,22690,"it is an interesting idea even though the proposed mincut pool is interesting this in an elegant choice, somewhat resembling the diffpool method since it's also end to end trainable.",originality [SEP] positive [SEP]  is an interesting idea trainable [SEP]  an elegant choice somewhat resembling method end [SEP]  the somewhat resembling diffpool method end
ICLR_2020_770,22691,i still believe the contribution novelty is limited. the novelty is limited ..,originality [SEP] negative [SEP]  i still believe [SEP]  still believe the contribution novelty [SEP]  the novelty is limited
ICLR_2020_770,22692,and performs well in a number of tasks. the math is solid and the concept is well substantiated by results ..,soundness [SEP] positive [SEP]  a number tasks [SEP]  well the is solid concept substantiated [SEP]  well is concept substantiated results
ICLR_2020_770,22693,"the authors provide intuitive thoughts but there are not theoretical derivations and proof. 4 .some experiments cannot support the claim very well. for example, the graph clustering experiments are not convincing. 4 .the graph classification results are not convincing enough ..",soundness [SEP] negative [SEP]  the authors provide thoughts [SEP]  authors provide intuitive thoughts [SEP]  the not not not experiments cannot support claim well
ICLR_2020_770,22694,"2 .the paper needs to be reorganized to demonstrate its contribution. making it difficult to understand the proposed method clearly 3 .the paper needs to be improved for its theoretical derivations and proof. or, the author should clarify the motivation to do this experiment ..",clarity [SEP] negative [SEP]  the understand proposed method [SEP]  paper needs [SEP]  the author should clarify motivation
ICLR_2020_770,22695,the paper is well written and clear to read ..,clarity [SEP] positive [SEP]  the paper well written clear
ICLR_2020_770,22696,"therefore, more details and analyses about the proposed method should be included to support and clarify the idea ..",replicability [SEP] negative [SEP]  more details analyses [SEP]  the clarify idea
ICLR_2020_770,22697,2 .the motivation is not clear ..,motivation [SEP] negative [SEP]  motivation not clear
ICLR_2020_770,22698,"3 .important baselines are missing ,.",meaningful-comparison [SEP] negative [SEP]  3 important baselines are missing
ICLR_2020_245,22980,the paper is easy to follow. the paper is well written and pleasant to read ..,clarity [SEP] positive [SEP]  the paper easy follow [SEP]  the paper easy follow
ICLR_2020_245,22981,results in section 2.3.2 table 1 are not exactly align with the story. the paper structure could be a bit improved. the plots are quite small and hard to follow ..,clarity [SEP] negative [SEP]  results section not [SEP]  align the story [SEP]  the be bit improved plots
ICLR_2020_245,22982,the novelty of the work is limited though ..,originality [SEP] negative [SEP]  the the novelty work
ICLR_2020_245,22983,"it would be worthwhile to include a comparison to that method. however, it would be nice to add some comparisons with prior works. it is unclear how the current method compare with nn rnn of (kerg et al .2019) and the unitary rnns. i think the method is promising, but comparison with prior work is missing. it would be good to include a comparison against lstms (and even transformer networks) 2 .the authors are missing a reference to this work.",meaningful-comparison [SEP] negative [SEP]  a authors reference [SEP]  add some comparisons [SEP]  method how compare rnn [SEP]  method the think [SEP]  prior work missing [SEP]  include a comparison
ICLR_2020_245,22984,the experimental section provides convincing data showing that non normal initialization schemes outperform orthogonal and identity initialization in vanilla rnn ..,substance [SEP] positive [SEP]  the experimental section provides data [SEP]  section provides convincing data [SEP]  non normal initialization initialization schemes outperform
ICLR_2020_245,22985,this line of experimentation is interesting as it potentially opens the door for more expressive modeling for sequential tasks by expanding the solution space of the weight matrices being learnt i.e orthogonal matrices are a special case ..,motivation [SEP] positive [SEP]  potentially opens the door [SEP]  the expanding solution space
ICLR_2020_245,22986,"2 .the authors do a great job in motivating the paper, and the explanation is clear and easily understandable ..",soundness [SEP] positive [SEP]  the explanation is clear [SEP]  a authors do great job
ICLR_2020_694,23020,empirically the authors show results for 3 datasets and this seems thorough ..,substance [SEP] positive [SEP]  empirically the authors show results [SEP]  empirically authors show results
ICLR_2020_694,23021,"moreover, the experiments are quite insufficient in terms of ablating different components of the proposed methods ..",substance [SEP] negative [SEP]  the experiments quite insufficient [SEP]  ablating different components
ICLR_2020_694,23022,"the motivation for this is very clear the presented task is realistic and important, and the paper seems to address it in a reasonable approach. while the problem being studied is important and there are a few concerns.",motivation [SEP] positive [SEP]  a are few concerns [SEP]  the motivation very clear [SEP]  the very clear presented task [SEP]  the paper seems [SEP]  address it [SEP]  a address reasonable approach [SEP]  the problem being studied
ICLR_2020_694,23023,"overall, the paper is very clear and easy to follow ..",clarity [SEP] positive [SEP]  the paper very clear
ICLR_2020_694,23024,"the evaluation seems lacking to me but i am not convinced that it works better than existing approaches (see below), and especially did not convince me that it is better in the zero shot test environment. i'm not sure that this assumption makes sense neither in the mario case or in other tasks it is not intuitive whether it has something to do with learning zero shot generalization.",soundness [SEP] negative [SEP]  the evaluation seems [SEP]  the not better is zero shot test environment [SEP]  i am not not convinced [SEP]  assumption makes sense [SEP]  it works better [SEP]  not has something
ICLR_2020_694,23025,the experimental results seem positive.,soundness [SEP] positive [SEP]  the experimental results seem positive
ICLR_2020_694,23026,the baselines presented in the experiments are relatively weak. but few of the related methods are used as baselines for comparison with the proposed method ..,meaningful-comparison [SEP] negative [SEP]  comparison proposed [SEP]  the presented experiments [SEP]  baselines presented
ICLR_2018_668,23161,but it relies heavily on heuristics (without a thorough investigation of scenarios in which this might not work ..,soundness [SEP] negative [SEP]  it relies heavily [SEP]  relies heavily heuristics [SEP]  a thorough investigation scenarios
ICLR_2018_668,23162,and the procedure is simple but makes sense ..,soundness [SEP] positive [SEP]  the procedure simple [SEP]  makes sense
ICLR_2018_668,23163,it might be helpful to investigate if there ways to better group the variables for group lasso regularization.,substance [SEP] negative [SEP]  it might be helpful [SEP]  investigate if there ways
ICLR_2018_668,23164,"for the group lasso method, since there are many ways to group the variable, it is not clear how the variables are grouped. another issue i find is the general writing, especially for the results section, is not entirely clear. please reread for some grammar writing issues.",clarity [SEP] negative [SEP]  writing reread some grammar issues [SEP]  are many ways not [SEP]  are not how variables grouped another issue [SEP]  the find general writing
ICLR_2018_668,23165,"the paper quality seems high, presentation clarity sufficient, the ideas presented.",clarity [SEP] positive [SEP]  the paper quality seems high [SEP]  presentation clarity clarity sufficient [SEP]  the ideas presented
ICLR_2018_668,23166,"overall, the paper does not seem to present novel ideas.",originality [SEP] negative [SEP]  overall the paper does not not not seem [SEP]  not present novel ideas
ICLR_2018_668,23167,"especially the use of group lasso) well thought out and original, and.",originality [SEP] positive [SEP]  especially the use group lasso
ICLR_2018_668,23168,and no explicit comparison with existing methods is provided a major complaint is the lack of comparison of results against other compression techniques ..,meaningful-comparison [SEP] negative [SEP]  results other techniques [SEP]  a comparison is is provided major complaint [SEP]  a major complaint the lack [SEP]  explicit comparison existing
ICLR_2018_668,23169,"the paper contains a good overview of related work in compression, and is not hiding anything ..",meaningful-comparison [SEP] positive [SEP]  is not not hiding anything [SEP]  paper a contains good overview [SEP]  a good overview related work
ICLR_2018_668,23170,the work seems significant this is certainly a well motivated problem i believe this is a very promising and well motivated work.,motivation [SEP] positive [SEP]  the work seems significant is [SEP]  a is well motivated problem believe [SEP]  work a is well motivated believe very promising and
ICLR_2018_771,24466,"as far as i understood, the proofs make sense.",soundness [SEP] positive [SEP]  i understood [SEP]  far the proofs make sense [SEP]  far proofs make sense
ICLR_2018_771,24467,it is also not clear why compressed sensing type recovery using a single relu or sigmoid would be of interest.,soundness [SEP] negative [SEP]  not would be interest [SEP]  it not clear
ICLR_2018_771,24468,i am unsure if real datasets will satisfied so many conditions ..,substance [SEP] negative [SEP]  i unsure [SEP]  datasets will satisfied so many conditions
ICLR_2018_771,24469,the authors approach in this vein seem to be only empirical. the proof techniques are classical.,originality [SEP] negative [SEP]  the authors approach [SEP]  this vein seem [SEP]  the be only empirical proof techniques
ICLR_2018_771,24470,but the results seem novel as far as i know ..,originality [SEP] positive [SEP]  the results seem novel far [SEP]  i know
ICLR_2018_771,24471,"the paper is overall difficult to read. sec .2 is unclear. some clarifications are required. please, provide the definition of the relu function here ..",clarity [SEP] negative [SEP]  the paper overall difficult read [SEP]  read sec [SEP]  the provide definition here
ICLR_2018_771,24472,", the paper does not sufficiently discuss related work. i think there is an insufficient literature review about recent recovery results in the context of sparse coding, dictionary learning and ica detailed comparisons with existing sample complexities obtained in previous work for related models (e.g. , sparse coding must be provided.",meaningful-comparison [SEP] negative [SEP]  related work previous models [SEP]  paper does not not not not sufficiently discuss related work [SEP]  an insufficient literature review recent recovery results [SEP]  ica detailed comparisons [SEP]  detailed comparisons existing [SEP]  existing sample complexities obtained [SEP]  work obtained previous
ICLR_2018_771,24473,the concept of ae framework is not well defined ..,replicability [SEP] negative [SEP]  the concept ae framework not
ICLR_2019_332,24510,' the experiments section is clearly not sufficient.,substance [SEP] negative [SEP]  the experiments section not sufficient
ICLR_2019_332,24511,as no comparison with existing algorithms is provided. algorithm to others.,meaningful-comparison [SEP] negative [SEP]  no comparison existing
ICLR_2019_332,24512,the authors provide no theoretical guarantee (like rate of convergence ... ) and do not compare empirically their.,soundness [SEP] negative [SEP]  do not not not compare empirically their [SEP]  authors provide no theoretical guarantee [SEP]  rate convergence
ICLR_2019_332,24513,"clarity could be improved in the neural network implementation i feel the paper is quite weak from the perspective of presentation. there are a couple of aspects the presentation can be improved from. i feel the authors should formally define what a spectral inference network is, especially what the network is composed of it is a little bit confusing there ..",clarity [SEP] negative [SEP]  it network is especially composed [SEP]  clarity could be improved [SEP]  clarity could be improved the neural network implementation [SEP]  the feel paper is [SEP]  a couple aspects [SEP]  a network is authors should formally define spectral inference [SEP]  is authors should formally define what
ICLR_2019_332,24514,"what is exactly done and why, when building the network, what are the nodes, what are the edges, and the semantics of the network and what's motivation of this type of network.",replicability [SEP] negative [SEP]  what is exactly done [SEP]  motivation this type
ICLR_2019_14,24908,the justification for the training loss was not completely clear to me there is no discussion of the issue that we can't get a straightforward decomposition of the joint probability over the data sequence according to next step probabilities via the chain rule of probabilities the paper could be improved. how incorporate such technique in such an autoregressive model is not easy. but can be improved further.,soundness [SEP] negative [SEP]  the the justification training loss not [SEP]  n't according next step probabilities
ICLR_2019_14,24909,rigorous experiments including complex high dimensional experiments clear and intuitive explanation (.,soundness [SEP] positive [SEP]  rigorous experiments including [SEP]  intuitive explanation
ICLR_2019_14,24910,so we don't have a clear way to compare the td vae models with jumpy predictions against other more traditional models none of the experiments make comparisons against previously published models and quantitative results.,meaningful-comparison [SEP] negative [SEP]  previously published quantitative results [SEP]  compare the td vae models [SEP]  models more traditional none [SEP]  the experiments make [SEP]  n't make comparisons
ICLR_2019_14,24911,"but the execution of some details on the experiments are missing (due to page limit). for reproducibility, detail specification on the hyperparameters and architecture will be helpful.",replicability [SEP] negative [SEP]  the execution some details [SEP]  the execution some details [SEP]  detail reproducibility specification
ICLR_2019_14,24912,"the idea is nice and novel , 1 .the introduction of belief state in the sequential model is smart. principled and quite original modeling based on variational inference.",originality [SEP] positive [SEP]  the idea nice [SEP]  and principled quite original modeling based [SEP]  based variational inference
ICLR_2019_14,24913,3 .four experiments demonstrated the main advantages of the proposed framework the proposed method is well evaluated for four tasks including high dimensional complex task ..,substance [SEP] positive [SEP]  task including high dimensional complex [SEP]  experiments demonstrated the main advantages is [SEP]  four tasks including
ICLR_2019_14,24914,pros. advancing a significant problem.,motivation [SEP] positive [SEP]  pros advancing problem [SEP]  a advancing significant problem
ICLR_2020_1082,25411,"the proposed approach gives important insights for the problem of weight initialization in neural networks. overall i think the work is very important and interesting. overall i agree with reviewer 1 that the topic is interesting i think the topic of the paper is interesting, overall i think the direction of the work is interesting ..",motivation [SEP] positive [SEP]  the work overall think is [SEP]  the proposed approach gives insights [SEP]  approach gives important insights [SEP]  the important insights problem [SEP]  the the paper direction
ICLR_2020_1082,25412,"overall, the method makes sense. while everything makes sense intuitively.",soundness [SEP] positive [SEP]  overall the method makes sense [SEP]  overall method makes sense [SEP]  overall method makes sense
ICLR_2020_1082,25413,alexnet seem not exciting first of all i find the empirical section quite weak ..,soundness [SEP] negative [SEP]  alexnet seem not exciting [SEP]  i find weak [SEP]  find the empirical section weak
ICLR_2020_1082,25414,"the authors do not consider more recent neural network designs such as normalization layers it would be great if the authors also compare their approach to huang et al .2018. the authors compared to other initialization schemes such as he et al. however, it lacks comprehensive comparison and consideration of more recent neural network layers. i still believe that it is informative to compare the two approaches because.",meaningful-comparison [SEP] negative [SEP]  authors also compare their approach [SEP]  the authors do not not consider designs [SEP]  however lacks comprehensive comparison
ICLR_2020_1082,25415,it would be great if the authors could discuss how these layers would change the derivation of the initialization method ..,replicability [SEP] negative [SEP]  it would be great [SEP]  authors could discuss these layers [SEP]  would the how layers change derivation
ICLR_2020_1082,25416,"also, preliminary experimental results using these layers are needed. experiments on the cifar 10 dataset with i think more experimental evidence is needed i would have hoped more rigor more carefully, with a more thorough empirical exploration, showing different architectures, different datasets ..",substance [SEP] negative [SEP]  showing different architectures [SEP]  preliminary experimental results using layers [SEP]  using these layers [SEP]  also results are needed experiments [SEP]  experimental think more evidence [SEP]  a more thorough empirical exploration showing architectures
ICLR_2020_1082,25417,i believe that the new technical insights of the paper alone is not significant enough.,originality [SEP] negative [SEP]  i believe is [SEP]  believe the new technical insights is not
ICLR_2020_1082,25418,"overall, the paper is well written and clear in comparison and explanation ..",clarity [SEP] positive [SEP]  the paper well written clear
ICLR_2020_1082,25419,though i think in its current form the paper is not ready the paper needs to be written.,clarity [SEP] negative [SEP]  i think is
ICLR_2020_2205,25727,"the experiment section is missing, and but it seems to be at the draft stage as it stands as the experiment section is missing (section 4 ).",substance [SEP] negative [SEP]  the experiment section is [SEP]  the be draft stage [SEP]  it seems
ICLR_2020_2205,25728,much of the method section is partly written. in some parts the sentences are broken and hard to follow the paper itself is incomplete and contains many typos ..,clarity [SEP] negative [SEP]  the method section is [SEP]  the follow paper [SEP]  contains many typos
ICLR_2020_2205,25729,"this opponent model seems to be simplistic, given security game has studied the opponent using more rigorous equilibrium analysis and with dynamic bayesian game formulation.",soundness [SEP] negative [SEP]  using more rigorous equilibrium analysis [SEP]  this opponent model seems [SEP]  given security game
ICLR_2020_2205,25730,the practical application is well motivated ..,motivation [SEP] positive [SEP]  the practical application well motivated
ICLR_2020_650,26633,"2 .the paper is very well written, the motivation and formulation is clear. , a well written paper the paper is very well written and clear. points in favor of acceptance include the high clarity of writing.",clarity [SEP] positive [SEP]  the points include high clarity [SEP]  paper a is well written clear [SEP]  the paper is clear [SEP]  points acceptance include clarity
ICLR_2020_650,26634,5 .the model seems to be related to adaptive computation time.,originality [SEP] negative [SEP]  5 the model seems [SEP]  be related adaptive computation time
ICLR_2020_650,26635,and represents a concrete contribution to the language modelling literature.,originality [SEP] positive [SEP]  a represents concrete contribution
ICLR_2020_650,26636,the link and the self citations on page 4 are does not seem to be valid links and citations the main shortcoming of the paper is experimental comparison to baselines ..,meaningful-comparison [SEP] negative [SEP]  the link self citations not [SEP]  link citations page not [SEP]  the not shortcoming paper is comparison
ICLR_2020_650,26637,"extensive analysis 2 .an extensive evaluation of the proposed technique against previous works and on all relevant datasets. the results in the paper demonstrate significant improvement over lstm, and while there are not as many baseline comparison to similar models as i would have liked to see, the quality of this work is sufficiently high that this is not a fatal flaw experiments demonstrating strong performance on a number of language modeling tasks. , good experiments of the proposed model, and a discussion of possible reasons for why the mogrification operation works well the ablation study showing the effect of different design decisions and the hyperparameter visualiztion in appendix b are particularly useful.",substance [SEP] positive [SEP]  the different design decisions hyperparameter visualiztion [SEP]  extensive extensive an analysis 2 evaluation proposed [SEP]  the all relevant datasets results [SEP]  results demonstrate significant improvement [SEP]  the see quality [SEP]  is is work quality this high [SEP]  a not fatal flaw experiments demonstrating performance [SEP]  demonstrating strong performance [SEP]  a strong performance number [SEP]  experiments language modeling tasks good [SEP]  the proposed model experiments good [SEP]  a discussion possible reasons [SEP]  the ablation study showing effect [SEP]  the showing effect
ICLR_2020_650,26638,what the experiments do not show is that the proposed mogrification outperforms other forms of multiplicative interaction and or gating. some qualitative analysis of the learned mogrification operation would be helpful for understanding the nature of the modulation.,substance [SEP] negative [SEP]  the understanding nature [SEP]  the experiments do not not show [SEP]  gating some qualitative analysis
ICLR_2020_650,26639,and good experimental result. the mogrification operation is described precisely enough for other researchers to implement and the arguments made in 4.4 are compelling ..,soundness [SEP] positive [SEP]  other researchers implement [SEP]  the arguments made
ICLR_2020_650,26640,"it motivates and explores the questions and issues surrounding this topic very well. it is clear, well motivated.",motivation [SEP] positive [SEP]  it motivates [SEP]  explores the questions [SEP]  surrounding this topic well
ICLR_2020_1596,27171,the experiment results are impressive. and has reasonable experimental support of its claims ..,soundness [SEP] positive [SEP]  the experiment results impressive [SEP]  has reasonable experimental support
ICLR_2020_1596,27172,the results on the image datasets seem too good to be true. the convergence rate analysis for this case is fairly simple i am not convinced that using the same optimal hyperparams as the wrn 28 4 task on the wrn 28 10 and resnet50 models is a reasonable experiment. why is this a good idea we are still not convinced that the hyperparameter tuning in the experiments (especially the baselines) is rigorous enough ..,soundness [SEP] negative [SEP]  the results image datasets seem good [SEP]  the be true true convergence rate analysis [SEP]  i fairly simple not [SEP]  the using same optimal hyperparams [SEP]  the a wrn 28 10 and resnet50 models reasonable experiment [SEP]  a good idea are still [SEP]  we are still
ICLR_2020_1596,27173,it is good to see some research directly addresses this problem and is on an important topic ..,motivation [SEP] positive [SEP]  it is good [SEP]  see some research [SEP]  research directly addresses this problem
ICLR_2020_1596,27174,"the word domain is confusing. but this statement seems misleading since it is not clear whether the worse rate is due to the analysis this can be confusing to the reader, and it is best to explicitly mention the setting under which the different results were derived.",clarity [SEP] negative [SEP]  the different results were derived [SEP]  the word domain is confusing [SEP]  the confusing due analysis can be [SEP]  the confusing can be reader [SEP]  statement seems misleading misleading it [SEP]  the explicitly mention setting
ICLR_2020_1596,27175,"this paper is clearly written, the paper is well written.",clarity [SEP] positive [SEP]  this is paper clearly written [SEP]  is paper clearly written the
ICLR_2020_1596,27176,so the following experiment results may not be used for assessment of the quality of the proposed method i would encourage the authors to do a more rigorous experimental evaluation of the proposed algorithm ..,substance [SEP] negative [SEP]  a do more rigorous experimental evaluation [SEP]  so the following experiment results may not not not be used [SEP]  so results may not not not be used assessment [SEP]  the assessment quality [SEP]  the not would encourage authors
ICLR_2020_1596,27177,python cifar.py a resnet depth 20 epochs 164 schedule 81 122 gamma 0.1 wd 1e 4 optimizer adam beta1 0.9 beta2 0.999 checkpoint. logdir gpu id 0 model name adam 003 lr 0.03 if the authors can provide more implementation details.,replicability [SEP] negative [SEP]  py cifar resnet depth [SEP]  the authors can provide details [SEP]  authors can provide more implementation details
ICLR_2020_1596,27178,the contribution of theorem 1 is a nice addition to the literature. 2 .the proposed algorithm avagrad is a simple but interesting idea. i think decoupling the learning rate and the damping parameter by normalizing the preconditioner is a simple but interesting idea.,originality [SEP] positive [SEP]  the contribution nice addition [SEP]  the a nice addition literature [SEP]  but a proposed algorithm avagrad simple interesting idea [SEP]  i is think
ICLR_2020_1596,27179,and i am not sure if analyzing rmsprop adam in this setting should be considered a significant contributions of the paper. we are also concerned about the novelty of the results.,originality [SEP] negative [SEP]  a not should be considered significant contributions
ICLR_2019_1168,27214,overall this is an interesting application of hierarchical rnns ..,motivation [SEP] positive [SEP]  an interesting application hierarchical rnns
ICLR_2019_1168,27215,"for an applications oriented paper, i would hope to see many more experiments than just one on a tiny dataset, and improvements in log likelihood that are more than the marginal improvements reported here but is inconclusivein a glaring act of omission.",substance [SEP] negative [SEP]  an applications oriented paper would hope [SEP]  see many more experiments [SEP]  improvements log likelihood
ICLR_2019_1168,27216,"think of a different way to present the results. the paper has many grammatical and spelling errors. there is no melodic motif, there is no sense of 4 bar phrasing (or any other recurring such pattern that i can tell the input representation could use further clarifying ..",clarity [SEP] negative [SEP]  the can tell input representation [SEP]  think a different way [SEP]  present the results [SEP]  the paper has errors [SEP]  paper has many grammatical and spelling errors [SEP]  no sense 4 bar phrasing
ICLR_2019_1168,27217,good problem generating polyphonic music with long term structure reasonable approach modification of samplernn makes sense con's the authors do make a variety of choices that appear to be fairly sensible. the core of their approach (using measures as a natural hierarchy for a multi level rnn) is a good one.,soundness [SEP] positive [SEP]  good a rnn one [SEP]  good problem generating music [SEP]  polyphonic music long term structure reasonable approach modification [SEP]  samplernn makes sense [SEP]  a make authors do variety [SEP]  the be fairly sensible core [SEP]  rnn using measures
ICLR_2019_1168,27218,the notion of user preference is completely convoluted with external factors.,soundness [SEP] negative [SEP]  the notion user preference [SEP]  completely convoluted external factors
ICLR_2019_1168,27219,"it does not seem worthwhile for this review to get into details about exactly how the system works, in light of the problematic output ..",replicability [SEP] negative [SEP]  it does not not not seem worthwhile [SEP]  not review get details [SEP]  how the system works
ICLR_2019_1168,27220,but not new in of itself as it was the basis for the prior work of roberts et al.,originality [SEP] negative [SEP]  not it was basis [SEP]  not was the basis [SEP]  the the basis prior work
ICLR_2019_1168,27221,in particular the comparisons to deepbach and sequencetutor are inappropriate and give little information about the quality of the model architecture itself ..,meaningful-comparison [SEP] negative [SEP]  particular the comparisons deepbach [SEP]  give little information [SEP]  the little information quality
ICLR_2019_385,27725,"as such, it may seem only incremental as such there isnt a major technical contribution imho in this work. furthermore, the presented orthogonalization for easier inference has been used before in many works.",originality [SEP] negative [SEP]  furthermore orthogonalization has been used before many works [SEP]  a nt nt major technical contribution contribution imho [SEP]  nt contribution imho this work [SEP]  the presented orthogonalization easier inference
ICLR_2019_385,27726,nevertheless there is value in novel results that may follow from previous works in a straightforward but non trivial fashion.,originality [SEP] positive [SEP]  value novel results [SEP]  may follow previous works
ICLR_2019_385,27727,", but i would consider it as an important piece to ensure a solid foundation of the 'maso view' on deep neural networks. interesting work, extending previous work by balestriero and baraniuk in a relevant and non trivial direction. this work could spark interesting future works and fruitful discussions at the iclr ..",motivation [SEP] positive [SEP]  works interesting could spark future [SEP]  would consider it [SEP]  an important piece ensure foundation [SEP]  a ensure solid foundation [SEP]  deep neural networks work interesting [SEP]  work extending previous
ICLR_2019_385,27728,a lot of explanatory content is missing the presentation could be cleaner and clearer although somewhat cluttered by a large number of subscripts and superscripts i would suggest a couple of ways to possibly improve the exposition. the paper is somewhat notation heavy ..,clarity [SEP] negative [SEP]  a lot explanatory content [SEP]  a would suggest couple
ICLR_2019_385,27729,"the presentation is reasonably clear, as long as it is well presented and thoroughly researched and implication well highlighted. it is well written.",clarity [SEP] positive [SEP]  is it well presented [SEP]  the presentation reasonably clear [SEP]  thoroughly researched implication
ICLR_2019_385,27730,the paper contains solid work and contributes to an interesting perspective interpretation of deep networks ..,soundness [SEP] positive [SEP]  the paper contains work [SEP]  paper contains solid work
ICLR_2019_385,27731,the experimental evaluation is adequate.,substance [SEP] positive [SEP]  the experimental evaluation adequate
ICLR_2019_729,27766,"augmenting agent state with state of dfa tracking action sequence constraints is novel and useful for this problem cons, an interesting and novel idea.",originality [SEP] positive [SEP]  cons novel an and this problem interesting idea [SEP]  dfa tracking action sequence constraints novel [SEP]  cons useful this problem
ICLR_2019_729,27767,i have concerns about the novelty of this method.,originality [SEP] negative [SEP]  i have concerns [SEP]  have concerns [SEP]  concerns the novelty
ICLR_2019_729,27768,no clear benefit of addressing this problem through shaping rewards 1 .goal .the goal of this work is unclear ..,motivation [SEP] negative [SEP]  no clear benefit addressing problem [SEP]  addressing this problem [SEP]  shaping rewards
ICLR_2019_729,27769,"no comparison to simply training with only non violating action sequences. however, i do not believe this paper did a good enough job in situating this work in the context of prior work in particular it is possible, however, that i missed something which contrasts the two works. i think it is particularly important to situate this work within the context of those others ..",meaningful-comparison [SEP] negative [SEP]  no comparison simply training [SEP]  however do not not believe this paper [SEP]  a not paper did good enough job [SEP]  i however do not not believe
ICLR_2019_729,27770,i would also encourage an more thoughtful examination of the theoretical ramifications of the reward shaping signal with respect to the optimal policy as but then the evaluation is insufficient but results are a bit lacking ..,substance [SEP] negative [SEP]  results are lacking [SEP]  would also encourage an more thoughtful examination signal [SEP]  an more thoughtful examination the theoretical ramifications [SEP]  the then evaluation is insufficient
ICLR_2019_729,27771,"it would be nice to explain to the reader in intuitive terms what it would be good to clarify in figure 1 what. general the structure of the paper was a bit all over the place, crucial details were spread throughout and it took me a couple of passes to put things together. i would suggest putting relevant details all in one place. however, i find the results hard to read ..",clarity [SEP] negative [SEP]  i would suggest [SEP]  the place crucial details [SEP]  put things together [SEP]  place details putting relevant one
ICLR_2019_729,27772,the paper is clearly written ..,clarity [SEP] positive [SEP]  the paper is clearly written
ICLR_2019_729,27773,what is the reward function used.,replicability [SEP] negative [SEP]  what is function [SEP]  is the reward function
ICLR_2018_224,27790,i agree with r1 that the results do not tell a completely clear story.,clarity [SEP] negative [SEP]  i agree [SEP]  agree r1 [SEP]  a results do not not not tell completely clear story
ICLR_2018_224,27791,and the paper is very well done.,clarity [SEP] positive [SEP]  the paper is well done
ICLR_2018_224,27792,and the paper makes a clear contribution.,originality [SEP] positive [SEP]  the paper makes contribution [SEP]  a paper makes clear contribution
ICLR_2018_224,27793,this paper isn't especially novel ..,originality [SEP] negative [SEP]  this paper n't n't especially novel
ICLR_2018_224,27794,the problem that the paper addresses is a major open issue within nlp i think this paper addresses an important problem of learning general purpose sentence representations ..,motivation [SEP] positive [SEP]  learning general purpose sentence representations [SEP]  the paper addresses is issue [SEP]  a addresses is major open issue [SEP]  problem i think [SEP]  problem paper think this [SEP]  problem an important learning representations
ICLR_2018_224,27795,my one major request would be a more complete ablation analysis it is also not clear whether the performance improvement comes from having more unlabeled data.,substance [SEP] negative [SEP]  my one major request would be analysis [SEP]  a request would be more complete ablation analysis [SEP]  not the performance improvement comes
ICLR_2018_224,27796,your ablation does not offer enough evidence to one to infer this among other things i am not yet convinced by the experiments that this is indeed the case.,soundness [SEP] negative [SEP]  not not is am the yet convinced experiments [SEP]  ablation does not not not offer enough evidence [SEP]  not infer other things
ICLR_2019_544,27974,the paper is easy to follow ..,clarity [SEP] positive [SEP]  the paper easy follow
ICLR_2019_544,27975,section 4 is interesting but is not properly written ..,clarity [SEP] negative [SEP]  section interesting
ICLR_2019_544,27976,"c1 .the novelty of the paper is rather limited, both in terms of the convergence analysis and exploiting the low rank structure in tensor trains. section 3 is also not novel to the paper ..",originality [SEP] negative [SEP]  the paper rather limited [SEP]  the terms convergence analysis [SEP]  the exploiting low rank structure
ICLR_2019_544,27977,"it misses the important reference 5 .in the experiment, please compare with other existing (tensor decomposition based) compression methods to demonstrate how the proposed method makes sense in this task ..",meaningful-comparison [SEP] negative [SEP]  method how makes sense [SEP]  it misses reference [SEP]  misses the important reference
ICLR_2019_544,27978,there is no discussion on how the paper comes about those modifications. this paper does not clearly illustrate how rsgd can efficiently solve this problem. would make no sense because the denominator might be very small.,soundness [SEP] negative [SEP]  no would make sense [SEP]  how paper comes those modifications [SEP]  paper does not not not clearly illustrate rsgd
ICLR_2019_544,27979,how to determine the rank of the tensor networks in weight compression problem is indeed an important and urgent task.,motivation [SEP] positive [SEP]  how determine the rank [SEP]  the the rank tensor networks [SEP]  an weight compression problem important and urgent task
ICLR_2019_544,27980,but also additional computational operations should be done in each iteration like exponential mapping (with multiple qr and svd ).,substance [SEP] negative [SEP]  also additional computational operations should be done [SEP]  each iteration exponential mapping [SEP]  multiple qr qr svd
ICLR_2019_1122,28298,"it is unfortunate that there is no empirical comparison with the most closely related prior work the authors compare to a weak translation baseline on small data sets, making it impossible to judge.",meaningful-comparison [SEP] negative [SEP]  it unfortunate [SEP]  unfortunate no empirical comparison closely related [SEP]  it unfortunate
ICLR_2019_1122,28299,"no details are provided on the tagset used and what system is used to predict it, or to what degree of accuracy ..",replicability [SEP] negative [SEP]  no details are provided [SEP]  the tagset used [SEP]  used what system
ICLR_2019_1122,28300,please make sure to proofread this paper is not ready for publication in iclr or most other venues. i found much of the paper confusing. sec 2.2 .the description of the model is confusing. table 1 .i m not sure what the code accuracy tells us. s also unclear to me what is means to original tag sequence note that the use of four columns corresponding to different beam sizes is misleading this makes it look as if there are four separate experiments for each condition.,clarity [SEP] negative [SEP]  i found much [SEP]  paper the confusing [SEP]  the confusing sec 2 2 description [SEP]  the code accuracy tells [SEP]  us accuracy tells [SEP]  means original sequence
ICLR_2019_1122,28301,"also, the authors rely on additional supervised data (namely pos tags) which has no clear motivation and seems the model is poorly motivated.",motivation [SEP] negative [SEP]  the is seems model [SEP]  also authors rely additional supervised data [SEP]  has no clear motivation
ICLR_2019_1122,28302,"to cause a number of problems why not use a purely unsupervised approach when it has already been demonstrated on the same problem many modeling choices are confusing, and the experiments are not convincing ..",soundness [SEP] negative [SEP]  not the choices are confusing confusing experiments [SEP]  cause a number [SEP]  problem not when has already been demonstrated the same many
ICLR_2019_1122,28303,whether the results would hold on a larger data set. so the following ablations and comparison to baselines are missing.,substance [SEP] negative [SEP]  the results would hold [SEP]  the following ablations comparison
ICLR_2019_968,28353,of using block sparse fnn seems unclear the obtained cnn approximating architectures look quite unrealistic compared to most practical use cases of cnns.,soundness [SEP] negative [SEP]  using block sparse fnn
ICLR_2019_968,28354,"2 .in the related work, the authors only compare with 2 previous work on the approximation error of cnn ..",meaningful-comparison [SEP] negative [SEP]  2 work authors only compare previous [SEP]  the work previous approximation error
ICLR_2019_968,28355,it would be nice to give more details of the construction since this is not claimed in schmidt hieber 2017. it is not very clear how the convolutional structure of cnns help in the analysis of approximating fnns ..,replicability [SEP] negative [SEP]  it would be nice not [SEP]  give more details [SEP]  is not claimed schmidt hieber
ICLR_2019_968,28356,"the presentation of the paper could be significantly improved, for instance by introducing relevant notions more clearly in the introduction and related work sections the discussion on 'relative scale' could be made clearer ..",clarity [SEP] negative [SEP]  the related work sections discussion [SEP]  the the presentation paper [SEP]  introducing relevant notions clearly discussion [SEP]  the introduction related
ICLR_2019_968,28357,"the idea for connecting the expressive ability of cnns with fnns is interesting, which can fully take advantage of the power of fnns to understand cnns ..",originality [SEP] positive [SEP]  the idea connecting ability [SEP]  the connecting expressive ability [SEP]  the expressive ability cnns [SEP]  can fully take advantage
ICLR_2020_59,28610,i really like the idea of studying the impact of the depth in the training dynamics. and i think there are several interesting contributions ..,originality [SEP] positive [SEP]  think are several interesting contributions [SEP]  the studying impact [SEP]  the the impact depth [SEP]  i really like idea
ICLR_2020_59,28611,"however, these results are very hard to read. the result presented in theorem 2, (and 3) are hard to interpret because of the many parameters that distract the reader to the main point ..",clarity [SEP] negative [SEP]  however these results are hard [SEP]  the result presented [SEP]  result presented theorem [SEP]  the many parameters distract reader
ICLR_2020_59,28612,the paper is well written.,clarity [SEP] positive [SEP]  the paper is well written
ICLR_2020_59,28613,could you extend your results (and definitions) to non uniform initialization.,substance [SEP] negative [SEP]  could you extend results [SEP]  could extend your results [SEP]  non uniform initialization
ICLR_2020_59,28614,"include a clear definition of incremental learning, results showing the depth s effect on incremental learning as well as extensions to several other models ..",substance [SEP] positive [SEP]  extensions several models [SEP]  include a clear definition results [SEP]  results showing effect [SEP]  s showing the depth effect [SEP]  a clear definition incremental learning
ICLR_2020_59,28615,infty is completely missing so i have no way to assess the validity of this result.,soundness [SEP] negative [SEP]  assess the validity [SEP]  infty completely missing
ICLR_2018_653,29006,"2 .the method is only evaluated on a toy dataset where both the structure of the dialog is limited (see figure 2) and the sentences themselves (the number of language templates is not provided). i wish more examples and some statistics regarding the diversity of produced dialogs were provided for me, the main drawback of the paper is that it was't tested with human users ..",substance [SEP] negative [SEP]  tested human users [SEP]  the method is [SEP]  method is only evaluated a toy dataset [SEP]  the number language templates not [SEP]  wish more examples [SEP]  some statistics regarding diversity [SEP]  the regarding diversity
ICLR_2018_653,29007,3 .the qualitative evaluation shows compelling examples from the model ..,substance [SEP] positive [SEP]  qualitative evaluation shows examples [SEP]  evaluation shows compelling examples
ICLR_2018_653,29008,5 .the use of the value network vs. the policy network is not clarified in the model description nor in the experiments. it is not clear to me how you did the supervised part of the training. it's not self contained. moreover i am not sure about quite some items. implementation details. i fail to understand how the supervised learning is used.,replicability [SEP] negative [SEP]  the supervised understand learning [SEP]  5 the the use value network [SEP]  the use is not not clarified model description [SEP]  not me clear how did part
ICLR_2018_653,29009,there are several typos or grammatical errors it is not clear how you got the ground truth for the training. the paper could be better organised. i struggled with the clarity of some text portions.,clarity [SEP] negative [SEP]  several typos grammatical errors
ICLR_2018_653,29010,i like the idea of coupling the language and the conversation model. the idea of enforcing information isolation is brilliant. creating hidden information and allowing the two party model to learn through self play is a very interesting approach and.,originality [SEP] positive [SEP]  a self play very interesting approach [SEP]  like the idea [SEP]  information creating hidden [SEP]  the model allowing two party [SEP]  model learn self play
ICLR_2018_653,29011,"i found it very difficult to work out what the contribution of this paper is over previous work the approach to using selfplay rl seems almost identical in each case, so there doesn t appear to be a technical contribution ..",originality [SEP] negative [SEP]  a contribution be technical [SEP]  found it difficult [SEP]  using selfplay [SEP]  seems almost identical each case
ICLR_2018_653,29012,the results seem promising.,soundness [SEP] positive [SEP]  the results seem
ICLR_2018_653,29013,reward seems to play a very important role for the proposed system i believe that the paper has a great potential and is a noticeable work.,motivation [SEP] positive [SEP]  a is noticeable work [SEP]  reward seems [SEP]  a play very important role [SEP]  the paper has potential [SEP]  a paper has great potential
ICLR_2018_653,29014,the paper needs to be much clearer about what its contributions are over previous work before it can be accepted.,meaningful-comparison [SEP] negative [SEP]  the paper needs [SEP]  are its contributions [SEP]  are contributions previous work
ICLR_2020_1508,30111,"i do not feel that the technical contributions are substantial enough to warrant acceptance at iclr. the methodological novelty is limited the technical novelty is small, as the extension of the existing nas models to handle physical inputs and a few new operators is relatively straightforward. 1 .there is limited technical novelty as the entire method is mainly based on previous work on neural architecture search ..",originality [SEP] negative [SEP]  the method is entire mainly based [SEP]  the technical novelty is [SEP]  is relatively straightforward 1 there [SEP]  technical novelty limited 1 there
ICLR_2020_1508,30112,application of nas to physics based.,originality [SEP] positive [SEP]  application physics [SEP]  physics based
ICLR_2020_1508,30113,"and the experimental evaluation only evaluates the method on two fairly simple problems. there are several aspects of the work that could be improved. while i appreciate the necessity to explore the methods performance in a more controlled setting, a more impactful testbed would another drawback of the evaluation is the lack of a proper statistical analysis of the results, given the small data and model sizes. it would have been interesting to see physicsnas applied to a more impactful task a more sophisticated statistical analysis of the results wasn t performed similarly, a more complete set of experiments with more sample amounts could be provided with little effort. nevertheless, it might be helpful to have some ablation study to show the improvement of the task specific adaptations presented in the paper.",substance [SEP] negative [SEP]  the evaluation only evaluates method [SEP]  the several aspects work [SEP]  the explore methods performance [SEP]  a the lack proper statistical analysis [SEP]  and the given small data model sizes [SEP]  a more impactful analysis physicsnas applied task [SEP]  a the more statistical analysis task sophisticated [SEP]  the set results wasn performed similarly [SEP]  a more set complete experiments [SEP]  could be provided little effort [SEP]  some ablation study show improvement [SEP]  the show improvement [SEP]  the task specific adaptations
ICLR_2020_1508,30114,experiments testing the dependence of the model on the numbers of samples and the strength of the physical inconsistencies were conducted. the results are also impressive as the proposed method surpasses all the considered baselines ..,substance [SEP] positive [SEP]  experiments testing the dependence [SEP]  the the model numbers [SEP]  the samples strength [SEP]  the were conducted results
ICLR_2020_1508,30115,the authors have done a good job of illustrating the idea and have compared it to most natural baselines. the related work gives a good summary and categorization of prior work in physics based learning estimating trajectory of a ball in presence of wind and air resistance.,meaningful-comparison [SEP] positive [SEP]  a authors have done good job [SEP]  the related work gives summary [SEP]  a good work gives summary [SEP]  work categorization prior
ICLR_2020_1508,30116,i think the idea has merit and rather like it. the problem (physics based learning) is interesting and relevant to the community it is interesting because it cleverly tackles the challenge of manually designing priors and network architectures ..,motivation [SEP] positive [SEP]  think the idea [SEP]  idea has merit [SEP]  the problem physics based learning [SEP]  the relevant community
ICLR_2020_1508,30117,only explore uninteresting be more convincing there is no reason why.,soundness [SEP] negative [SEP]  only explore uninteresting be why [SEP]  more convincing no reason
ICLR_2020_1508,30118,that the authors did not discuss the computational costs and whether different methods are compared given the same cost ..,replicability [SEP] negative [SEP]  the cost given same [SEP]  the authors did not not not discuss costs [SEP]  the authors did not not not discuss computational costs [SEP]  not different methods are compared
ICLR_2018_183,30737,i don't think there is enough interesting novelty in this paper ..,originality [SEP] negative [SEP]  i do n't think
ICLR_2018_183,30738,"and the proposed method is original and works well. 1) potentially a good idea ,.",originality [SEP] positive [SEP]  the proposed method original [SEP]  a works well 1 potentially good idea
ICLR_2018_183,30739,this is good work it is well written.,clarity [SEP] positive [SEP]  is good work well written
ICLR_2018_183,30740,"section 3 could use some more signposting. badly presented the writing of the paper fails in let the reader aware of what the paper actually serves comments so i suggest the authors to better explain the connection between the told problem and their proposed solution, and how this can solve the problem. i would have appreciated a paper more self explanative.",clarity [SEP] negative [SEP]  a paper would have appreciated explanative [SEP]  badly presented the writing comments [SEP]  let reader aware what [SEP]  paper actually serves comments [SEP]  so the suggest authors [SEP]  the authors better explain connection [SEP]  i so suggest
ICLR_2018_183,30741,the experiments are thorough.,substance [SEP] positive [SEP]  the experiments thorough
ICLR_2018_183,30742,why these measures matter and what is going to be done with them.,soundness [SEP] negative [SEP]  why these measures matter [SEP]  why measures matter what [SEP]  be done them
ICLR_2018_183,30743,"capable of filling an ontology of relations scarcely present in a given repository 2) solid theoretical background, even if no methodological novelty has been introduced.",soundness [SEP] positive [SEP]  filling an ontology [SEP]  a relations scarcely present given repository [SEP]  capable even no methodological novelty has been introduced
ICLR_2018_183,30744,i would like to see more details on how the evaluation is done here.,replicability [SEP] negative [SEP]  i would like [SEP]  see more details [SEP]  how the evaluation is done here
ICLR_2020_1067,31199,i believe that the question the authors try to answer is very interesting and worth of exploration ..,motivation [SEP] positive [SEP]  i believe is [SEP]  worth exploration
ICLR_2020_1067,31200,"therefore, my main recommendation to the authors would be to identify other datasets for their experiment. having such a dataset would make your paper much stronger the main issue about the submission is the limited depth in the contributions, analyzing a single family of network architectures (bagnets) over two datasets, one of which is relatively small.",substance [SEP] negative [SEP]  a analyzing single family [SEP]  would dataset make your paper stronger is [SEP]  the main make paper much stronger issue [SEP]  the is issue limited depth
ICLR_2020_1067,31201,the contributions of the study are limited there is no methodological contribution ..,originality [SEP] negative [SEP]  the the contributions study [SEP]  contribution contributions are limited is no methodological
ICLR_2020_1067,31202,the dataset based on mnist is perhaps too artificial (too structured ).,soundness [SEP] negative [SEP]  the dataset based [SEP]  based mnist
ICLR_2020_382,31228,"this work is well motivated. the authors presented an interesting paper which tries to solve a practically important question. overall, the paper is well motivated with the paper is trying to address a practically important issue in machine learning ..",motivation [SEP] positive [SEP]  a practically important address issue [SEP]  this work well motivated [SEP]  authors presented an interesting paper [SEP]  a solve practically important question
ICLR_2020_382,31229,"therefore, the setup of this problem seems novel a reasonable amount of novelty, the authors' choice of using such formulations to assess model performance is novel ..",originality [SEP] positive [SEP]  assess model performance [SEP]  therefore setup this is problem seems novel [SEP]  therefore setup novel novel a reasonable amount
ICLR_2020_382,31230,"the mathematical formulation of the metric consists of simple sums and averages, which in itself is not novel. however.",originality [SEP] negative [SEP]  the mathematical formulation metric consists [SEP]  is itself not not novel
ICLR_2020_382,31231,the numerical experiments are well conducted.,substance [SEP] positive [SEP]  the numerical experiments well conducted
ICLR_2020_382,31232,", but i am not totally convinced by their results ..",soundness [SEP] negative [SEP]  i am not not not totally convinced [SEP]  am not not totally convinced their results
ICLR_2020_382,31233,"the authors could simplify their notations, and could periodically remind the readers about the notations ..",clarity [SEP] negative [SEP]  the authors could simplify notations [SEP]  authors could simplify their notations [SEP]  the could periodically remind readers
ICLR_2020_448,31573,"overall, this is a well organised and nicely presented work. well written, with the authors' motivations and explanation of the method conceived quite straightforwardly ..",clarity [SEP] positive [SEP]  a well organised and nicely presented work written [SEP]  the authors motivations explanation [SEP]  the method conceived straightforwardly
ICLR_2020_448,31574,"the paper does, however, at times feel to be disjointed and, to an extent, lacking in focus. i find the writing quite confusing throughout adjusting and clarifying the notation would improve the paper. 2 .the way kl divergence is used in eq .5 is misleading since the arguments are two distributions over different sets of random variables. .the way that part is presented now leaves the reader to derive all the details on their own.",clarity [SEP] negative [SEP]  the derive all details [SEP]  does however times feel [SEP]  lacking focus [SEP]  i find confusing [SEP]  the find writing confusing [SEP]  is way that part presented now
ICLR_2020_448,31575,the idea on how to utilise the unlabeled test data to realise tranductive learning is novel.,originality [SEP] positive [SEP]  the idea how utilise data [SEP]  the how utilise unlabeled test data [SEP]  is realise tranductive learning
ICLR_2020_448,31576,i am not convinced about how truly novel the method is when viewed as a whole.,originality [SEP] negative [SEP]  i not convinced [SEP]  how truly novel the method
ICLR_2020_448,31577,the analysis is thorough.,substance [SEP] positive [SEP]  the analysis thorough
ICLR_2020_448,31578,please provide some discussion on this issue ..,soundness [SEP] negative [SEP]  provide some discussion
ICLR_2020_448,31579,"the paper is technically sound and, for the most part ,.",soundness [SEP] positive [SEP]  the paper technically sound [SEP]  the technically sound most part
ICLR_2020_448,31580,it is not clear from the description as to how is implemented here.,replicability [SEP] negative [SEP]  it not clear [SEP]  clear the description
ICLR_2020_448,31581,it would be great to include the inductive inference scheme mentioned right before eq .7 and compare it side by side with the standard amortized vi.,meaningful-comparison [SEP] negative [SEP]  mentioned eq [SEP]  it would be great [SEP]  compare side
ICLR_2020_1735,31635,it is also not clear to me why this paper begins with rank 1 quantization but ends up with scaled quantization. the approximation is loose without any guarantee. the main criticisms is therefore the lack of concrete evidences that those schemes are actually helpful and the relative simplicity (so the theoretical part of the paper are not sufficient by itself ).,soundness [SEP] negative [SEP]  sufficient itself [SEP]  clear me [SEP]  the lack concrete evidences [SEP]  those schemes are actually helpful [SEP]  the are helpful relative simplicity [SEP]  not the the relative simplicity theoretical part
ICLR_2020_1735,31636,one of my main concerns is the novelty of this paper. many of the solutions in the paper have already been discovered in literature ..,originality [SEP] negative [SEP]  my main concerns the novelty [SEP]  the many solutions discovered [SEP]  many have already been discovered literature
ICLR_2020_1735,31637,"moreover, some of the recent quantization methods are not compared. i am not an expert on neural network compression so i am not quite sure how the proposed method compares with the state of the art algorithms.",meaningful-comparison [SEP] negative [SEP]  the method how compares state [SEP]  moreover the recent quantization methods are not not compared [SEP]  the method how proposed compares
ICLR_2020_1735,31638,the writing is of good quality ..,clarity [SEP] positive [SEP]  the writing good quality
ICLR_2019_640,31803,quick initial improvements and good performance in the later stages the modification is simple and easy to implement ..,soundness [SEP] positive [SEP]  quick initial improvements good performance [SEP]  the the later stages modification
ICLR_2019_640,31804,the experimental results for adam are not convincing. the experimental evaluation is not convincing that this approach will lead to significant improvements in optimizing such modern models in practice. it does not provide any guidance on how to find p in a practical way that would lead to wide adoption of padam as a replacement for the established competitor optimizers.,soundness [SEP] negative [SEP]  the experimental results not convincing [SEP]  the experimental convincing evaluation [SEP]  not this approach will lead [SEP]  not approach will lead significant improvements [SEP]  not not does provide any guidance [SEP]  p how find
ICLR_2019_640,31805,this is potentially a very significant contribution which could become the next state of the art optimization method for deep learning ..,originality [SEP] positive [SEP]  a very significant contribution could become state [SEP]  could become the next state
ICLR_2019_640,31806,"given how simple the modification is, the novelty is also limited, and not sufficient relative to the low significance ..",originality [SEP] negative [SEP]  how simple the modification
ICLR_2019_640,31807,"the paper is very clear and well written, providing a good overview of existing approaches and explaining the specific issue it addresses ..",clarity [SEP] positive [SEP]  the paper very clear written [SEP]  a providing good overview [SEP]  the explaining specific issue
ICLR_2019_640,31808,"the proposed method shows improved performance across different datasets, including imagenet.",substance [SEP] positive [SEP]  the proposed method shows performance [SEP]  method shows improved performance [SEP]  including imagenet
ICLR_2019_640,31809,one possible explanation is that the training budget is not enough.,substance [SEP] negative [SEP]  one possible explanation the training budget
ICLR_2019_640,31810,missing an important baseline.,meaningful-comparison [SEP] negative [SEP]  missing an important baseline
ICLR_2019_640,31811,and so the work is very limited in terms of any significance impact.,motivation [SEP] negative [SEP]  the work very limited [SEP]  very limited terms
ICLR_2020_1101,32289,"this paper analyzes a simplified setting which is far from the original maml setting and yet derives conditions that are not very meaningful or useful i believe that the analysis is done on an overly simplified setting and easily breaks without such simplifications some of the simplifications for proving are empirical, so that the proof itself is not that rigorous ..",soundness [SEP] negative [SEP]  the not empirical proof [SEP]  is setting far the original maml [SEP]  the are believe analysis [SEP]  is an simplified setting analysis done overly
ICLR_2020_1101,32290,the derivations are correct.,soundness [SEP] positive [SEP]  the derivations correct
ICLR_2020_1101,32291,there are also some points in the main text that doesn't describe the setting clearly this statement can potentially be misleading. column vectors row vectors are mixed up ..,clarity [SEP] negative [SEP]  some points main text [SEP]  the does n't n't describe setting
ICLR_2020_1101,32292,and the paper is nicely presented. the paper is well written and easy to follow ..,clarity [SEP] positive [SEP]  the paper is nicely presented [SEP]  the paper is nicely presented
ICLR_2020_1101,32293,"but i am not completely sure of their impact i am not sure with the practical significance of it. the take away of this work is not in other words, it makes small contribution to the practical training of maml ..",motivation [SEP] negative [SEP]  the practical small contribution training [SEP]  i not not completely sure [SEP]  the the practical significance take [SEP]  is other words makes contribution [SEP]  is makes small contribution
ICLR_2020_1101,32294,"i think the paper is exploring an interesting direction in this work, the authors focused on an important problem training maml is kind of unstable and tricky, so that developing guidelines that stabilize maml or its first order approximations is of significance.",motivation [SEP] positive [SEP]  maml developing guidelines stabilize [SEP]  i think is [SEP]  think the paper is [SEP]  paper is exploring an interesting direction [SEP]  the authors focused [SEP]  an authors focused important problem training maml
ICLR_2020_1101,32295,"the paper would be way more convincing if the authors could use their findings to describe some more precise heuristics to tune the learning rates, and conduct a proper comparison of its performance with other methods the baselines should be compared, to support the effectiveness of this proposed algorithm ..",meaningful-comparison [SEP] negative [SEP]  the paper would be convincing [SEP]  authors could use their findings [SEP]  a conduct proper comparison
ICLR_2020_1589,32571,experiments were limited to face images from celeba database ..,substance [SEP] negative [SEP]  experiments were limited [SEP]  experiments were limited face images
ICLR_2020_1589,32572,"the authors are reasonably thorough, testing their model on a variety of problem settings and perform ablation studies on hyperparameters ..",substance [SEP] positive [SEP]  perform ablation studies [SEP]  the authors reasonably thorough [SEP]  testing their model [SEP]  a their model variety
ICLR_2020_1589,32573,while the proposal demonstrates improved empirical performance.,soundness [SEP] positive [SEP]  the proposal demonstrates [SEP]  improved empirical performance
ICLR_2020_1589,32574,the experimental results are not convincing.,soundness [SEP] negative [SEP]  the experimental results not not convincing
ICLR_2020_1589,32575,"it seems to be the only contribution of this paper. the idea of using invertible networks for estimating a specific forward process is not new, first, the novelty of this paper is trivial, in my opinion, the eq .2 is the only contribution of this paper ..",originality [SEP] negative [SEP]  it seems [SEP]  a estimating specific forward process
ICLR_2020_1589,32576,"as far as i know, this is the first work to use normalizing flows for inpainting and compressed sensing ..",originality [SEP] positive [SEP]  i know [SEP]  the first work use flows
ICLR_2020_1589,32577,taking an existing model and applying it to a problem where similar extensions have been tried) does not seem quite worthy of a full paper ..,motivation [SEP] negative [SEP]  a not not not seem quite worthy full paper [SEP]  taking an existing model not [SEP]  a applying problem similar
ICLR_2020_1589,32578,"there are a lot of claims in this paper have been made without clarification, i have huge troubles in understanding certain sentences.",clarity [SEP] negative [SEP]  understanding certain sentences [SEP]  huge troubles understanding sentences
ICLR_2020_1058,33060,first i think this mechanism itself's contribution is kind of incremental because this technique is well under the pgd adversarial training framework.,originality [SEP] negative [SEP]  first i think is [SEP]  first think this is mechanism [SEP]  this of incremental technique
ICLR_2020_1058,33061,"i like the proposed approach, in this paper ..",originality [SEP] positive [SEP]  i like approach [SEP]  like the proposed approach
ICLR_2020_1058,33062,i think the authors may need to compare their proposed method with 1 if possible ..,meaningful-comparison [SEP] negative [SEP]  i think [SEP]  think the authors [SEP]  compare their proposed method
ICLR_2020_1058,33063,"interesting topic, important subject.",motivation [SEP] positive [SEP]  interesting topic important subject
ICLR_2020_1058,33064,"and a very simple approach significant improvements in terms of training times. it is a fairly simple approach and seems to work well in practice, at least on the tasks that the authors have tried.",soundness [SEP] positive [SEP]  least the tasks [SEP]  a simple approach significant improvements fairly
ICLR_2020_1058,33065,"the math notation is a bit cumbersome, lots of undefined variables and functions used without properly giving enough background to the readers. please try to explain the equations and theorems more carefully. the writing, i think still needs some work, some of the math notation is mostly not properly explained, in sections 2.2 and 2.3. please provide references for the optimal control formulation in 2.2 some references to variables in the text are not made precise by identifying the variable in question k are not well discussed in section 2.4 reduce plot sizes and include more experimental details in the main text ..",clarity [SEP] negative [SEP]  more include experimental details [SEP]  functions used [SEP]  properly giving enough background [SEP]  the explain equations carefully [SEP]  not some writing still needs work [SEP]  not not not is properly mostly explained sections [SEP]  provide references [SEP]  the some 2 2 references optimal control formulation [SEP]  the not not are text made precise [SEP]  not not are section well discussed
ICLR_2020_1058,33066,the writing is very clear ..,clarity [SEP] positive [SEP]  the writing very clear
ICLR_2020_1058,33067,experiments are only on small scale toy datasets like cifar10 and mnist ..,substance [SEP] negative [SEP]  experiments small scale [SEP]  small scale toy datasets cifar10
ICLR_2020_1058,33068,some experimental details are missing ..,replicability [SEP] negative [SEP]  some experimental details are missing
ICLR_2018_53,33469,i found the relation to kanerva s original model interesting and well explained. the proposal of learning with a probabilistic memory is interesting the model appears novel and is interesting.,originality [SEP] positive [SEP]  the model appears novel [SEP]  found the relation interesting [SEP]  found kanerva s original model interesting explained [SEP]  the well explained proposal [SEP]  a interesting proposal probabilistic is memory
ICLR_2018_53,33470,the experiments and results on omniglot and cifar provide an interesting insight to the model's behaviour with the comparisons to vae and dnc also seem well constructed. qualitative results on sampling from the model using the cifar dataset.,substance [SEP] positive [SEP]  results well constructed qualitative [SEP]  the experiments results qualitative [SEP]  experiments an cifar provide interesting insight [SEP]  the an interesting insight model's behaviour
ICLR_2018_53,33471,overall i found the paper well written and reintroduced reframed a relatively underutilized but well theoretically founded model for modern use ..,soundness [SEP] positive [SEP]  overall i found [SEP]  overall found the paper
ICLR_2018_53,33472,and the framework proposed is elegant and cleanly explained ..,clarity [SEP] positive [SEP]  the framework proposed
ICLR_2018_53,33473,there is a mismatch in the training and evaluation procedure the implications of which i don't fully understand yet ..,clarity [SEP] negative [SEP]  the a mismatch training and evaluation procedure [SEP]  the the training and evaluation procedure implications
ICLR_2018_53,33474,"the experiments, however, are lacking in that they do not compare against other any recently proposed memory augmented deep generative models bornschein et al and li et. the paper should include a discussion and a comparison with the latter.",meaningful-comparison [SEP] negative [SEP]  a a discussion comparison [SEP]  experiments however are lacking they not [SEP]  a paper should include discussion
ICLR_2020_647,33845,significant reductions in average running time across the various datasets. they solve similar problems as in this paper and also provide promising results significant amount.,soundness [SEP] positive [SEP]  also provide promising results amount [SEP]  significant reductions average time [SEP]  solve similar problems
ICLR_2020_647,33846,"i feel the main weakness is that the empirical evidence provided are not thorough and sufficient, but i might be wrong. one aspect that is missing from this paper is the discussion of the cost of generation of the training dataset, and of the training of the gnn.",soundness [SEP] negative [SEP]  feel the main weakness is [SEP]  the empirical evidence provided not [SEP]  might be wrong wrong one aspect [SEP]  the the discussion cost
ICLR_2020_647,33847,well written paper with clear figures (especially figure 2) and explanations. i enjoyed reading it ..,clarity [SEP] positive [SEP]  it reading [SEP]  well written paper clear figures [SEP]  explanations enjoyed
ICLR_2020_647,33848,"novelty is somewhat low, as it is a straightforward application of existing ideas like gasse et al .neurips.",originality [SEP] negative [SEP]  like gasse et al [SEP]  somewhat low it [SEP]  a straightforward application existing
ICLR_2020_647,33849,given that the idea proposed by this paper is novel and interesting the paper is quite interesting and outperform its baseline by a.,originality [SEP] positive [SEP]  the idea proposed [SEP]  idea this is paper novel [SEP]  the paper paper interesting
ICLR_2020_647,33850,"it would be useful to present results on other datasets like mnist. as a baseline it would be good to include the results for branch and bound using strong branching. ( only 1 base model on 1 dataset) an ablation study for the fail safe strategy is needed. the authors should make sure to include the ablation study results, and a detailed discussion on training data generation time and training time in the final version of the paper ..",substance [SEP] negative [SEP]  present results [SEP]  results other the datasets ablation study [SEP]  it would be useful [SEP]  results the include [SEP]  using strong branching [SEP]  the is study needed authors [SEP]  results the ablation study authors should make sure sure [SEP]  a detailed discussion training time
ICLR_2020_647,33851,this is an important study that should be part of this paper ..,motivation [SEP] positive [SEP]  an important study should be part [SEP]  should be part
ICLR_2020_647,33852,"5 .there have been a few strong baselines in this field that the authors do not discuss and compare against the authors should discuss them in related works, and it is strongly encouraged to add at least one of them as a stronger baseline.",meaningful-comparison [SEP] negative [SEP]  a baseline at least stronger [SEP]  is it encouraged [SEP]  them related works
ICLR_2020_141,34135,"overall i find the idea interesting and the experimental results promising. the implementation of this idea is solid in the paper, relating it to theoretical concepts such as entropy regularized entropy transport problem though, technical flow of the paper is great and the proposed algorithm is valid ..",soundness [SEP] positive [SEP]  overall i find interesting [SEP]  the experimental results promising [SEP]  the results promising implementation [SEP]  idea is implementation this solid
ICLR_2020_141,34136,one missing point is to theoretically quantify the effect of the proposed regularization i am not sure if gans can achieve that the only problem of the paper is the improvement on the experiment is marginal ..,soundness [SEP] negative [SEP]  one missing point theoretically quantify effect [SEP]  the theoretically quantify effect
ICLR_2020_141,34137,"a about the theory the illustration of the problem in vae is interesting. this is a very interesting paper, i believe, a solid contribution to variational autoencoders. this is the most important section which can be of interest to the community to understand vaes '.",motivation [SEP] positive [SEP]  understand vaes [SEP]  the the illustration problem [SEP]  a interesting very paper believe [SEP]  i believe [SEP]  the be most important section can [SEP]  interest be can
ICLR_2020_141,34138,i am not sure the proposed algorithm is surely useful.,motivation [SEP] negative [SEP]  i not sure [SEP]  sure the proposed algorithm
ICLR_2020_141,34139,"b about the experiment the experimental section is clear and i encourage the authors to improve the exposition in this section as much as possible. introduction is written beautifully. point 2 is beautifully written. , and introduction is written very well, pointing out very important bold insights about the literature on unsupervised representation learning. i would say, it is a very well written paper, which is an enjoyable read the paper is well organized and well written. the point is clear.",clarity [SEP] positive [SEP]  the written point well organized [SEP]  the improve exposition much [SEP]  is introduction written beautifully point [SEP]  very pointing important bold insights [SEP]  i encourage authors [SEP]  a is is written very well would say paper
ICLR_2020_141,34140,"i found point 1 very confusing in page 4. there are minor grammar mistakes making some of sentences incoherent or confusing, in the paper. i think, overall, language can be improved. despite some of the grammar mistakes which can be easily fixed by proof reading.",clarity [SEP] negative [SEP]  proof reading [SEP]  found very confusing page [SEP]  minor grammar mistakes making [SEP]  the paper think [SEP]  i found point confusing [SEP]  overall language can be improved [SEP]  the grammar mistakes overall language can be improved
ICLR_2020_141,34141,"limitations, a good contribution on its own.",originality [SEP] positive [SEP]  limitations good contribution [SEP]  limitations a good contribution
ICLR_2020_141,34142,experimental evaluation is sufficient ..,substance [SEP] positive [SEP]  experimental evaluation sufficient
ICLR_2020_141,34143,thus i cannot say this is a fair comparison and because the superiority of the proposed algorithm is shown in only this point.,meaningful-comparison [SEP] negative [SEP]  thus i cannot not not say is [SEP]  thus cannot a not say is fair comparison [SEP]  this is superiority shown only point
ICLR_2020_20,34340,i am not sure if it is correct ..,soundness [SEP] negative [SEP]  i not sure [SEP]  sure it
ICLR_2020_20,34341,"compared to the old methods that train a separate generator, the performance of the proposed method is noticeably good as shown in fig 3.",soundness [SEP] positive [SEP]  compared the old methods
ICLR_2020_20,34342,"i think the description is not correct also, it is better if you can describe these metrics in detail in the appendix. there are many components that are missing from the discussion.",clarity [SEP] negative [SEP]  think the description is is not [SEP]  it better
ICLR_2020_20,34343,the baseline from using real data is missing.,meaningful-comparison [SEP] negative [SEP]  the baseline using data [SEP]  using real data
ICLR_2020_20,34344,the comparison to old methods seems fair ..,meaningful-comparison [SEP] positive [SEP]  the comparison old methods [SEP]  comparison old methods seems fair
ICLR_2020_20,34345,the motivation of the paper is clear. the structure of the network might be particularly interesting for people who are not in this field. the results are very interesting and worth a publication.,motivation [SEP] positive [SEP]  the the motivation paper [SEP]  the clear structure
ICLR_2020_20,34346,the statistical significance of the results in table 5 is missing ..,motivation [SEP] negative [SEP]  the the statistical significance results [SEP]  the the statistical significance results
ICLR_2020_20,34347,one weakness of the paper is in the experimental results especially in section 5.4.,substance [SEP] negative [SEP]  one weakness the paper
ICLR_2020_523,34500,i think the analysis on the property of the covariance matrix of the input data are valuable. this work has the potential to be of interest for the learning theory community on theoretical properties of recurrent neural networks ..,motivation [SEP] positive [SEP]  be interest [SEP]  i think are [SEP]  think the analysis are [SEP]  the the analysis property [SEP]  the work has potential
ICLR_2020_523,34501,t have sufficient expertise to determine whether all the proof steps are correct.,clarity [SEP] negative [SEP]  t have expertise [SEP]  have sufficient expertise
ICLR_2020_523,34502,this contribution is fairly weak and the practical value of their theoretical work would be much more convincing if they were to put more effort into this section ..,soundness [SEP] negative [SEP]  more put effort [SEP]  this contribution fairly weak [SEP]  fairly weak the practical value
ICLR_2019_47,35357,"and i think that this is a simple, reasonably workable approach with some nice theoretical benefits ..",soundness [SEP] positive [SEP]  i think is [SEP]  a simple reasonably workable approach nice
ICLR_2019_47,35358,assumption that the agent is given a model with no mismatch is very strong a weakness is that the setting is very clean in several ways.,soundness [SEP] negative [SEP]  very clean several ways [SEP]  a agent is given model
ICLR_2019_47,35359,i like the idea of scms i like the idea of counterfactual reasoning i like the idea of leveraging models in this unique way. the combination of those ideas is novel and enjoyable. the combination seems to be novel ..,originality [SEP] positive [SEP]  the this unique way combination [SEP]  like the idea [SEP]  leveraging models
ICLR_2019_47,35360,"it is mainly a combination of existing tools, but.",originality [SEP] negative [SEP]  it a combination [SEP]  a combination existing
ICLR_2019_47,35361,i wish the experiments were a little more varied.,substance [SEP] negative [SEP]  i wish were [SEP]  wish the experiments were
ICLR_2019_47,35362,integration with scms is interesting counterfactual variants of algorithms are clearly motivated and interesting the work is an interesting approach to a relevant problem. the issue of inaccurate dynamics models seems especially relevant an interesting and well motivated approach to an important problem.,motivation [SEP] positive [SEP]  an approach relevant problem issue seems important [SEP]  are clearly motivated the work [SEP]  interesting an the work approach [SEP]  approach relevant issue inaccurate dynamics models seems
ICLR_2019_47,35363,"paper is generally well written cons, and the paper is well written in an approachable, conversational style. the approach is technically sound and generally presented clearly, with.",clarity [SEP] positive [SEP]  paper generally well written [SEP]  paper generally well written cons the
ICLR_2019_47,35364,it would be better if the authors could clarify what is the prior distribution p exactly means in terms of cf pe algorithm and mb pe algorithm.,clarity [SEP] negative [SEP]  it would be better [SEP]  authors could clarify what is [SEP]  p exactly means terms
ICLR_2019_47,35365,related literature is covered well.,meaningful-comparison [SEP] positive [SEP]  related literature is covered well
ICLR_2019_47,35366,the counterfactual inference task is limited in scope and the dynamics and rewards are deterministic and assumed known work may not be easily reproducible due to the large number of pieces and incomplete specification of (hyper) parameter settings.,replicability [SEP] negative [SEP]  pieces incomplete specification [SEP]  task is limited scope [SEP]  assumed known work
ICLR_2020_450,35435,while there is room for improvement to further develop the method to the community ..,motivation [SEP] positive [SEP]  room improvement [SEP]  the further develop method
ICLR_2020_450,35436,the current version of the paper would be a good contribution.,originality [SEP] positive [SEP]  the the current version paper [SEP]  version a would be good contribution
ICLR_2020_450,35437,the authors present a counter example that it may not be true my only major complaint with the paper is that it is not clear to what extent the theoretical and practical problems are related ..,soundness [SEP] negative [SEP]  clear what extent [SEP]  a authors present counter example [SEP]  may not not be true true my only major complaint
ICLR_2020_450,35438,but does a good job at demonstrating them and shedding some light on the issue ..,soundness [SEP] positive [SEP]  does a good job [SEP]  demonstrating them [SEP]  shedding some light
ICLR_2020_450,35439,2 .the experiments are not extensively studied. experiments seem largely limited ..,substance [SEP] negative [SEP]  experiments are not not not extensively studied [SEP]  experiments are not not extensively studied
ICLR_2020_450,35440,"the experiments are thorough and fit into a growing body of evidence that the likelihoods of normalizing flows and other image based likelihood models may not be that informative or well calibrated, where past work has focused on out of distribution detection ..",substance [SEP] positive [SEP]  the experiments thorough [SEP]  not where past work has focused [SEP]  not where work has focused distribution detection
ICLR_2020_450,35441,this could use some clarification. the experiments section is written very poorly. this section relies heavily on the supplement making it hard to read due to the constant back and forth between the results and details of the experiments.,clarity [SEP] negative [SEP]  the results details [SEP]  could use some clarification [SEP]  the supplement making hard
ICLR_2020_450,35442,comparisons on image data sets such as mnist and cifar10 alone are not convincing enough to establish generalizability of the proposed theory ..,meaningful-comparison [SEP] negative [SEP]  comparisons image data sets not [SEP]  image data sets such [SEP]  establish generalizability
ICLR_2019_205,35829,i think this is a good paper and solves an important problem where one usually had to sacrifice diversity to obtain stable training by adding a reconstruction loss ..,motivation [SEP] positive [SEP]  a adding reconstruction loss [SEP]  i think is [SEP]  a good paper solves problem [SEP]  an solves important problem [SEP]  obtain stable training
ICLR_2019_205,35830,"it seems that such a distribution may not capture the fact that multiple dimensions of the output multiple pixel intensities) are not independent conditioned on the input weak theoretical results there are empirical results to back that claim, but i strongly believe that the theoretical results fall short and feel out of place in the overall justification for the proposed method ..",soundness [SEP] negative [SEP]  the place overall justification [SEP]  it seems [SEP]  seems a such distribution not [SEP]  distribution may not not not capture the fact [SEP]  not the fact multiple dimensions [SEP]  not the conditioned input weak theoretical results [SEP]  results empirical back claim [SEP]  that back claim [SEP]  i strongly believe [SEP]  the theoretical results fall short
ICLR_2019_205,35831,"the analyses in section 4.4 are sound in derivation but not so much in the conclusions drawn presents a simple idea, complete with experiments for comparing diversity with competing methods ..",soundness [SEP] positive [SEP]  the analyses section [SEP]  sound derivation [SEP]  not drawn presents idea
ICLR_2019_205,35832,the paper is well written 2 .the paper is well written and easy to follow ..,clarity [SEP] positive [SEP]  the paper is is well written [SEP]  the paper is is well written 2
ICLR_2019_205,35833,"however, the major weakness of the paper is the lack of novelty of the core idea. lack of novelty and.",originality [SEP] negative [SEP]  lack novelty [SEP]  the the major weakness paper [SEP]  the the paper lack
ICLR_2019_205,35834,the analysis in sec 4.4 is insightful.,originality [SEP] positive [SEP]  the analysis insightful
ICLR_2019_205,35835,"analysis on the experiments is a little insufficient, as shown below ..",substance [SEP] negative [SEP]  analysis the experiments
ICLR_2019_205,35836,2 .why only mlmm 1 is not compared with other methods on srgan celeba and glcic a.,meaningful-comparison [SEP] negative [SEP]  only mlmm is not not compared [SEP]  is not compared other methods
ICLR_2020_963,35995,"i am a bit sceptical as regards the generalization power of the generative model. but probably not a very well defined modeling choice. another crucial issue is the level of overfiting the current approach might have, because learning the prior implies this behaviour.",soundness [SEP] negative [SEP]  regards the generalization power [SEP]  the overfiting current approach [SEP]  implies this behaviour
ICLR_2020_963,35996,i think that the proposed model is a rather good practical approach the experiments are rather convincing better density mapping without over regularised latent variables.,soundness [SEP] positive [SEP]  rather are convincing better density mapping [SEP]  i think is [SEP]  think the proposed model is [SEP]  a the proposed model rather good practical approach
ICLR_2020_963,35997,"5 .i think that the first paragraph of sec .2 and some parts of the next paragraph need improvement. the main disadvantage of the paper is its language. there are many typos and difficult to follow sentences. the language in the paper is a bit off. the introduction should be re written. .i find it confusing. there are numerous typos and half missing sentences (too many to list all i think it would also make sense to rework section 1 and 2 as, currently, they both present introduction, motivation, and related works. the very first sentence of the introduction misses an ending ..",clarity [SEP] negative [SEP]  the the paragraph next need improvement main disadvantage [SEP]  the paper its language [SEP]  many typos difficult follow [SEP]  follow sentences [SEP]  the language sentences half missing [SEP]  would also make sense [SEP]  the first sentence related works very
ICLR_2020_963,35998,the construction of the objective and motivation behind is rather clear. this is very well done and provides the reader with a good understanding of the behaviour of both models ..,clarity [SEP] positive [SEP]  the a good understanding behaviour [SEP]  the provides reader [SEP]  the a reader good understanding
ICLR_2020_963,35999,", i find the idea quite interesting 3 that the paper is interesting from the engineering perspective.",originality [SEP] positive [SEP]  i find interesting is [SEP]  find the idea interesting is [SEP]  find the idea quite interesting paper
ICLR_2020_963,36000,and it lacks novelty as the method itself is quite incremental (replacing a vae with an ae). my main concern is the lack of novelty in the proposed method ..,originality [SEP] negative [SEP]  lacks novelty [SEP]  a replacing vae [SEP]  lack the my main concern
ICLR_2020_963,36001,"first, more analysis of the model would be helpful. the experimental part is the.",substance [SEP] negative [SEP]  more analysis the model [SEP]  first analysis the would be helpful helpful experimental part
ICLR_2020_963,36002,"method, which is extensively and thoroughly evaluated paper's main strength.",substance [SEP] positive [SEP]  method is strength [SEP]  is extensively and thoroughly evaluated paper's main strength
ICLR_2020_963,36003,the paper presents a well motivated.,motivation [SEP] positive [SEP]  the paper presents motivated
ICLR_2020_305,36154,this idea is novel in gcn field. the reader finds that the proposed approach is interesting ..,originality [SEP] positive [SEP]  this idea novel [SEP]  novel gcn field [SEP]  is the reader finds
ICLR_2020_305,36155,in terms of implementation the concatenation in eq 6 seems to be the only major change to gat. i m not sure if this is a major advance.,originality [SEP] negative [SEP]  m a major not not sure advance [SEP]  terms implementation [SEP]  the be only major change
ICLR_2020_305,36156,overall this paper addressed its core ideas clearly and made proper experiments and analysis to demonstrate the superiority against existing counterparts. clear performance improvements on prior state of the.,soundness [SEP] positive [SEP]  clear performance improvements prior state [SEP]  overall paper addressed its core ideas clearly [SEP]  made proper experiments [SEP]  demonstrate the superiority
ICLR_2020_305,36157,"whereas the use of random fourier features (rff) is well justified, a limitation is that it is based on a stationarity assumption. .6 is not very clear.",soundness [SEP] negative [SEP]  a is based stationarity assumption [SEP]  a is well justified limitation [SEP]  is it based
ICLR_2020_305,36158,the baselines compared in this paper seems to be too weak. eq 12 is not a sufficiently clear and self contained recap of prior work ..,meaningful-comparison [SEP] negative [SEP]  self contained recap [SEP]  the baselines compared [SEP]  baselines this paper seems
ICLR_2020_305,36159,experimental results are also favorable. art is visible in both transductiveinductive settings and nodeedge related tasks.,substance [SEP] positive [SEP]  experimental results favorable [SEP]  favorable art [SEP]  visible both transductiveinductive settings nodeedge related
ICLR_2020_305,36160,dynamic graphs are an important but challenging data structure for many problems. dealing with the inductive setting is an important advantage ..,motivation [SEP] positive [SEP]  dynamic graphs important structure [SEP]  dealing the inductive setting [SEP]  an important the inductive setting advantage
ICLR_2020_305,36161,3 .writing .the english is rather flaky throughout. the paper is rather hard to follow and ambiguous. a few specific things that are not explained so well 4.4 the relationship between t i and the neighbours of the target node in eq.,clarity [SEP] negative [SEP]  3 writing rather flaky [SEP]  a follow ambiguous few specific things [SEP]  the are not not explained well relationship
ICLR_2019_1527,36189,the attack methods are clearly and extensively described and the paper is well organized overall ..,clarity [SEP] positive [SEP]  the attack methods extensively described [SEP]  the paper is organized
ICLR_2019_1527,36190,the significance of the three classes of attacks is not properly explained the organization of section 4 makes the paper difficult to read the presentation of the experimental section can be improved to ensure the analysis points out the relevant takeaways. figure 5 is improperly referenced in the main body of the paper.,clarity [SEP] negative [SEP]  the the significance three classes [SEP]  the significance is not not not not properly explained organization [SEP]  the read presentation [SEP]  the ensure analysis
ICLR_2019_1527,36191,strong original contributions are not found in this work while i do not think lack of original contributions is a minus for this type of paper.,originality [SEP] negative [SEP]  contributions are not not found this work [SEP]  not is do think lack [SEP]  strong original contributions contributions not
ICLR_2019_1527,36192,"to the best of my knowledge, the authors propose novel kinds of attacks as well as novel attack algorithms on rl agent ..",originality [SEP] positive [SEP]  best my knowledge [SEP]  the authors propose kinds [SEP]  authors propose novel kinds
ICLR_2019_1527,36193,one concern is that the connections of each attack setting to a specific threat scenario in the real world are not discussed in this paper ..,substance [SEP] negative [SEP]  connections are not not discussed this paper [SEP]  each attack setting [SEP]  a setting specific threat scenario
ICLR_2019_1527,36194,"for this type of security research, contribution becomes weak without a connection to a threat in the real world ..",motivation [SEP] negative [SEP]  a a connection threat [SEP]  this type security research [SEP]  a contribution becomes weak weak connection
ICLR_2019_1527,36195,would be useful for many researchers the need for effective ways to quickly generate adversarial attacks in rl is clear the problem considered is certainly significant ..,motivation [SEP] positive [SEP]  many researchers the need [SEP]  quickly generate adversarial attacks
ICLR_2019_1527,36196,the summarization of the attack scenarios against rl is high quality and the results shown of different attack strategies against rl based on modifying the.,soundness [SEP] positive [SEP]  attack shown different strategies [SEP]  the results shown
ICLR_2019_1527,36197,"the difficulty of generating attacks in each of these classes and the need for new algorithms is not explained properly. the presentation and experiments leave me unconvinced that the presented approaches are a significant step ahead in attack generation (cons 1 .unclear presentation of technical contributions, experimental results do not support the key contributions of faster attack generation 2 i am also unconvinced of the relevance of blackbox attack algorithms given the nascent stage of deeprl.",soundness [SEP] negative [SEP]  not presentation experiments leave unconvinced [SEP]  the not leave unconvinced presented approaches [SEP]  the a presented approaches significant step [SEP]  not technical contributions experimental results [SEP]  the not not not contributions results do support key [SEP]  attack algorithms blackbox given stage
ICLR_2019_1527,36198,it would also be helpful to position prior work in the taxonomy ..,meaningful-comparison [SEP] negative [SEP]  it would also be helpful [SEP]  position prior work
ICLR_2019_1527,36199,section 4.1 gives a good overview observations analyzed by the agent.,meaningful-comparison [SEP] positive [SEP]  section gives observations [SEP]  section gives a good overview observations [SEP]  analyzed the agent
ICLR_2020_1734,36534,the paper is well written and clear.,clarity [SEP] positive [SEP]  the paper well written clear
ICLR_2020_1734,36535,but the text of the article and the experiments can be improved. the formatting of the article needs to be improved e.g. 5 .the quality of the pictures should be improved increase the captions font size in figure 2.,clarity [SEP] negative [SEP]  the the text article [SEP]  the text can be improved formatting [SEP]  the quality pictures
ICLR_2020_1734,36536,and the proposed architecture is novel to my knowledge ..,originality [SEP] positive [SEP]  the proposed architecture novel [SEP]  novel my knowledge
ICLR_2020_1734,36537,"in terms of novelty, separating the dataset into normal outliers noise is not novel overall, the novelty of this paper is in doubt ..",originality [SEP] negative [SEP]  terms novelty the [SEP]  separating the dataset not
ICLR_2020_1734,36538,using variance is not well motivated and it is referred to figure 4 the extension seems to be very straightforward.,motivation [SEP] negative [SEP]  using variance not [SEP]  not the extension seems
ICLR_2020_1734,36539,the proposed algorithm looks robust and well motivated.,motivation [SEP] positive [SEP]  the proposed algorithm looks robust
ICLR_2020_1734,36540,"similarly, why the reconstruction error is included in the latent representation (eq 5) is not clear. but the proposed method based on the variance assumption is too intuitive and not convincing. in addition, the experimental results on the very simple mnist task is very poor, putting the effectiveness of the proposed model in doubt as the proposed approach is a heuristic, the experiments should be done more persuasively.",soundness [SEP] negative [SEP]  the proposed method based [SEP]  the based variance assumption [SEP]  convincing addition [SEP]  the addition experimental results [SEP]  the putting effectiveness
ICLR_2020_1734,36541,"and also proper discussion of such similar works is required the refining process is also problematic, including more metrics used and more alternative algorithms considered ..",substance [SEP] negative [SEP]  more alternative algorithms considered [SEP]  proper discussion such works [SEP]  also discussion is is required the refining process [SEP]  including more metrics
ICLR_2020_1734,36542,"the sensitivity of the results to the choice of hyper parameters p0, p, and r is not clear, and how these parameters are chosen is not discussed ..",replicability [SEP] negative [SEP]  the the sensitivity results not [SEP]  parameters not how these are chosen
ICLR_2020_1734,36543,we expect that we should provide a comparison with other methods.,meaningful-comparison [SEP] negative [SEP]  we expect [SEP]  we expect [SEP]  a should provide comparison
ICLR_2019_294,37398,"this is a good paper, as we have good experimental evidence that the proposed method seems to have some advantage over baseline methods. and there is some experimental results to back it up ..",soundness [SEP] positive [SEP]  a good paper have evidence [SEP]  we have evidence [SEP]  good have experimental evidence [SEP]  the proposed method seems [SEP]  method seems some advantage baseline [SEP]  experimental some results back
ICLR_2019_294,37399,namely they should elaborate verbally on why learning the missing data distribution helps ..,soundness [SEP] negative [SEP]  namely they should elaborate verbally [SEP]  the why learning missing data distribution
ICLR_2019_294,37400,i would therefore suggest adding experiments where authors pick the mode of the distribution and estimate an error metric such as root mean square error (rmse or psnr https a major shortcoming of this paper is that the performance of the proposed approach is not fully supported by extensive experiments. some discussion about the potential extensions will also be helpful.,substance [SEP] negative [SEP]  experiments extensive some discussion [SEP]  i would therefore suggest [SEP]  adding experiments [SEP]  the is performance not [SEP]  experiments is performance not not not fully supported extensive
ICLR_2019_294,37401,missing data imputation using generative adversarial nets provides an excellent benchmark dataset the experiment results are sufficient to demonstrate the advantages of the proposed method.,substance [SEP] positive [SEP]  the demonstrate advantages [SEP]  missing data imputation using nets
ICLR_2019_294,37402,"i also found the 'marketing' presentation of the algorithm little misleading, especially in the introduction.",clarity [SEP] negative [SEP]  i also found presentation [SEP]  also found the marketing presentation [SEP]  the misleading introduction
ICLR_2019_294,37403,", the paper is well organized.",clarity [SEP] positive [SEP]  the paper well organized
ICLR_2019_294,37404,"overall, what i am trying to say is, the key idea of this paper that is learning the mask distribution is not well motivated in this paper ..",motivation [SEP] negative [SEP]  what am trying [SEP]  i am trying [SEP]  is the learning mask distribution
ICLR_2019_294,37405,to identify a plausible setting where such identifiability issues are not present the brilliance of this paper is in identifying this niche application of data imputation missing data incomplete data ..,motivation [SEP] positive [SEP]  identify a plausible setting [SEP]  where such identifiability issues are not not not not not present brilliance [SEP]  this identifying niche application data
ICLR_2019_294,37406,"the algorithm seems novel, it is a nice extension of ambientgan.",originality [SEP] positive [SEP]  the algorithm seems novel [SEP]  it seems novel novel [SEP]  a seems novel novel nice extension
ICLR_2019_456,37816,"the contribution is modest, essentially applying the same idea as the one proposed in maml to a variational objective, but.",originality [SEP] negative [SEP]  one proposed maml [SEP]  the contribution modest [SEP]  the essentially applying same idea
ICLR_2019_456,37817,the proposed method is new up to my knowledge. this is one of the first methods to do bayesian meta learning ..,originality [SEP] positive [SEP]  the proposed method new [SEP]  new my knowledge [SEP]  the first methods do learning
ICLR_2019_456,37818,the paper is relatively well written and the paper is clearly written and easy to read ..,clarity [SEP] positive [SEP]  the paper is well written [SEP]  the paper is well written
ICLR_2019_456,37819,section 2 and 3 could be written in a more compact way.,clarity [SEP] negative [SEP]  section could be written [SEP]  section a could be written more compact way
ICLR_2019_456,37820,the contributions clearly stated motivated.,motivation [SEP] positive [SEP]  the contributions clearly stated motivated
ICLR_2019_456,37821,authors conducted a good set of experiments.,substance [SEP] positive [SEP]  authors conducted set [SEP]  a authors conducted good set
ICLR_2019_456,37822,"but are missing comparisons bayesian versions of maml. however, the comparison is only with respect to maml and other techniques could have also be included to make it more meaningful. because the authors only compare with a non bayesian meta learning method (maml.",meaningful-comparison [SEP] negative [SEP]  comparison maml the [SEP]  it make meaningful [SEP]  the only authors compare
ICLR_2019_456,37823,"the derivation of the proposed method is rigorous and well justified. furthermore, the computational cost of the proposed method is described well enough ..",soundness [SEP] positive [SEP]  the derivation proposed [SEP]  the well justified computational cost
ICLR_2020_41,38099,as a non expert in the field and the empirical results also support the claims observations ..,soundness [SEP] positive [SEP]  a non expert the field [SEP]  the results also support claims observations
ICLR_2020_41,38100,be fully convinced. figure 3 is counterintuitive ..,soundness [SEP] negative [SEP]  be fully convinced figure
ICLR_2020_41,38101,i found the paper well written. provides decent background explanation i think the revised paper is of higher quality and clarity as a result.,clarity [SEP] positive [SEP]  higher quality clarity [SEP]  found the paper [SEP]  provides decent background explanation [SEP]  the paper think revised is
ICLR_2020_41,38102,the details should come in the main text using precise language and math formulation. page 4 is very hard to follow since it tries to give a textual description to mathematical concepts. i think it is important to provide the mathematical definition such that 1) it is easier to follow 2) the concepts are unambiguously defined ..,clarity [SEP] negative [SEP]  the concepts are unambiguously defined [SEP]  the details should come [SEP]  the main text using formulation [SEP]  using precise language and math formulation [SEP]  a give textual description
ICLR_2020_41,38103,it motivates the idea well by identifying challenges in a promising technique (random tranfsormations) i think this paper is well motivated the paper picks an important problem.,motivation [SEP] positive [SEP]  an paper picks important problem [SEP]  motivates the idea well [SEP]  identifying challenges [SEP]  i is think [SEP]  is think this paper
ICLR_2020_41,38104,but i think this paper could be improved by checking the performance over large datasets (.,substance [SEP] negative [SEP]  i think [SEP]  think this paper [SEP]  checking the performance
ICLR_2020_41,38105,the experiments are done on 3 datasets and 4 different adversarial attack techniques. the final experiment on end to end attack is interesting.,substance [SEP] positive [SEP]  the experiment final end [SEP]  the experiments are done [SEP]  experiments are done 3 datasets [SEP]  the experiment 4 different adversarial attack techniques final
ICLR_2020_41,38106,the details of the distribution classifier is missing from the paper.,replicability [SEP] negative [SEP]  the the details distribution classifier [SEP]  the details is missing paper
ICLR_2018_348,38776,"the representation is clear with detailed empirical the paper is very well written, nicely structured it is well written, well presented the paper is well written.",clarity [SEP] positive [SEP]  the empirical paper paper [SEP]  the representation clear [SEP]  the clear detailed empirical paper
ICLR_2018_348,38777,"but, in my opinion, a description of the learning framework should be given in the paper. section 5 should contain a discussion on complexity issues because it is not clear how the model can learn large graphs ..",clarity [SEP] negative [SEP]  learn not how model can large graphs [SEP]  my opinion a description [SEP]  a should section contain discussion
ICLR_2018_348,38778,2 .more details on how node embedding vectors are initialized. it is not clear to me how the node and graph embeddings are initialized and how they evolve along the learning process ..,replicability [SEP] negative [SEP]  how the evolve learning process [SEP]  2 more details node the
ICLR_2018_348,38779,"4 .the sequence ordering is important. , and examines an important problem that has so far not received much attention in the field. and addresses an important problem.",motivation [SEP] positive [SEP]  important an examines problem [SEP]  has far not not not received much attention [SEP]  important an examines problem
ICLR_2018_348,38780,the choice of er random graph as a baseline is too simplistic. it does not provide a meaningful comparison ..,meaningful-comparison [SEP] negative [SEP]  the choice random graph [SEP]  simplistic it does not not not provide comparison [SEP]  a does not not provide meaningful comparison
ICLR_2018_348,38781,provides extensive experimental evaluation.,substance [SEP] positive [SEP]  provides extensive experimental evaluation
ICLR_2018_348,38782,a short discussion of this result would make the paper stronger it is not clear whether models for large graphs can be learned. it should be said whether the node embeddings and graph embeddings for the output graph can be useful ..,substance [SEP] negative [SEP]  a short discussion this result [SEP]  clear models [SEP]  make paper stronger it
ICLR_2018_348,38783,the proposed model has several interesting novelties (mainly in terms of new applications experiments.,originality [SEP] positive [SEP]  the proposed model has novelties [SEP]  model has several interesting novelties [SEP]  terms new experiments
ICLR_2018_348,38784,training the generative model with fixed ground truth ordering was similarly performed in) and is thus not particularly novel ..,originality [SEP] negative [SEP]  training the generative model
ICLR_2018_348,38785,i am not convinced by the discussion on graph grammars in the second paragraph. the functions must be defined and their choice explained and justified it is not clear to me why the proposed updating framework for the embeddings allow to generate decision functions adapted to the graphs to be learned ..,soundness [SEP] negative [SEP]  i am not not convinced [SEP]  their choice explained [SEP]  not is justified it [SEP]  clear me proposed [SEP]  functions generate decision
ICLR_2018_573,38898,while the paper is well written.,clarity [SEP] positive [SEP]  the paper is well written
ICLR_2018_573,38899,the technical exposition is at times difficult to follow with some design decisions of the network layout being quite in its present form the manuscript doesn't seem quite ready for publication yet. writing needs to be improved lack of motivation not easy to follow technique details each subsection of section 3 starts with technique details without explaining why we do this. i also felt too much of the architecture is described in prose and could be more efficiently and precisely conveyed in equations ..,clarity [SEP] negative [SEP]  the technical exposition times [SEP]  times times difficult follow [SEP]  follow some design decisions [SEP]  ready publication writing [SEP]  technique details each subsection [SEP]  is described prose
ICLR_2018_573,38900,the motivation for combining self attention and autoregressive models remains unclear unfortunately the motivation part is missing.,motivation [SEP] negative [SEP]  the motivation combining attention [SEP]  combining self attention [SEP]  motivation autoregressive models remains unclear unfortunately
ICLR_2018_573,38901,"overall, the presented work looks quite promising and an interesting line of research. review autoregressive models are of large interest to the iclr community and exploring new architectures is a valuable contribution ..",motivation [SEP] positive [SEP]  a is valuable contribution [SEP]  overall the presented work looks promising line
ICLR_2018_573,38902,ad hoc and not well motivated it seems to me that the paper simply try to combine the transformer with pixelcnn rnn based image generation without a clear explanation why this is needed.,soundness [SEP] negative [SEP]  rnn based image generation [SEP]  seems me [SEP]  the paper simply try
ICLR_2018_573,38903,qualitatively the proposed method has good results in several tasks cons.,soundness [SEP] positive [SEP]  qualitatively the proposed method has results [SEP]  qualitatively method has good results
ICLR_2018_573,38904,expressing the involved operations in mathematical terms would help comprehend some of the technical details and add to the reproducibility of the proposed model.,replicability [SEP] negative [SEP]  expressing the involved operations [SEP]  the technical details add [SEP]  the add reproducibility
ICLR_2018_573,38905,another concern is the experimental evaluation. the celeba super resolution task furthermore seems fairly limited ..,substance [SEP] negative [SEP]  another concern experimental evaluation [SEP]  another the concern experimental evaluation
ICLR_2018_573,38906,the proposed model is evaluated in terms of visual appearance of samples and log likelihoods ..,substance [SEP] positive [SEP]  the proposed model is evaluated [SEP]  terms visual appearance
ICLR_2018_573,38907,"the experiments lack comparisons except the human evaluation, while the log likelihood improvement is marginal. i would like to see qualitative comparison between competing algorithms in the paper as well.",meaningful-comparison [SEP] negative [SEP]  experiments lack comparisons [SEP]  comparison see qualitative well
ICLR_2018_573,38908,using self attention in autoregressive models is an intriguing idea ..,originality [SEP] positive [SEP]  using self attention [SEP]  autoregressive models an intriguing idea
ICLR_2018_795,39142,the paper is well written.,clarity [SEP] positive [SEP]  the paper is well written
ICLR_2018_795,39143,", well motivated and the idea is very interesting for the computer vision and robotic communities ..",motivation [SEP] positive [SEP]  well motivated the idea [SEP]  the very interesting computer vision
ICLR_2018_795,39144,the technical contribution is original. the vision based agent localization approach is novel compared to the methods of the literature ..,originality [SEP] positive [SEP]  the technical contribution original [SEP]  the original vision based agent localization approach compared [SEP]  the compared methods
ICLR_2018_795,39145,the experimental validation of the proposed approach could be more convincing.,soundness [SEP] negative [SEP]  the experimental validation proposed
ICLR_2018_795,39146,the comparison is not rigorous in the sense that the proposed method estimates a 2d pose (3 dof) while orb slam and ekf slam are methods designed for 3d pose estimation (6 dof.,meaningful-comparison [SEP] negative [SEP]  the comparison not rigorous [SEP]  the rigorous sense proposed [SEP]  a pose method estimates 2d
ICLR_2018_795,39147,it would be interesting to test the proposed method on real data to measure its robustness in terms of noise sensor and in terms of motion blur. it would also be interesting to test the proposed method on datasets usually used in the slam community.,substance [SEP] negative [SEP]  the usually used slam community [SEP]  it would be interesting [SEP]  test the proposed method [SEP]  datasets usually used
ICLR_2020_690,39394,i also find the large table of number in table 1 to be rather impenetrable. i would recommend an alternative method of presentation to make the desired point there are many undefined terms and acronyms the description of visual masking in sec .4.3 was confusing and difficult to follow. for that i believe it is necessary to demonstrate that the present empirical results can be used to improve results of an image generation task i have a problem understanding some of the metrics used results are sometimes presented in a confusing way. there are some issues with the presentation i had a hard time understanding what exactly contrast sensitivity function and contrast masking are ..,clarity [SEP] negative [SEP]  a are time had hard [SEP]  would recommend an alternative method was [SEP]  the make desired point [SEP]  are many undefined terms [SEP]  the acronyms description [SEP]  the description visual masking [SEP]  the present demonstrate empirical results [SEP]  an image generation task have problem [SEP]  a are confusing results sometimes presented way [SEP]  a confusing some way issues
ICLR_2020_690,39395,otherwise the writing was reasonably clear. presentation is mainly clear ..,clarity [SEP] positive [SEP]  the writing reasonably clear [SEP]  reasonably clear presentation
ICLR_2020_690,39396,the findings of the paper are not terribly surprising and as discuss above it remains unclear whether the characteristics captured by the pe score are necessary or sufficient to explain the success of dnns to guide image generation tasks by providing a perceptual loss function ..,soundness [SEP] negative [SEP]  are not it remains unclear [SEP]  the explain success
ICLR_2020_690,39397,i believe the submission convincingly demonstrates a statistical association between the proposed pe score of a dnn feature and human perceptual quality assessments.,soundness [SEP] positive [SEP]  i believe assessments [SEP]  believe the submission assessments
ICLR_2020_690,39398,i am inclined to think that the impact potential of this paper would be rather low.,motivation [SEP] negative [SEP]  i inclined think [SEP]  think the impact potential
ICLR_2020_690,39399,application of methods from psychology neuroscience to artificial neural networks is an interesting avenue of work. better unsderstanding of perceptual metrics is of wide interest for various image processing applications.,motivation [SEP] positive [SEP]  interest wide various applications [SEP]  application methods [SEP]  methods various image processing applications
ICLR_2020_690,39400,experiments are not very exhaustive and at times a bit confusing ..,substance [SEP] negative [SEP]  experiments not not very exhaustive
ICLR_2020_690,39401,then the tuning process should be clearly explained ..,replicability [SEP] negative [SEP]  the then tuning process should be clearly explained
ICLR_2020_690,39402,there are no baselines and there is not much justification of computing the perceptual efficacy score the way it is computed it would be interesting to see a comparison of frequency and orientation tuning of features in a cnn to human cells.,meaningful-comparison [SEP] negative [SEP]  a comparison frequency [SEP]  is not not much justification [SEP]  a see comparison
ICLR_2018_773,39526,the paper's claims are correct.,soundness [SEP] positive [SEP]  the paper's claims correct
ICLR_2018_773,39527,"it is not clear how these results may be applied in practice or open new directions for future theoretical work. but as there are exponentially many regions corresponding to the different activations, it is unclear what the practical consequences of these theoretical observations are ..",soundness [SEP] negative [SEP]  the unclear practical consequences [SEP]  not clear how these results may be applied [SEP]  not how results may be applied practice [SEP]  it clear
ICLR_2018_773,39528,"the main claims results in the paper are not stated very clearly, and the authors are not clear about what the contributions as for section 4.2, the paper needs to do a better job of explaining exactly what is been shown in table 2. but the presentation is a bit awkward in places ..",clarity [SEP] negative [SEP]  the the main claims results paper not [SEP]  the are not not not clear authors [SEP]  a do better job [SEP]  what explaining exactly
ICLR_2018_773,39529,of the paper are or why they are useful.,motivation [SEP] negative [SEP]  the paper are [SEP]  are they useful
ICLR_2018_773,39530,i think the work is heading in an interesting direction.,motivation [SEP] positive [SEP]  i think [SEP]  think the work [SEP]  work is heading an interesting direction
ICLR_2018_773,39531,"at this point i feel that the theoretical results, which constitute the majority of the paper, are of limited novelty and or significance. theorem 2.5 is very related to results already proven for linear networks in earlier work, so there is little novelty here but i found it somewhat incremental ..",originality [SEP] negative [SEP]  it found incremental [SEP]  this point feel are [SEP]  feel the theoretical results are [SEP]  limited novelty significance [SEP]  theoretical results results [SEP]  novelty little found incremental
ICLR_2020_1165,39729,it is unclear why the neural network should learn eigenfunctions as the filters. the work is unfinished without a thorough analysis and discussion of these crucial aspects ..,soundness [SEP] negative [SEP]  it unclear [SEP]  why network should learn eigenfunctions
ICLR_2020_1165,39730,the fact that gabor wavelets are the eigenfunctions of convolution is sound. it provides good food for thought about what needs to be learned and what comes from the pre specified choice of architecture.,soundness [SEP] positive [SEP]  what needs [SEP]  provides good food [SEP]  good food thought
ICLR_2020_1165,39731,it is clearly written 2.,clarity [SEP] positive [SEP]  it is clearly written
ICLR_2020_1165,39732,it misses references to relevant works.,meaningful-comparison [SEP] negative [SEP]  it misses references [SEP]  misses references
ICLR_2020_1165,39733,it will be useful to add discussion and experimental results to show the advantage of this explanation in real applications ..,substance [SEP] negative [SEP]  it will be useful [SEP]  add discussion [SEP]  show the advantage
ICLR_2019_399,39931,"overall, i find the paper somewhat lacking in terms of evaluation. little is discussed on why the baseline results are only a few. only a few baseline results, in particular, at high compression size.",substance [SEP] negative [SEP]  particular high compression size [SEP]  overall i find [SEP]  overall find the paper [SEP]  a baseline results are only only few few
ICLR_2019_399,39932,the proposed approach is interesting.,originality [SEP] positive [SEP]  the proposed approach interesting
ICLR_2019_399,39933,and the performance on the benchmarks is good enough to demonstrate its effectiveness. interesting approach based on the bits back argument good performance trade off demonstrated through experiments cons.,soundness [SEP] positive [SEP]  demonstrate its effectiveness [SEP]  interesting approach based
ICLR_2020_2135,40203,although the idea of circumventing the quantization step required by the use of entropy coders is certainly valid and interesting the method is technically sound and.,soundness [SEP] positive [SEP]  the is interesting method method [SEP]  the idea circumventing step [SEP]  idea entropy coders is certainly valid interesting
ICLR_2020_2135,40204,"supporting arguments for decision although the motivation for circumventing the quantization step seems plausible, the authors show no evidence that the competing method 1, which does perform a post training quantization step, actually suffers from it the results simply don t support this claim.",soundness [SEP] negative [SEP]  support this claim [SEP]  supporting arguments decision [SEP]  authors show no evidence [SEP]  t results simply don
ICLR_2020_2135,40205,the quality of the empirical study can be improved. 3 .the experiments are very insufficient. 5 .ablation study is also needed ..,substance [SEP] negative [SEP]  the quality empirical study [SEP]  study insufficient 5 ablation is also needed
ICLR_2020_2135,40206,it doesn t discuss anything relevant to the contributions claimed in this paper ..,motivation [SEP] negative [SEP]  claimed this paper [SEP]  t doesn discuss [SEP]  the contributions claimed
ICLR_2020_2135,40207,i think the direction of the proposed method has good potential.,motivation [SEP] positive [SEP]  i think [SEP]  think the direction [SEP]  the direction proposed method has potential
ICLR_2020_2135,40208,the paper is clearly written.,clarity [SEP] positive [SEP]  the paper is clearly written
ICLR_2020_2135,40209,6 .there are many broken sentences and typos ..,clarity [SEP] negative [SEP]  6 there many sentences [SEP]  6 there many broken sentences
ICLR_2020_2135,40210,1 .the novelty is not clear ..,originality [SEP] negative [SEP]  the novelty not clear
ICLR_2020_2135,40211,"it only compares with one method, which is not enough. but it is not compared. png and jpeg should also be compared.",meaningful-comparison [SEP] negative [SEP]  it only compares [SEP]  only compares one method [SEP]  it only compares not
ICLR_2020_2135,40212,"so far, i cannot tell how your method works and which part works ..",replicability [SEP] negative [SEP]  far i cannot not not tell [SEP]  not how your method works [SEP]  not how method works which part
ICLR_2020_2057,40249,the studied problem is very interesting. this paper tackles a very interesting and important problem that might have huge implications for security and many other aspects ..,motivation [SEP] positive [SEP]  might have huge implications [SEP]  the studied problem very interesting [SEP]  problem this paper tackles [SEP]  problem very interesting paper a tackles and important
ICLR_2020_2057,40250,how the input space is partitioned the reviewer couldn't find any clue that the method actually worked for various settings 3 .the choice of parameters is unclear and not discussed ..,replicability [SEP] negative [SEP]  choice parameters [SEP]  method actually worked various settings
ICLR_2020_2057,40251,"i would like to see some analysis of the computational complexity and also some related experimental results. this field is not that thoroughly investigated the reviewer could not find the dataset they train (more experimental results supporting the argument of the authors are required. experimental results for more than two layered networks should be provided. the authors did not discuss whether the proposed approach can handle batchnorm layers. 2 .experimental evaluation is extremely limited it is all contained in just one paragraph. this analysis is very limited but for this experiments with deeper than 2 layers networks are necessary also, experimental evaluation should be completely re done and extended ..",substance [SEP] negative [SEP]  experimental are evaluation necessary [SEP]  i would like [SEP]  see some analysis [SEP]  the not not could find dataset [SEP]  experimental results train more [SEP]  related experimental results results [SEP]  results more than two layered networks should be provided [SEP]  the not not authors did discuss proposed approach [SEP]  not approach can handle batchnorm layers [SEP]  it extremely limited [SEP]  this experiments deeper
ICLR_2020_2057,40252,some theoretical explanation of the method is provided.,soundness [SEP] positive [SEP]  some the theoretical explanation method
ICLR_2020_2057,40253,the information the experiments conveys is too small to convince the argument of the author. the immediate question here is why this algorithm is not applied to sufficiently deep nn.,soundness [SEP] negative [SEP]  the the information experiments [SEP]  the convince argument [SEP]  is why this algorithm not not not applied
ICLR_2020_2057,40254,the author should clarify the novelty and the strong points of the works compared to the mentioned work ..,meaningful-comparison [SEP] negative [SEP]  the work compared mentioned [SEP]  the author should clarify novelty [SEP]  the works compared
ICLR_2020_2057,40255,the algorithm's description is either incomplete or unclear. the paper looks rather incomplete to me and requires a major revision.,clarity [SEP] negative [SEP]  a requires major revision [SEP]  the algorithm's description incomplete [SEP]  the incomplete paper looks [SEP]  me requires revision
ICLR_2020_711,40318,i was not very clear on a couple of items.,clarity [SEP] negative [SEP]  i not not very clear
ICLR_2020_711,40319,and the results appear convincing the authors did a very good job ..,soundness [SEP] positive [SEP]  the results appear [SEP]  the convincing authors [SEP]  a did very good job
ICLR_2020_711,40320,"finally, why the proposed method can be better than others is not well explained and clarified ..",soundness [SEP] negative [SEP]  finally why the proposed method can be better [SEP]  finally why method can be better better others
ICLR_2020_711,40321,i would have liked a little bit more explanation about the implementation details though.,replicability [SEP] negative [SEP]  i would have liked explanation though [SEP]  would have a liked little bit more explanation though
ICLR_2020_711,40322,the work seems to be an incremental extension of yu huang (2019b) and phrased as a nas algorithm. it is hard for a reader to see novelties there.,originality [SEP] negative [SEP]  see reader novelties there [SEP]  the work seems
ICLR_2020_711,40323,references are given wherever needed and all the closest related work is covered sufficiently ..,meaningful-comparison [SEP] positive [SEP]  references are given [SEP]  wherever needed all the closest related work
ICLR_2020_711,40324,the experimental part conducts several ablation studies which supports their various decisions ..,substance [SEP] positive [SEP]  the experimental part conducts studies [SEP]  part conducts several ablation studies [SEP]  supports their various decisions
ICLR_2020_711,40325,"ps also deteriorates the performance of learning models on the validation testing set overall, the paper is too experimental ..",substance [SEP] negative [SEP]  the validation testing set overall [SEP]  also deteriorates the performance [SEP]  learning models
ICLR_2018_619,40540,"the task proposed in the paper is interesting but the study made is somewhat limited but the study is not comprehensive yet 2 need to visualize the input data space, with the training data, test data, the 'gaps' in training data.",substance [SEP] negative [SEP]  the visualize input data space [SEP]  the task paper is interesting gaps [SEP]  the study made not
ICLR_2018_619,40541,the regularization proposed is quite simple and already known overall nothing really new was discovered or proposed.,originality [SEP] negative [SEP]  the regularization proposed [SEP]  already known overall nothing
ICLR_2018_619,40542,1 .the idea is interesting.,originality [SEP] positive [SEP]  idea interesting
ICLR_2018_619,40543,a more detailed comparison with all previous regularization scheme would be much needed ..,meaningful-comparison [SEP] negative [SEP]  a more detailed comparison previous scheme
ICLR_2018_619,40544,it works better on this example but it's not clear at all why such analysis does not seem to shed much light on anything.,soundness [SEP] negative [SEP]  not shed much light [SEP]  it works better not [SEP]  not not not why such analysis does seem
ICLR_2020_790,40618,"this paper was extremely hard to read or comprehend. it s riddled with typos, inaccurate notations and undefined variables (see below for a. the authors will need to significantly polish and improve the presentation of the paper. the notation therein is extremely unclear. without a clear definition of the algorithm, it s completely unclear what the proposed method does. the paper needs a lot more polish and proof reading to make this paper presentable. the proposed approach is completely cryptic, with clearly not enough definition of the notations the algorithm deals with ..",clarity [SEP] negative [SEP]  not definition completely cryptic clearly enough [SEP]  this paper extremely hard read [SEP]  the authors will need [SEP]  the improve presentation [SEP]  extremely notation the unclear [SEP]  proof reading [SEP]  paper the proposed make presentable approach
ICLR_2020_790,40619,the net result is that algorithm is undefined.,replicability [SEP] negative [SEP]  the net result undefined [SEP]  algorithm undefined
ICLR_2020_790,40620,the proposed algorithm is not clear ..,soundness [SEP] negative [SEP]  the proposed algorithm not clear
ICLR_2020_790,40621,the authors need much more experimentation to bolster their claims in the paper. 2 .there is only one dataset for the comparison of the performance of different graph neural networks. more datasets are needed to thoroughly verify the performance of the proposed ballistic graph neural network ..,substance [SEP] negative [SEP]  the performance graph neural network thoroughly verify proposed ballistic [SEP]  authors need much more experimentation
ICLR_2020_790,40622,"this section should at least introduce other works in the field of graph embedding, such as those reported as baselines.",meaningful-comparison [SEP] negative [SEP]  reported baselines [SEP]  section should least introduce other works [SEP]  other the works field
ICLR_2019_12,40838,sufficient experiment evidence cons the authors are suggested to include more state of the art transfer learning methods in order to make the results more.,substance [SEP] negative [SEP]  include more state [SEP]  the more make results
ICLR_2019_12,40839,but there are several practical treatments that are questionable. is not well defined the claim that leap learns faster than a random initialization for breakout is not convincing at all ..,soundness [SEP] negative [SEP]  are several practical treatments [SEP]  the is is well defined claim
ICLR_2019_12,40840,"3 .the set theta is not very well defined, and sometimes misleading ..",clarity [SEP] negative [SEP]  the set theta not not well defined misleading
ICLR_2019_12,40841,"overall, the paper is well presented ..",clarity [SEP] positive [SEP]  overall the paper is well presented
ICLR_2019_12,40842,"the details of the experiments such as parameter configurations are missing, which makes the results not easy to be reproduced ..",replicability [SEP] negative [SEP]  the the details experiments [SEP]  the experiments such [SEP]  the makes results not not easy
ICLR_2018_48,41417,"the significance of the attention mechanism has not been studied in the experiments second, the experimental set up on the cora and citeseer data sets should be properly randomized ..",substance [SEP] negative [SEP]  the the significance attention mechanism not [SEP]  the significance has not not not been studied experiments second [SEP]  the experimental set
ICLR_2018_48,41418,state of the art results on three datasets. experiments are very well described and performed.,substance [SEP] positive [SEP]  state the art results [SEP]  state the art results
ICLR_2018_48,41419,they have compared with graphsage only on ppi dataset. kipf i found the lack of comparison to previous works on attention and on constructions of nn for graph data are missing. however as explained earlier some comparisons are needed it might also be a good idea to compare your method to something like lle (locally linear embedding)..,meaningful-comparison [SEP] negative [SEP]  your method something [SEP]  the found lack [SEP]  previous works some comparisons [SEP]  explained some comparisons [SEP]  are it however earlier comparisons needed [SEP]  a might also be good idea [SEP]  compare your method
ICLR_2018_48,41420,interesting combination of attention and local graph representation learning. the authors provide a fair and almost comprehensive discussion of state of the art approaches ..,soundness [SEP] positive [SEP]  a and fair almost comprehensive discussion state [SEP]  interesting combination attention [SEP]  the authors provide discussion [SEP]  a and authors provide fair almost comprehensive discussion
ICLR_2018_48,41421,well written paper. it conveys the idea clearly. i found the paper clearly written and very well presented. overall i liked the paper and the presentation nothing groundbreaking here but still interesting enough and well explained.,clarity [SEP] positive [SEP]  the presentation groundbreaking here interesting [SEP]  well written paper conveys idea clearly [SEP]  conveys the idea clearly [SEP]  paper the found
ICLR_2018_48,41422,i find the idea to use the multi head attention very interesting.,originality [SEP] positive [SEP]  i find idea [SEP]  find the idea [SEP]  the use multi head attention interesting
ICLR_2018_48,41423,the comparison makes sense but it also shows that the ideas presented here are less novel than they might initially seem ..,originality [SEP] negative [SEP]  novel they might initially seem [SEP]  comparison makes sense [SEP]  the ideas presented here
ICLR_2019_539,41876,the paper is easy to read and follow ..,clarity [SEP] positive [SEP]  the paper easy read
ICLR_2019_539,41877,the paper in its current form is not ready for publication when and where such a technique makes sense the interface for pvars is not entirely clear section 2 could provide more details such that it would read as a tutorial on pvars ..,clarity [SEP] negative [SEP]  a read such would tutorial [SEP]  the paper current form not [SEP]  is not when where technique makes sense [SEP]  the not sense interface [SEP]  not could provide more details [SEP]  it read such would
ICLR_2019_539,41878,"in my opinion, the main problem of the paper is that the contributions are not clear ..",originality [SEP] negative [SEP]  my opinion main problem [SEP]  my opinion the main problem
ICLR_2019_539,41879,interesting intriguing idea brushed off as if unimportant the idea of while the idea may be appealing the idea is very interesting however.,originality [SEP] positive [SEP]  idea idea unimportant the [SEP]  interesting intriguing idea brushed [SEP]  idea brushed as if unimportant the
ICLR_2019_539,41880,in my opinion the paper should be more focused on detailing the commands of use of predictive variables and emphasising the advantages with respect to existing methods problems inherent to the proposed technique are not properly addressed.,soundness [SEP] negative [SEP]  the problems inherent proposed technique [SEP]  the emphasising advantages [SEP]  existing methods problems problems inherent
ICLR_2019_539,41881,the limitations properly addressed and discussed and the implications of the technique honestly described.,soundness [SEP] positive [SEP]  the limitations properly addressed [SEP]  the discussed implications
ICLR_2019_539,41882,pvars is potentially interesting and worth exploring and worth studying.,motivation [SEP] positive [SEP]  pvars potentially interesting
ICLR_2019_539,41883,the paper does not address several problems inherent to the technique.,motivation [SEP] negative [SEP]  the paper does not not not address problems [SEP]  the not problems inherent technique
ICLR_2020_2136,41910,the extension to visual planning imitation learning was very interesting explores differences between sequential and hierarchical prediction models weaknesses questions suggestions novel latent method for goal conditioned prediction (sequential and hierarchical) really cool experiments on navigation using the predicted frames this paper proposes a novel latent variable method for goal oriented video prediction which is then used to enable an agent to go from point a to point b. i feel this paper brings nice insights useful for the model based reinforcement learning literature where the end goal can be guided by an.,originality [SEP] positive [SEP]  the learning model insights useful based reinforcement literature [SEP]  the extension visual planning [SEP]  sequential and hierarchical prediction models weaknesses suggestions [SEP]  really cool experiments experiments [SEP]  a novel latent method paper proposes variable [SEP]  is prediction goal variable oriented video then used
ICLR_2020_2136,41911,"form, is marginal at best.",originality [SEP] negative [SEP]  form marginal
ICLR_2020_2136,41912,"missing baseline .i would be good to compare against them for better assessment of the predicted videos it would be good if the authors can include the suggested video prediction baseline from wichers et al. , 2018 in their quantitative comparisons ..",meaningful-comparison [SEP] negative [SEP]  baseline the video authors can include suggested prediction [SEP]  better assessment predicted [SEP]  baseline the authors can include
ICLR_2020_2136,41913,"the human 3.6m experiments are missing the baseline from wichers et al. , 2018 more experiments are required to support the claims of the paper as well. the authors should present additional quantitative evaluation to show that the predicted frames contain useful semantic information as well as more comprehensive experiments.",substance [SEP] negative [SEP]  frames contain useful semantic information [SEP]  the experiments are missing baseline [SEP]  experiments are more required [SEP]  the support claims well [SEP]  the authors should present evaluation [SEP]  authors should present additional quantitative evaluation [SEP]  the predicted frames contain information
ICLR_2020_2136,41914,image rather than predefined rewards.,motivation [SEP] positive [SEP]  image predefined rewards
ICLR_2020_2136,41915,"the motivation behind the paper is not clear. their implementation, however, is motivated by their application and therefore these models are usually only conditioned on the start frames the authors did not provide a suite of applications where such a model can be useful. impact of the paper, in the current and for sure does not meet the requirements for a prestigious conference such as iclr.",motivation [SEP] negative [SEP]  the a requirements prestigious conference [SEP]  the the motivation paper not [SEP]  clear their implementation [SEP]  is their implementation however motivated application [SEP]  a not not not authors did provide suite [SEP]  be not model where can useful useful impact [SEP]  the current sure [SEP]  the not not not impact does meet requirements
ICLR_2020_2136,41916,the used metrics are not a good evaluation metric for frame prediction as they both do not give us an objective evaluation in the sense of the semantic quality of predicted frames.,soundness [SEP] negative [SEP]  the not evaluation objective sense [SEP]  the used metrics not good evaluation [SEP]  metric a not good evaluation predicted frames
ICLR_2020_2136,41917,the authors provided the code which is always a plus ..,soundness [SEP] positive [SEP]  the authors provided code [SEP]  the authors provided code [SEP]  a is always plus
ICLR_2020_2136,41918,"on quality of writing, the paper is well written but it can use a figure that demonstrates proposed architecture.",clarity [SEP] positive [SEP]  quality writing [SEP]  writing the paper [SEP]  it well written
ICLR_2020_279,41965,the extension seems quite simple and natural. the empirical results are good ..,soundness [SEP] positive [SEP]  the extension seems simple [SEP]  the natural empirical results
ICLR_2020_279,41966,"one concern is that the reasoning model, while been quite original, is not tested in large scale retrieval cases to assess its robustness ..",substance [SEP] negative [SEP]  one concern the reasoning model [SEP]  is model not not tested large scale retrieval cases [SEP]  not assess its robustness
ICLR_2020_279,41967,"the paper has very detailed and insightful ablation studies, including hop steps and hop attentions, and other graph structures ..",substance [SEP] positive [SEP]  the paper has studies [SEP]  paper has very detailed and insightful ablation studies [SEP]  including hop steps
ICLR_2020_279,41968,the method improves the current state of the art ..,originality [SEP] positive [SEP]  the method improves state [SEP]  the method improves current state
ICLR_2020_279,41969,1 has already been explored by previous works which should be discussed in the paper.,originality [SEP] negative [SEP]  has already been explored previous works [SEP]  be should discussed the paper
ICLR_2020_279,41970,i think it is important to compare directly against other transformer architectures.,meaningful-comparison [SEP] negative [SEP]  i think is [SEP]  think it is [SEP]  compare directly other transformer architectures
ICLR_2020_279,41971,"the model is described in a very detailed manner with contrasts drawn to previous models ,. i enjoyed reading section 2 as it very succinctly describes previous approaches and introduces transformer xh.",clarity [SEP] positive [SEP]  drawn previous models [SEP]  reading section [SEP]  previous succinctly describes approaches
ICLR_2020_279,41972,would be good to clarify this. our pipeline in table 1 is confusing.,clarity [SEP] negative [SEP]  our pipeline table
ICLR_2020_279,41973,provides excellent motivation for the decisions taken by the authors.,motivation [SEP] positive [SEP]  provides excellent motivation [SEP]  the decisions taken [SEP]  the taken authors
ICLR_2020_1144,42862,i found the observation very interesting while i think this paper makes an independent and useful contribution.,originality [SEP] positive [SEP]  paper makes an independent and useful contribution [SEP]  found the observation interesting [SEP]  i found interesting [SEP]  think this paper
ICLR_2020_1144,42863,and the supporting experiments confirm the hypothesis. but the intuition seems sensible. the presented results are impressive but have a few missing pieces.,soundness [SEP] positive [SEP]  the experiments confirm hypothesis [SEP]  the intuition seems sensible [SEP]  the intuition seems sensible sensible presented results
ICLR_2020_1144,42864,some of the claims are overblown since the results from lample et al .are not presented or discussed i was unclear on a few parts of the derivation for the regularizing losses.,soundness [SEP] negative [SEP]  a unclear few parts
ICLR_2020_1144,42865,"the tackled problem is important. overall, i think this paper makes a worthwhile contribution ..",motivation [SEP] positive [SEP]  a paper makes worthwhile contribution [SEP]  the tackled problem important [SEP]  i overall think [SEP]  overall think this paper
ICLR_2020_1144,42866,"my main concern is with regards to the experiments, which are clearly not enough detailled. additionally, i'd like to see some more detail about the robustness of the method ..",replicability [SEP] negative [SEP]  the detail some more robustness [SEP]  i d additionally like [SEP]  detail see some more
ICLR_2020_1144,42867,i cannot understand what nll is considered in the preliminary experiments ..,clarity [SEP] negative [SEP]  not is considered the preliminary experiments [SEP]  cannot understand nll
ICLR_2020_1564,43071,"this problem setting is very realistic and encountered in most problems, especially in temporally extended settings, the approach with restricting the policy class demonstrates decent empirical results although the direct method is very much comparable.",soundness [SEP] positive [SEP]  is approach demonstrates decent empirical results [SEP]  this problem setting
ICLR_2020_1564,43072,it is also not made plain what assumptions are being employed in order to allow for extrapolation ..,soundness [SEP] negative [SEP]  is also not not not made plain plain what assumptions [SEP]  not assumptions are being employed order
ICLR_2020_1564,43073,while the problem being solved is very relevant and their approach compares three different approaches to the deficient support problem and it considers an important problem of deficient support ..,motivation [SEP] positive [SEP]  problem an considers important [SEP]  the problem being solved [SEP]  their approach compares approaches [SEP]  compares three different approaches [SEP]  the problem being solved deficient support
ICLR_2020_1564,43074,i am not sure how this work is positioned with respect to approaches solving similar problems in the reinforcement learning land ..,motivation [SEP] negative [SEP]  i not not sure positioned [SEP]  approaches solving problems [SEP]  solving similar problems
ICLR_2020_1564,43075,i would appreciate some comparison positioning to such methods in the bandit setting as well. the proposed method was only compared to a few old benchmarks ..,meaningful-comparison [SEP] negative [SEP]  a method was only compared few old benchmarks [SEP]  would appreciate some comparison positioning well [SEP]  some comparison positioning such methods [SEP]  method the proposed was only compared
ICLR_2020_1564,43076,i found a few pieces of this paper confusing ..,clarity [SEP] negative [SEP]  i found pieces confusing [SEP]  found a few pieces confusing [SEP]  found this paper confusing
ICLR_2020_1564,43077,this paper is well written.,clarity [SEP] positive [SEP]  this is paper well written
ICLR_2020_1564,43078,i think this is a promising approach.,originality [SEP] positive [SEP]  i think is [SEP]  think is a promising approach
ICLR_2018_692,43100,i don't find the paper of high significance or the proposed method solid for publication at iclr.,motivation [SEP] negative [SEP]  method solid publication [SEP]  don't n't find the paper [SEP]  the proposed method method solid
ICLR_2018_692,43101,"the authors do not give a conclusive analysis under what condition it may happen. however, both these effects are only shown on a specific dataset, architecture, learning algorithm and hyper parameter setting. experiments are not described in detail.",substance [SEP] negative [SEP]  not not are experiments described detail [SEP]  a authors do not not not give conclusive analysis [SEP]  however both these effects are only shown
ICLR_2018_692,43102,many experiments which try to study the effect cons.,substance [SEP] positive [SEP]  many experiments try [SEP]  study the effect cons
ICLR_2018_692,43103,and there is lack of solid analysis or discussion behind these observations. the fact that the results only applies to cifar 10 dataset and could not be observed for imagenet or other architectures is disappointing and heavily takes away from the significance of this work. experiment design feels ad hoc and unstructured.,soundness [SEP] negative [SEP]  lack solid analysis [SEP]  lack solid analysis [SEP]  experiment design feels
ICLR_2018_692,43104,the authors also provide sufficient intuition for super convergence ..,soundness [SEP] positive [SEP]  the authors also provide intuition [SEP]  authors also provide sufficient intuition
ICLR_2018_692,43105,hutter in next section but do not compare it to their work.,meaningful-comparison [SEP] negative [SEP]  hutter next section [SEP]  do not not compare it [SEP]  do not compare their work
ICLR_2018_692,43106,"unfortunately, this paper feels to be hastily written and can only be read when accompanied with several references as key parts (clr) are not described and thus the work cannot be reproduced from the paper. the role and value of the many lr plots remains unclear to me. the terms are introduced but the paper misses the most basic formulas figures are not properly described.",clarity [SEP] negative [SEP]  paper not the misses most basic formulas figures [SEP]  unfortunately this paper feels [SEP]  are not not described the work [SEP]  are the terms introduced [SEP]  paper be not not thus the work cannot reproduced
ICLR_2018_692,43107,the paper does not maker clear how the exact schedules work ..,replicability [SEP] negative [SEP]  the paper does not not not maker clear [SEP]  the not how exact schedules work
ICLR_2020_1051,43696,"in general, the text is well written and easy to follow ..",clarity [SEP] positive [SEP]  general the text well written easy
ICLR_2020_1051,43697,"therefore, i am not sure about the technical contribution of this paper to the area. those extensions seem a bit incremental and are not well supported by the experimental results in the paper.",originality [SEP] negative [SEP]  the well supported experimental results [SEP]  the sure technical contribution [SEP]  those extensions seem incremental
ICLR_2020_1051,43698,"the authors didn t compare their method to kurth nelson redish (2009) in both pathworld and atari 2600, which seems insufficient to demonstrate the point that the extension is useful ..",meaningful-comparison [SEP] negative [SEP]  the is extension useful [SEP]  authors compare their method [SEP]  the demonstrate point
ICLR_2020_1051,43699,"moreover, the authors didn t conduct experiments on non hyperbolic discounting functions, which makes the claim that approximating non hyperbolic discounting functions is one of the paper s contributions.",substance [SEP] negative [SEP]  the s is paper contributions [SEP]  moreover authors conduct experiments [SEP]  the makes claim
ICLR_2020_1051,43700,unsubstantiated empirically a single hazard rate for the entire environment seems counterintuitive ..,soundness [SEP] negative [SEP]  unsubstantiated a empirically single hazard rate rate seems [SEP]  unsubstantiated the entire environment seems counterintuitive
ICLR_2020_1051,43701,the discovery that learning many action value functions with different exponential discounting rates as auxiliary tasks improves performance is quite interesting ..,motivation [SEP] positive [SEP]  the discovery learning functions [SEP]  learning many action value functions
ICLR_2020_1883,43961,"however, since the paper is mostly empirical in nature and based on algorithmic implementation, the experimental evaluation does not seem quite convincing for the following reasons 1. it is unclear why attentionxml and dismec are shown to be non scalable for amazon3m when they have shown to be evaluated on the bigger version of the same datasets in other works 1 .my main concern is that the proposed method seems to be a combination of a number of tricks.",soundness [SEP] negative [SEP]  a a combination number [SEP]  the paper is mostly empirical not [SEP]  the not not not seem quite convincing following reasons [SEP]  the proposed method seems
ICLR_2020_1883,43962,and the empirical results show improved.,soundness [SEP] positive [SEP]  the empirical results show
ICLR_2020_1883,43963,all the datasets used in the work are private and not publically available ..,substance [SEP] negative [SEP]  all the datasets used
ICLR_2020_1883,43964,2 .it is not clear why the authors did not to evaluate their approach on the standard datasets from the extreme classification repository http.,meaningful-comparison [SEP] negative [SEP]  not why the authors did [SEP]  not not evaluate their approach
ICLR_2020_1883,43965,it will be hard to be used in real applications ..,motivation [SEP] negative [SEP]  it will be hard [SEP]  be used real applications
ICLR_2020_1883,43966,3 .the writing and the organization of this paper needs to be improved. a .some notations are not clearly defined. b .several method names are not defined ..,clarity [SEP] negative [SEP]  not are clearly defined several method names [SEP]  the writing organization [SEP]  writing this paper needs
ICLR_2020_1883,43967,i really like the paper writeup.,clarity [SEP] positive [SEP]  i really like writeup [SEP]  really like the paper writeup
ICLR_2018_258,44045,the paper is very clearly written the experiments are very clearly presented and solidly designed. and the writing is good ..,clarity [SEP] positive [SEP]  the paper is clearly written [SEP]  the paper is clearly written experiments [SEP]  the solidly designed writing good
ICLR_2018_258,44046,and the proposal is very well placed in the context of previous methods for the same purpose ..,meaningful-comparison [SEP] positive [SEP]  the proposal is well placed [SEP]  the context previous methods
ICLR_2018_258,44047,it is still necessary to compare their computational complexity.,meaningful-comparison [SEP] negative [SEP]  it necessary [SEP]  compare their computational complexity
ICLR_2018_258,44048,"consequently, there is not a great degree of novelty in terms of the proposed method, and the results are only it is a little bit straight forward derived from the original binarization scheme.",originality [SEP] negative [SEP]  the derived original binarization scheme [SEP]  not a great degree novelty [SEP]  novelty terms
ICLR_2018_258,44049,slightly better than those of previous methods.,soundness [SEP] negative [SEP]  slightly better previous methods
ICLR_2018_258,44050,cons although the work seems convincing.,soundness [SEP] positive [SEP]  the work seems convincing
ICLR_2018_258,44051,the experiments are complete.,substance [SEP] positive [SEP]  the experiments complete
ICLR_2020_465,44219,"the paper has an extensive literature review, addresses an important problem, and has informative discussions ..",motivation [SEP] positive [SEP]  the paper has review [SEP]  paper has an extensive literature review [SEP]  an addresses important problem
ICLR_2020_465,44220,"it is well written and there are nice examples to illustrate the central ideas. the paper is clear, concise, and well written.",clarity [SEP] positive [SEP]  it is well written [SEP]  are nice examples [SEP]  the illustrate central ideas
ICLR_2020_465,44221,the writing in this paper is sometimes pompous. 2 .throughout the paper there is a confusing mix between ideas from economics and ideas from accounting ..,clarity [SEP] negative [SEP]  ideas economics [SEP]  the writing this paper [SEP]  a confusing mix ideas
ICLR_2020_1490,44261,my first concern about this work is its novelty ..,originality [SEP] negative [SEP]  my first concern this work [SEP]  this work its novelty
ICLR_2020_1490,44262,i like the idea proposed in the paper and strongly encourage the authors to seriously address the raised questions regarding experiments and comparisons.,originality [SEP] positive [SEP]  regarding experiments [SEP]  like the idea
ICLR_2020_1490,44263,"the paper would improve by comparing the quality of its latent representations with the recent unsupervised self supervised learning methods such as 1,2. the comparisons to baselines are unfair. fair comparisons should be performed against other latent variable models such as flow models and vaes with more interesting tasks, which will make the paper much stronger. but the latent activations are indeed a weak baseline considering that pixelcnn is so powerful a generator ..",meaningful-comparison [SEP] negative [SEP]  the comparing quality [SEP]  comparisons unfair fair should be performed [SEP]  the paper would improve
ICLR_2020_1490,44264,this paper is well written overall and the method is clearly presented ..,clarity [SEP] positive [SEP]  this paper well written overall [SEP]  well written overall the method
ICLR_2020_1490,44265,( please use equations not just words ).,clarity [SEP] negative [SEP]  use equations not words
ICLR_2020_1490,44266,"however, the experiments are not well designed.",substance [SEP] negative [SEP]  however the experiments are not not not not well designed
ICLR_2020_1490,44267,and the results are unconvincing. hidden activation used in this paper is unclear and lacking.,soundness [SEP] negative [SEP]  the results unconvincing [SEP]  hidden activation used
ICLR_2018_280,44268,the contributions are interesting.,originality [SEP] positive [SEP]  the contributions interesting
ICLR_2018_280,44269,and experimental results seem promising. very promising results with an interesting active learning approach to multitask rl.,soundness [SEP] positive [SEP]  experimental results seem [SEP]  an interesting active learning approach multitask
ICLR_2018_280,44270,but the paper is difficult to read due to many different ideas and because some algorithms and many important explanations must be found in the appendix.,clarity [SEP] negative [SEP]  the paper difficult read [SEP]  read due many different ideas [SEP]  the be algorithms must found appendix
ICLR_2018_280,44271,paper is overall well written clear cons.,clarity [SEP] positive [SEP]  paper is overall well written cons [SEP]  paper is overall well written clear cons
ICLR_2018_280,44272,"the gap is so large that i am not convinced on the fairness of the comparison. comparison only to a very basic baseline (i.e .uniform sampling) couldn't comparisons be made, in some way, to other multitask work.",meaningful-comparison [SEP] negative [SEP]  couldn't n't comparisons be made [SEP]  the fairness comparison n't [SEP]  e a i very basic baseline uniform sampling
ICLR_2018_280,44273,i do not see how the single output layer is defined ..,replicability [SEP] negative [SEP]  i do not not see [SEP]  do not see the single output layer
ICLR_2018_280,44274,in my opinion section 6 should be developped and more experiments should be done with the dua4c algorithm ..,substance [SEP] negative [SEP]  my opinion section should be developped [SEP]  should be developped more experiments [SEP]  should be experiments done the dua4c algorithm
ICLR_2018_280,44275,"this paper delivers an important reference point for future work towards achieving generalist agents, which master diverse tasks and represent complementary behaviours compactly at scale ..",motivation [SEP] positive [SEP]  this paper delivers point [SEP]  paper delivers an important reference point [SEP]  master diverse tasks
ICLR_2020_1374,44803,"overall, the paper is well organized and provides rigorous experiments with conclusions based on the empirical observations ..",soundness [SEP] positive [SEP]  provides rigorous experiments [SEP]  conclusions based
ICLR_2020_1374,44804,it is still doubtful whether those empirical results can be generalized as there is no analytical and thoughtful discussions ..,soundness [SEP] negative [SEP]  it is still doubtful [SEP]  doubtful those empirical results can be generalized [SEP]  results can be generalized no analytical and thoughtful discussions
ICLR_2020_1374,44805,"overall, i think the paper should be rejected as it suffers from not high enough level of novelty in proposed method. which is not enough while this paper can be improved in some key ways.",originality [SEP] negative [SEP]  paper be not can improved some key ways [SEP]  overall i think [SEP]  overall think the paper
ICLR_2020_1374,44806,it does make an interesting contribution.,originality [SEP] positive [SEP]  it does make contribution [SEP]  does make an interesting contribution
ICLR_2020_1374,44807,the paper is well written and the paper is easy to follow an the authors should also be credited for releasing code anonymously with which we could reproduce their results.,clarity [SEP] positive [SEP]  the an follow authors
ICLR_2020_1374,44808,but the way of reporting the results are not clear enough ..,clarity [SEP] negative [SEP]  the way reporting results not [SEP]  the reporting results
ICLR_2020_1374,44809,point the interesting problem.,motivation [SEP] positive [SEP]  point the interesting problem
ICLR_2020_1374,44810,"comparing to other baselines like rlls 1 is also missing in this table. t consider other metrics like the error in weight estimates which is considered in most of the prior work they don t compare their results with regularizations suggested on top of bbse, particularly azizzadenesheli et i must say that some other reviews were disappointingly lacking in thoroughness ..",meaningful-comparison [SEP] negative [SEP]  compare their results azizzadenesheli [SEP]  regularizations suggested [SEP]  i must say [SEP]  other must say some reviews
ICLR_2018_23,44950,the paper is largely well written and well motivated.,clarity [SEP] positive [SEP]  the paper largely well written motivated
ICLR_2018_23,44951,the overall setup is interesting i'm pretty sure this is the first paper to tackle this problem directly in general ..,originality [SEP] positive [SEP]  the overall setup interesting [SEP]  the first paper tackle problem [SEP]  this tackle problem
ICLR_2018_23,44952,( i find the authors' practical use cases convincing where one only has access to imperfect data in the first place and the empirical results are convincing. it has an important setting to begin with and the proposed method is clean and elegant albeit a bit simple. elegant and simple solution nice results and decent experiments (but see below the assumption that the measurement process and parameters are known is quite a strong one. the theoretical analysis is satisfactory ..,soundness [SEP] positive [SEP]  the theoretical analysis satisfactory [SEP]  i find cases are [SEP]  an important setting begin [SEP]  the proposed method is clean [SEP]  and results elegant bit simple simple solution nice [SEP]  the see assumption [SEP]  a one are process known quite strong
ICLR_2018_23,44953,i would make a suggestions for possible further experimental analysis the baseline experiments are a bit limited it's clear that such baselines would never produce samples which are any better than the fixed version which is fed into them ..,substance [SEP] negative [SEP]  the is better fixed version fed [SEP]  would make a suggestions are [SEP]  would baselines never never never never never produce samples
ICLR_2018_23,44954,i imagine it may sometimes also be hard to accurately model the measurement function of a device.,replicability [SEP] negative [SEP]  i imagine [SEP]  imagine it [SEP]  accurately model the measurement function
ICLR_2018_23,44955,this is an important research direction as it is not uncommon to get noisy measurements in the real world under different circumstances important problem this is a nice paper which deals with an important problem.,motivation [SEP] positive [SEP]  an important problem deals [SEP]  is an important research direction [SEP]  not get noisy measurements problem [SEP]  a nice paper deals
ICLR_2020_1887,44989,reviewer has concern about the scope and application value of the problem as a research paper ..,motivation [SEP] negative [SEP]  reviewer has concern [SEP]  reviewer has concern [SEP]  concern the scope and application value
ICLR_2020_1887,44990,"it's useful to discuss the speed of convergence in the attribute value adjustment iterations the task of predicting android button attributes, while practical, seems over simplified. and not very convincing results make the question the potential impact of this paper ..",soundness [SEP] negative [SEP]  the results make question impact [SEP]  it useful [SEP]  the attribute value adjustment iterations
ICLR_2020_1887,44991,"overall, the method is sensible and elegant, and could easily be applied to other domains ..",soundness [SEP] positive [SEP]  the method sensible [SEP]  could easily be applied other domains
ICLR_2020_1887,44992,reviewer would like to see some discussion or experiment data on how this affects the process and how did the current algorithm address it. reviewer suggests at least experiment with a set of common ui elements to proof the horizontal performance. and it is not clear how the model would perform with other and more sophisticated android components ..,substance [SEP] negative [SEP]  would how and perform not model other more sophisticated android components [SEP]  how affects the process address [SEP]  how the the process did current algorithm address [SEP]  a set common elements [SEP]  the proof horizontal performance
ICLR_2020_1887,44993,i found the paper very clear and well written ..,clarity [SEP] positive [SEP]  i found paper clear [SEP]  found the paper clear
ICLR_2020_1887,44994,while the idea of using synthetic data (which can be easily procedurally generated) to do this reverse engineer training is very clever.,originality [SEP] positive [SEP]  the idea using data [SEP]  using synthetic data [SEP]  do this reverse engineer training
ICLR_2020_1887,44995,are the baselines strong enough how about a direct comparison to some of the work listed in the second para on page 2.,meaningful-comparison [SEP] negative [SEP]  the baselines baselines strong enough [SEP]  a baselines strong enough direct comparison [SEP]  the work listed
ICLR_2020_2193,45010,my main concerns are the following representing words by distributions is not a novel idea.,originality [SEP] negative [SEP]  my main concerns following [SEP]  representing words [SEP]  a distributions not novel idea
ICLR_2020_2193,45011,there is therefore not a meaningful comparison to the most relevant previous work ..,meaningful-comparison [SEP] negative [SEP]  not a meaningful comparison most relevant work
ICLR_2020_2193,45012,word similarity experiments are not enough to justify this approach. the experiments seem a little weak. what is the advantage of vmf distribution.,soundness [SEP] negative [SEP]  word similarity experiments not not enough justify [SEP]  justify this approach [SEP]  experiments the seem weak [SEP]  seem weak what
ICLR_2020_2193,45013,the word is well exceptionally well motivated.,motivation [SEP] positive [SEP]  the word well exceptionally motivated
ICLR_2020_2193,45014,the connection between motivation and proposed method seems weak ..,motivation [SEP] negative [SEP]  the connection motivation [SEP]  connection proposed method seems weak
ICLR_2020_2193,45015,the vmf distribution is underexamined as tool for analyzing high dimensional semantic vector distributions.,substance [SEP] negative [SEP]  the vmf distribution is underexamined [SEP]  distribution is underexamined tool [SEP]  analyzing high dimensional semantic vector distributions
ICLR_2020_2193,45016,"it seems that the authors use the wrong template, which is not the template for iclr2020.",clarity [SEP] negative [SEP]  it seems [SEP]  the authors use template [SEP]  the authors use wrong template
ICLR_2020_1285,45289,"needs more diverse experiments (instead of grid worlds) to support the paper (as a result, the experimental evaluation should be much more thorough. and the experiment part is limited only tested on one simple scenario ..",substance [SEP] negative [SEP]  only tested one simple scenario [SEP]  needs more diverse experiments [SEP]  grid worlds support paper [SEP]  experiment the part is limited
ICLR_2020_1285,45290,it might be hard to express objectives using logic formulas in real world applications the word baseline here is misleading. the authors should more clearly explain this ..,clarity [SEP] negative [SEP]  the is misleading misleading authors [SEP]  it might be hard [SEP]  using logic formulas
ICLR_2020_1285,45291,the current contribution is rather limited in terms of methodology and shallow in terms of experimental evaluation. the only methodological novelty of proposed contribution is the idea of encoding the multi objective reward as a logical function.,originality [SEP] negative [SEP]  the encoding multi objective reward [SEP]  the current contribution rather limited [SEP]  experimental evaluation only novelty [SEP]  the idea encoding reward
ICLR_2020_1285,45292,the idea of modeling multi objective as a logical language is novel ..,originality [SEP] positive [SEP]  the idea modeling objective [SEP]  modeling multi objective
ICLR_2020_1285,45293,2 .the general claims made by the authors are not really supported by the experimental evaluation ..,soundness [SEP] negative [SEP]  general claims made not [SEP]  the made authors [SEP]  the claims are not not not really supported experimental evaluation
ICLR_2020_1285,45294,the major novelty of this paper is encoding the objective as a logical expression.,soundness [SEP] positive [SEP]  the major novelty this paper [SEP]  the novelty is encoding objective
ICLR_2020_1285,45295,"in particular, many details of their experimental setup are missing.",replicability [SEP] negative [SEP]  particular many details
ICLR_2020_1285,45296,lack of baselines experiments. it is possible to compare the performance with previous works when the final objective is linear to each individual objective. more baselines and scenarios can be included.,meaningful-comparison [SEP] negative [SEP]  it is possible [SEP]  compare the performance
ICLR_2020_349,45603,"paper tackles the problem of efficient inference and test time generalization and the proposed approach is interesting really enjoyed the paper and approach although i was previously unfamiliar with the pcmc model, using a neural network parametrization seems novel and well motivated ..",originality [SEP] positive [SEP]  paper the is really enjoyed [SEP]  proposed approach
ICLR_2020_349,45604,", seems to be theoretically sound, and outperforms evaluated baselines. 3 .the approximation theorem is useful and clean, and the empirical results are intriguing. while the metrics and baselines considered demonstrate a considerable empirical case for this method. overall, this paper presented a simple but effective approach for using neural networks in the pcmc class of models ..",soundness [SEP] positive [SEP]  the empirical results are intriguing [SEP]  a empirical demonstrate considerable case [SEP]  a overall paper presented simple but effective approach
ICLR_2020_349,45605,the paper makes claims about the representation properties of pcmc net but fails to validate them with simulation studies and there s no discussion of related work incorporating neural networks into ranking based models ..,soundness [SEP] negative [SEP]  paper makes claims [SEP]  the claims representation properties [SEP]  related work incorporating networks
ICLR_2020_349,45606,"experimental evaluation is insufficient, however, with the method assessed only on a single dataset in which case it is unclear if the method is better than baselines in general additionally, the method should be evaluated on at least one more dataset and compared to ml inference for pcmc. would be interesting to have a more in depth treatment of this 2 lack of data sets only one experiment on one data set is reported. the experiments do not thoroughly validate the method as they contain no simulation studies and only one data set. the experimental section is too limited, with results on only one dataset and no comparison of different architectural choices for how to incorporate neural networks into pcmc models, or analysis pointing toward what the features are learning that allows them to improve over earlier approaches ..",substance [SEP] negative [SEP]  improve earlier approaches [SEP]  experimental evaluation is insufficient however [SEP]  inference pcmc models [SEP]  depth treatment this 2 lack [SEP]  data sets [SEP]  experiment only one sets [SEP]  is the reported experiments not [SEP]  the method assessed not [SEP]  not they contain studies [SEP]  no not contain simulation studies [SEP]  experimental the section too limited [SEP]  too limited results [SEP]  no comparison different architectural choices [SEP]  how incorporate neural networks analysis [SEP]  analysis pointing [SEP]  the are features learning
ICLR_2020_349,45607,consideration of more datasets would improve the results.,substance [SEP] positive [SEP]  consideration more datasets [SEP]  consideration would improve the results
ICLR_2020_349,45608,"the authors do not compare to ml inference in pcmc, which seems to be the closest possible baseline.",meaningful-comparison [SEP] negative [SEP]  the be closest possible baseline [SEP]  the authors do not not compare [SEP]  inference pcmc
ICLR_2020_349,45609,"finally, the paper is full of complicated terms and cumbersome notation, which makes it difficult to read. the exposition should be made simpler and easier to follow (especially section 2), and all technical terms should be appropriately defined. the text was also confusing in a number of places (possibly due to my lack of knowledge in choice modeling) knowing nothing about choice modeling, i found the introduction hard to follow with lots of jargon that may be inaccessible to the broader ml community ..",clarity [SEP] negative [SEP]  the paper full [SEP]  full complicated terms [SEP]  the read exposition [SEP]  follow especially section [SEP]  all terms be should technical appropriately defined [SEP]  the terms be should appropriately defined text [SEP]  knowing nothing
ICLR_2020_349,45610,2 .the approach of the paper is well motivated intuitively.,motivation [SEP] negative [SEP]  the approach paper
ICLR_2020_349,45611,while i found the paper s methodology well motivated and sensible.,motivation [SEP] positive [SEP]  i found motivated [SEP]  found the paper s methodology motivated
ICLR_2020_1848,46088,"overall the paper is well written and easy to follow the paper is very well written, follows a concrete and easy to follow story line ..",clarity [SEP] positive [SEP]  the paper well written easy [SEP]  the paper well written easy [SEP]  a follows concrete
ICLR_2020_1848,46089,but some conceptual issues remain the figures should be better explained (took me a while to figure out what dots colors represent). the paper could use a more structured re write ..,clarity [SEP] negative [SEP]  a re paper could use more structured write [SEP]  some conceptual issues remain
ICLR_2020_1848,46090,"in general, there is hardly any discussion of what conditions are required for the proposed estimates to even be valid. however, i find these a bit too basic to be very convincing ,.",soundness [SEP] negative [SEP]  any discussion what conditions [SEP]  the conditions are required proposed estimates [SEP]  i however find basic
ICLR_2020_1848,46091,"the experiments look reasonable and the the intervention prediction heuristic is splendid. it is simple, sensible, and has been proven by experiments to be very effective ..",soundness [SEP] positive [SEP]  experiments look reasonable [SEP]  the the intervention prediction heuristic is splendid [SEP]  heuristic is splendid splendid it
ICLR_2020_1848,46092,the authors should describe what are the underlying interventions in each dataset a bit more ..,replicability [SEP] negative [SEP]  the authors should describe are [SEP]  authors should describe what are
ICLR_2020_1848,46093,although further work is needed to show it is useful. it reports results only for very small scms ..,substance [SEP] negative [SEP]  reports results [SEP]  further work is needed [SEP]  is show it
ICLR_2020_1848,46094,while the paper adopts the core design choices from recent prior art be published as a main track conference paper.,originality [SEP] negative [SEP]  the paper adopts choices [SEP]  the paper adopts core design choices [SEP]  paper a be published main track conference
ICLR_2020_1848,46095,the proposed methodology) is sufficiently novel to.,originality [SEP] positive [SEP]  the proposed methodology sufficiently novel
ICLR_2020_1124,46454,"i believe the paper is tackling an important task (extending neural network methods for sparse and missing time series data), and i i feel this work is still interesting since it discusses an interesting topic.",motivation [SEP] positive [SEP]  an interesting discusses topic [SEP]  believe the paper [SEP]  paper is tackling an important task [SEP]  extending neural network methods [SEP]  i believe [SEP]  is work feel this
ICLR_2020_1124,46455,find the proposed methods intuitive and the experiment evaluations interesting.,originality [SEP] positive [SEP]  find the experiment evaluations evaluations interesting
ICLR_2020_1124,46456,although the proposed method is of limited novelty (a straightforward extension to tlstm) and the proposed methods for static decay features feels somehow trivial.,originality [SEP] negative [SEP]  methods static decay features feels trivial [SEP]  the proposed method limited novelty [SEP]  a limited novelty straightforward extension [SEP]  the proposed methods static decay
ICLR_2020_1124,46457,i find the technical description of the proposed method insufficient.,meaningful-comparison [SEP] negative [SEP]  i find description insufficient [SEP]  find the technical description insufficient [SEP]  find the proposed method insufficient
ICLR_2020_1124,46458,"there does not seem to be explanation about how the proposed mechanism is better than the previous method this paper can benefit greatly with sufficient justification of its choice of model mechanisms, a more careful explanation of the advantage of its approach to sparse feature relative to previous approaches.",soundness [SEP] negative [SEP]  previous feature relative approaches [SEP]  the how proposed mechanism is better [SEP]  sufficient justification its choice [SEP]  explanation a model mechanisms more careful
ICLR_2020_1124,46459,"the experiment section does not seem to contain sufficient detail to be reproducible, and lack of sufficient detail in experiment results to be convincing. self contained description of the experiment procedures and standard error information for the experiments a more detailed explanation of experiment protocol is needed ..",replicability [SEP] negative [SEP]  the a experiments more detailed explanation [SEP]  the experiment section does not not not seem lack [SEP]  not contain sufficient detail [SEP]  self contained description explanation
ICLR_2020_1124,46460,the organization of the paper can also be improved (see major comments). the paper in its current form does not yet reach the iclr standard due to the lack of clarity in its technical description the organization of the method section can be improved. the titles and labels for the experiment result figure (figure 5) are too small to be readable ..,clarity [SEP] negative [SEP]  the paper does not not not not yet reach iclr standard [SEP]  the lack clarity
ICLR_2020_1021,46658,"as such it has questionable novelty and limited potential impact. but lacks any depth or clear important contribution. i find the significance low as the work is incremental and has technical rather than theoretical statements, and lacks a clear contribution ..",originality [SEP] negative [SEP]  has technical theoretical statements statements [SEP]  such has questionable novelty and limited potential impact [SEP]  lacks any depth [SEP]  i find significance [SEP]  the work is incremental
ICLR_2020_1021,46659,this paper presents an interesting theoretical result on providing stochastic robustness guarantees for lipschitz constrained neural networks ..,originality [SEP] positive [SEP]  lipschitz constrained [SEP]  paper presents an interesting theoretical result networks [SEP]  providing stochastic robustness guarantees
ICLR_2020_1021,46660,the paper is in general well written.,clarity [SEP] positive [SEP]  the paper general
ICLR_2020_1021,46661,"the paper could see some improvements in notation and some erroneous claims at the moment, the paper is quite confusing and hard to read, and it's not entirely clear what the crux of the paper, the new architecture is doing. issues with the theoretical results in the paper and felt that overall the paper was rushed and difficult to read in places as a result notation is inconsistent throughout with the loss function l taking either one or two arguments in different places.",clarity [SEP] negative [SEP]  l one or taking either two arguments [SEP]  a some notation erroneous claims result [SEP]  not not entirely clear what [SEP]  the issues theoretical results [SEP]  the paper could see improvements is [SEP]  the l loss function taking arguments
ICLR_2020_1021,46662,sanity check but not a good validation of the method it's also not validated where does the effect comes from. .4) there are several (fixable) issues present in the theoretical results. the first of which is a regularization scheme which provides no provable guarantees on the lipschitz constant itself. you describe spectral normalization as a regularization technique which is inaccurate.,soundness [SEP] negative [SEP]  sanity a check not not good validation [SEP]  the does effect comes [SEP]  several fixable issues issues present [SEP]  the issues present theoretical results [SEP]  no provides provable guarantees
ICLR_2020_1021,46663,i believe the stated result can be made rigorous and correct.,soundness [SEP] positive [SEP]  i believe [SEP]  believe the stated result
ICLR_2020_1021,46664,paper presents interesting theoretical contributions towards measuring the robustness of lipschitz constrained neural networks ..,motivation [SEP] positive [SEP]  constrained neural networks [SEP]  paper presents interesting theoretical contributions [SEP]  lipschitz constrained networks
ICLR_2020_1021,46665,"the empirical results are fairly limited and lack explanation in places and appropriate comparisons to existing work. the paper is missing references to several key pieces of related work tackling similar problems. however, the paper does not discuss existing baselines which provide similar stochastic guarantees e.g. 4.",meaningful-comparison [SEP] negative [SEP]  similar provide stochastic guarantees [SEP]  the empirical results fairly limited lack [SEP]  is paper missing references [SEP]  existing paper however does not not not not discuss baselines
ICLR_2020_1021,46666,i do not understand the proposed training strategy ..,replicability [SEP] negative [SEP]  i do not not not understand strategy [SEP]  do not not understand the proposed training strategy
ICLR_2020_675,47005,"to my knowledge, it s the first time that the rl algorithm is applied to causal discovery area for structure searching. overall, the idea of this paper is novel , 2 .the novel idea of applying reinforcement learning to dag search sounds intriguing. to the best of the author s knowledge, such idea has never been considered by previous work in causal graphical models ..",originality [SEP] positive [SEP]  idea has never never never never been considered previous work [SEP]  my knowledge s time [SEP]  structure searching [SEP]  the idea this paper [SEP]  idea novel applying learning [SEP]  applying reinforcement learning [SEP]  search idea dag sounds intriguing [SEP]  knowledge s the best author
ICLR_2020_675,47006,"the novelty is somewhat limited, since the paper is combining two previously proposed ideas.",originality [SEP] negative [SEP]  the novelty somewhat limited [SEP]  the is paper combining ideas [SEP]  is paper combining two previously proposed ideas
ICLR_2020_675,47007,and the experiment is comprehensive.,substance [SEP] positive [SEP]  the experiment comprehensive
ICLR_2020_675,47008,the authors should give more clarifications to convince me about their.,clarity [SEP] negative [SEP]  convince their [SEP]  authors should give more clarifications
ICLR_2020_675,47009,"and the authors do a nice job of exposition, and empirical.",clarity [SEP] positive [SEP]  the authors do job empirical [SEP]  a authors do nice job empirical
ICLR_2020_675,47010,"pros 1 .it's great to see the authors has done a comprehensive comparison with the other methods, especially under different simulation scenarios.",meaningful-comparison [SEP] negative [SEP]  pros great [SEP]  see the authors [SEP]  a authors has done comprehensive comparison
ICLR_2020_675,47011,reinforcement learning offers a powerful tool for policy evaluation and decision making. it s good to see that the author can successfully extend such toolbox to the field of causal structure learning ..,motivation [SEP] positive [SEP]  reinforcement learning offers tool [SEP]  learning a offers powerful tool [SEP]  s it good
ICLR_2020_675,47012,i think this is a sensible idea.,soundness [SEP] positive [SEP]  i think is [SEP]  think is a sensible idea
ICLR_2018_733,47204,"the study seems sound from a technical viewpoint to me and its contribution is incremental, as it builds on existing research, which is although the result are good and the.",soundness [SEP] positive [SEP]  the result are good [SEP]  the study seems sound [SEP]  study seems sound sound a technical viewpoint
ICLR_2018_733,47205,correctly identified. i think that the technical contribution is a bit thin for a ml conference and this paper may be a better fit for.,originality [SEP] negative [SEP]  a paper may be better fit [SEP]  i think is [SEP]  think the technical contribution is
ICLR_2018_733,47206,"please revise list of references (right now a mess in terms of format, typos, incompleteness this is somewhat confusing to me and maybe you want to review the structure of the sections ..",clarity [SEP] negative [SEP]  review the structure [SEP]  a references right now mess [SEP]  a right now mess terms [SEP]  me somewhat confusing
ICLR_2018_733,47207,the paper is well written and easy to understand ..,clarity [SEP] positive [SEP]  the paper well written easy
ICLR_2018_733,47208,i would appreciate a few more technical details or formal description here and there ..,replicability [SEP] negative [SEP]  i would appreciate details here [SEP]  would a appreciate few more technical details here
ICLR_2020_205,47388,"at a high level, the paper addresses an interesting problem. i believe that this paper would be of interest to the adversarial ml community and i hence recommend acceptance i feel this paper could be useful to the community for two main reasons 1. this approach could be useful in settings where data is scarce or compute is expensive.",motivation [SEP] positive [SEP]  paper addresses an interesting problem [SEP]  paper interest be would [SEP]  hence recommend acceptance [SEP]  i believe [SEP]  paper believe this [SEP]  the be community useful
ICLR_2020_205,47389,i feel that the results obtained are rather expected and the paper does not provide some interesting methodological contribution that could help to develop robust transfer training ..,motivation [SEP] negative [SEP]  develop robust transfer training [SEP]  the are rather expected paper not [SEP]  paper does not not not provide some interesting methodological contribution
ICLR_2020_205,47390,"overall, the paper contains an experimental study that, in my opinion, is thorough, presents interesting findings, and contains the necessary ablations ..",substance [SEP] positive [SEP]  presents interesting findings [SEP]  overall paper contains an experimental study [SEP]  my opinion is thorough
ICLR_2020_205,47391,iv .why isn t experiment in figure 3 should be repeated for cifar10 as well.,substance [SEP] negative [SEP]  why isn t experiment figure [SEP]  experiment should be repeated cifar10 well
ICLR_2020_205,47392,"i find the paper interesting overall, the exploration in the paper seems novel and could be useful to the.",originality [SEP] positive [SEP]  i find interesting overall [SEP]  the interesting exploration seems novel
ICLR_2020_205,47393,"so far, the contribution appears to me rather limited for iclr ..",originality [SEP] negative [SEP]  far the contribution appears [SEP]  far contribution appears me [SEP]  rather limited iclr
ICLR_2020_205,47394,but i think the narrative of this section should be modified to make this clearer. i think that the paper could benefit by reducing these 3 sections in only one section where the results obtained can be summarized in one big table and two or three figures for example.,clarity [SEP] negative [SEP]  think the narrative [SEP]  the paper could benefit
ICLR_2020_205,47395,"the authors should add this result to the paper, even if in the appendix.",meaningful-comparison [SEP] negative [SEP]  the authors should add result [SEP]  authors should add this result
ICLR_2019_911,47647,i think focusing on not just attacking gcns but actually preventing them is awesome the study of detecting malicious edges in graphs is interesting and important ..,motivation [SEP] positive [SEP]  i think is [SEP]  not actually preventing them [SEP]  the awesome study detecting edges
ICLR_2019_911,47648,"however, the significance of the paper can be improved ..",motivation [SEP] negative [SEP]  the the significance paper
ICLR_2019_911,47649,"how robust are these methods also, the evaluations need to be further improved. to properly test the detection performance, i recommend that the authors run experiments on various random graph models ..",substance [SEP] negative [SEP]  authors run experiments [SEP]  robust are these methods also [SEP]  the evaluations need [SEP]  the properly test detection performance
ICLR_2019_911,47650,"it is unclear if they provide any real robustness to an adversary. given that the proposed algorithms do not leverage the underlying model structure very much, why the proposed algorithms are special to the graphical neural network is not very clear ..",soundness [SEP] negative [SEP]  they provide robustness [SEP]  provide any real robustness [SEP]  the algorithms do not not not not leverage underlying model structure much [SEP]  the given proposed algorithms
ICLR_2019_911,47651,the proposed method is developed under the assumptions about the attacking models sound simple but reasonable with proper references ..,soundness [SEP] positive [SEP]  reasonable proper references [SEP]  the proposed method is developed [SEP]  the method is developed assumptions [SEP]  the attacking models sound simple
ICLR_2019_911,47652,it will be great if the authors clearly describe what the proposed methods aim to defend ..,clarity [SEP] negative [SEP]  it will be great [SEP]  authors clearly describe what [SEP]  the proposed methods aim
ICLR_2018_107,47660,"this paper is well written and easy to follow. overall, the paper is well written. and the results clearly follow.",clarity [SEP] positive [SEP]  this paper well written easy [SEP]  paper follow the [SEP]  follow the results
ICLR_2018_107,47661,i think it is better to clarify in the paper that the proposed method can reduce only the complexity of the input embedding layer ..,clarity [SEP] negative [SEP]  clarify the paper [SEP]  the method can reduce only complexity
ICLR_2018_107,47662,"the motivation is clear and the the motivation is clear, the idea and approaches look suitable.",motivation [SEP] positive [SEP]  the motivation is clear [SEP]  the the motivation is clear clear [SEP]  idea approaches look suitable
ICLR_2018_107,47663,idea is simple and effective.,soundness [SEP] positive [SEP]  idea simple
ICLR_2018_107,47664,it would be better the current analysis is too simple. it may also be interesting to provide suitable theoretical analysis.,soundness [SEP] negative [SEP]  it would be better [SEP]  it would be better [SEP]  analysis provide suitable theoretical
ICLR_2018_107,47665,"to provide deeper analysis in subsection 6.1 furthermore, i would like to see two additional analysis ..",substance [SEP] negative [SEP]  provide deeper analysis [SEP]  i would like [SEP]  analysis see two additional
ICLR_2018_107,47666,"although this paper is focused on only the input embeddings, authors should refer some recent papers that tackle to reduce the complexity of the softmax layer.",meaningful-comparison [SEP] negative [SEP]  this is paper focused [SEP]  authors should refer some recent papers [SEP]  the reduce complexity
ICLR_2018_107,47667,what kind of information is distributed in each trained basis vector.,replicability [SEP] negative [SEP]  what kind information [SEP]  kind is distributed each trained basis vector
ICLR_2020_879,47720,most useful part of the algorithm is that there is no need for concept annotations and the use of concept based self interpretable models is very useful to the field ..,motivation [SEP] positive [SEP]  most useful part the algorithm [SEP]  no need concept
ICLR_2020_879,47721,the paper is quite well written. thanks again for a well organized and easy to follow paper.,clarity [SEP] positive [SEP]  the paper well written [SEP]  well written thanks [SEP]  paper well written
ICLR_2020_879,47722,the visualization is a bit confusing cause it is unclear whether it is each span is a set of spans or a single span.,clarity [SEP] negative [SEP]  a a span set single [SEP]  the visualization is confusing [SEP]  bit it confusing
ICLR_2020_879,47723,the introduced method is well justified.,soundness [SEP] positive [SEP]  the introduced method well justified
ICLR_2020_879,47724,"there is not enough discussion of why it actually should be the case the subjective results are interesting but not convincing. and new model, and it s hard to be persuaded the model is doing well based on this new measure, when there is little ground to know what this measure really measures. overall, i m not impressed with the models performances ..",soundness [SEP] negative [SEP]  is not not enough discussion [SEP]  the why actually should be case [SEP]  convincing and new model [SEP]  new based this measure [SEP]  little ground know measures [SEP]  know what measures
ICLR_2020_879,47725,the idea sounds interesting.,originality [SEP] positive [SEP]  the idea sounds interesting
ICLR_2020_879,47726,authors should make a much more comprehensive discussion of what already exists in the concept based interpretability literature and make the contribution of this work more clear the results are pretty disappointing compared to the existing models such as lei et al s initial baseline or bastings et al .while the paper argues this method isn.,meaningful-comparison [SEP] negative [SEP]  this paper argues method [SEP]  a authors should make much more comprehensive discussion et [SEP]  based interpretability literature [SEP]  make more the clear results [SEP]  the compared existing models such [SEP]  the paper argues
ICLR_2020_879,47727,"i would like to see some studies on how this correlates with human s judgements on how interpretable the model is. the paper evaluates on this measure, which is included in the appendix, and.",substance [SEP] negative [SEP]  i would like [SEP]  see some studies [SEP]  this paper evaluates measure
ICLR_2020_879,47728,the experimental results support the usefulness of the proposed method on a variety of datasets ..,substance [SEP] positive [SEP]  the experimental results support usefulness [SEP]  the results support usefulness [SEP]  the a proposed method variety
ICLR_2019_135,48209,my largest concern about both this paper and the allamanis et al .paper is how it compares to the state of the art in apr in general ..,meaningful-comparison [SEP] negative
ICLR_2019_135,48210,the one industrial software project tells me little about the proposed approach s effectiveness when applied to a significant number of widely used software programs like the ones residing in state of the art benchmarks for apr the error could be potentially quite problematic ..,soundness [SEP] negative [SEP]  the be error could potentially problematic [SEP]  a when applied significant number [SEP]  a software significant number widely used programs
ICLR_2019_135,48211,", and the resulting gains are quite impressive. it provides a clear improvement over allamanis et al paper.",soundness [SEP] positive [SEP]  the resulting gains quite impressive [SEP]  it provides improvement [SEP]  a provides clear improvement
ICLR_2019_135,48212,"it is quite well written, and clear. they do a good job of describing the problems with earlier approaches, and how their approach can address it. strengths of the paper are well written and easy to follow and understand ..",clarity [SEP] positive [SEP]  it well written clear [SEP]  a do good job [SEP]  the describing problems [SEP]  approach how their can address
ICLR_2019_135,48213,and addresses the problem quite directly.,motivation [SEP] positive [SEP]  addresses the problem directly
ICLR_2019_135,48214,makes me feel the ideas in this paper may not lead to significant impact on the research community.,motivation [SEP] negative [SEP]  makes me [SEP]  feel the ideas [SEP]  may not lead significant impact
ICLR_2019_135,48215,the evaluation is quite thorough evaluation on several datasets ..,substance [SEP] positive [SEP]  the evaluation evaluation quite thorough [SEP]  evaluation quite thorough several datasets
ICLR_2019_135,48216,the implementation and evaluation are only on a quite syntactic system with low precision and that needs to sift through a huge amount of weak and irrelevant signals to make predictions.,substance [SEP] negative [SEP]  the implementation evaluation [SEP]  a quite syntactic system low precision [SEP]  make predictions
ICLR_2019_135,48217,i have some significant reservations about the novelty and the technical content. the proposed model doesn't quite bring anything new to the table ..,originality [SEP] negative [SEP]  i have reservations [SEP]  have some significant reservations [SEP]  the new table
ICLR_2019_135,48218,although there are some valid concerns and provides an interesting approach to the task ..,originality [SEP] positive [SEP]  some valid concerns provides approach [SEP]  an provides interesting approach
ICLR_2020_1752,48603,"they should at least compare their method with this one the review and comparison with the state of the art is lacking and many references are missing. the proposed learning loss needs to be compared with the original one to demonstrate any potential performance improvement in other words, there should also be a comparison with lambda 1 or 0.",meaningful-comparison [SEP] negative [SEP]  a comparison other words [SEP]  should least compare their method review [SEP]  the the one review original [SEP]  the a comparison state [SEP]  is lacking many references [SEP]  the proposed learning loss needs [SEP]  the one be compared original [SEP]  any demonstrate potential performance improvement
ICLR_2020_1752,48604,"in other words, the foundation of their training is wrong, which makes their experimental results unconvincing. contributions are, and why they are justified, theoretically or empirically it is not clear whether it is actually helping experiments on cifar 10 100 is not sufficient to be convincing vgg 15 is not convincing to show case compression.",soundness [SEP] negative [SEP]  show case compression [SEP]  foundation their training is wrong [SEP]  makes results unconvincing contributions [SEP]  are they justified [SEP]  is it not not clear [SEP]  is not actually helping experiments [SEP]  convincing convincing be vgg
ICLR_2020_1752,48605,"a larger dataset would be better. the experimental setup is simplistic and not convicing, the authors should ideally try a more realistic, large scale dataset and how results are reused ..",substance [SEP] negative [SEP]  a larger dataset would be better [SEP]  dataset would be better better the experimental setup [SEP]  large dataset more realistic scale
ICLR_2020_1752,48606,the writing of this paper is not good. figure 2 and related numbers are slightly misleading. it would be great to clarify this all over the text as m increases signigicantly when using i need clarification on the need of training full rank and low rank (end of page 4)..,clarity [SEP] negative [SEP]  the writing this paper not [SEP]  good figure [SEP]  training full rank end
ICLR_2020_1752,48607,some of the ideas are interesting.,originality [SEP] positive [SEP]  the ideas interesting
ICLR_2020_1752,48608,"the novelty is low, this very type of decomposition is already widely studied applying svd to the matricized weights of deep neural networks is not new. as a contribution ..",originality [SEP] negative [SEP]  is a not not new contribution [SEP]  applying svd [SEP]  the applying matricized weights deep
ICLR_2020_1752,48609,"it is not clear to me how the 2 branches are trained and what parameters are shared. during the learning, it is not clear to me how the process is implemented and the scalability of this approach ..",replicability [SEP] negative [SEP]  is not how the process implemented scalability [SEP]  not how branches are trained what parameters [SEP]  the are parameters shared learning
ICLR_2020_297,48878,the paper is well written and very well presented and clear this paper is well written in english and is well structured ..,clarity [SEP] positive [SEP]  the paper is [SEP]  paper presented clear this [SEP]  is well english structured
ICLR_2020_297,48879,gives a nice overview on related work and in particular reweighted sampling schemes the authors do a comprehensive literature review.,meaningful-comparison [SEP] positive [SEP]  gives a nice overview [SEP]  a authors do comprehensive literature review
ICLR_2020_297,48880,the proposed methods and variations appear to be simple.,originality [SEP] negative [SEP]  methods variations appear
ICLR_2020_297,48881,and the insight that decoupling representation and classifier learning performs well on long tailed classification seems novel. novel and efficient approach of redesigning the classifier as a post processing step after the representation training cons.,originality [SEP] positive [SEP]  classifier learning performs well [SEP]  insight long tailed classification seems novel
ICLR_2020_297,48882,"yet very effective i am leaning towards acceptance as the method is clear, easy to implement, well studied through the experiments and has good results on standard benchmarks ..",soundness [SEP] positive [SEP]  has good results [SEP]  effective i am leaning [SEP]  the method is clear easy
ICLR_2020_297,48883,"the experiments are mostly thorough and detailed. thorough experiments with baselines and comparisons with competitors what's more, he experiment is comprehensive and rigorous ..",substance [SEP] positive [SEP]  the experiments mostly thorough [SEP]  baselines comparisons [SEP]  he experiment experiments
ICLR_2020_297,48884,"it would be great to provide more details and guidelines for practitioners. the authors should add details about the exact schedules, batch size etc. for reproducibility.",replicability [SEP] negative [SEP]  the exact schedules batch size [SEP]  it would be great [SEP]  provide more details
ICLR_2020_297,48885,i tend to accept this paper since it is interesting and renews our understanding of the long tailed recognition ability of neural network and sampling strategies.,motivation [SEP] positive [SEP]  accept this paper [SEP]  is it interesting
ICLR_2020_360,49261,and the authors present ablations to reveal the source of gains. adequate ablation.,substance [SEP] positive [SEP]  the authors authors present ablations reveal [SEP]  present ablations reveal source [SEP]  the reveal source
ICLR_2020_360,49262,"the authors limit their investigation of downstream performance to the glue set of tasks, which are classification tasks. results on squad or another more elaborate nlp task and or the release of the electra models would make the paper much stronger i'd like to see a little more investigation into table 3. it will be helpful if the authors provide more empirical analysis why the adversarial electra perform worse or failed.",substance [SEP] negative [SEP]  tasks are classification [SEP]  the task another more elaborate nlp release [SEP]  the results would make paper stronger [SEP]  a investigation more see little [SEP]  the authors limit investigation [SEP]  authors more provide empirical analysis
ICLR_2020_360,49263,simple but novel self supervised task for learning text representations idea is simple and makes sense intuitively the paper proposed a novel sample efficient pretraining task all these observations are interesting ..,originality [SEP] positive [SEP]  novel task a paper proposed sample efficient pretraining are [SEP]  learning text representations idea [SEP]  makes sense intuitively
ICLR_2020_360,49264,", strong results, i think the formulations of the experiments and ideas to develop this are adequate. and the experimental results are positive ..",soundness [SEP] positive [SEP]  results i think are [SEP]  results think the formulations are [SEP]  results the experimental positive
ICLR_2020_360,49265,the studied problem is important.,motivation [SEP] positive [SEP]  the studied problem important
ICLR_2018_497,49909,the one shot learning results are promising. the math appears correct and the algorithms are clearly stated ..,soundness [SEP] positive [SEP]  the one shot learning results are promising [SEP]  the math appears correct [SEP]  the math appears correct correct algorithms
ICLR_2018_497,49910,the experiments on dataset ordering are not convincing. the experiments on using the proposed model as a generative model are confusing ..,soundness [SEP] negative [SEP]  the experiments dataset ordering not [SEP]  the experiments dataset ordering [SEP]  the using proposed model
ICLR_2018_497,49911,the idea of explicitly representing the neighborhood structure within a dataset is generally interesting and seems related to the concept of low dimensional image manifold. the paper has some interesting ideas.,originality [SEP] positive [SEP]  interesting paper has some ideas [SEP]  the idea explicitly representing structure [SEP]  the seems related related concept
ICLR_2018_497,49912,this work seems related to simultaneous clustering and representation learning.,originality [SEP] negative [SEP]  this work seems related [SEP]  representation learning
ICLR_2018_497,49913,the motivation of the paper is not convincing. unclear how impactful are the results. there are some serious concerns on the impact of this paper.,motivation [SEP] negative [SEP]  the impact some serious concerns [SEP]  the motivation paper not this [SEP]  the how impactful results
ICLR_2018_497,49914,initialization of the transition operator is very important.,motivation [SEP] positive [SEP]  initialization the transition operator
ICLR_2018_497,49915,"however, they are rushed and not analyzed in detail. i am not convinced that the proposed method is well tuned for the task. , and the experiments are substandard.",substance [SEP] negative [SEP]  not analyzed detail [SEP]  the not convinced proposed method [SEP]  the method is well tuned task
ICLR_2018_497,49916,and experiments are carefully performed.,substance [SEP] positive [SEP]  experiments are carefully performed
ICLR_2018_497,49917,but the presentation is not convincing.,clarity [SEP] negative [SEP]  the presentation not not convincing
ICLR_2018_497,49918,the paper is well written this paper is well written.,clarity [SEP] positive [SEP]  the paper is well written [SEP]  paper is well written this
ICLR_2020_2199,50228,i have checked the analysis.,substance [SEP] positive [SEP]  i have checked analysis [SEP]  have checked the analysis
ICLR_2020_2199,50229,i would like to see such methods show difference in real world datasets. 1 .the results of the paper are limited to specific deep linear neural networks which are not practical. the results are not rigorously stated and proved ..,substance [SEP] negative [SEP]  the results are not not not practical [SEP]  i would like [SEP]  see such methods [SEP]  methods show difference [SEP]  1 the results [SEP]  the results are limited specific deep linear neural networks
ICLR_2020_2199,50230,and it seems solid. overall i think this is an interesting paper with strong results and vote for accepting.,soundness [SEP] positive [SEP]  it seems solid [SEP]  i overall think is [SEP]  an overall interesting paper strong
ICLR_2020_2199,50231,"while the assumption on the input correlation matrix being whitened can be dropped, other assumptions in the paper are unrealistic and are stated without any intuition or explanation the analysis performed in the paper cover the deep linear case and no intuition is provided on how these results can help in understanding the more general non linear case ..",soundness [SEP] negative [SEP]  the linear case understanding more general non [SEP]  be can dropped other assumptions [SEP]  the analysis cover deep linear case [SEP]  can how these results help
ICLR_2020_2199,50232,2 .the paper lacks a cohesive introduction that includes a literature review on this very rich area of research ..,meaningful-comparison [SEP] negative [SEP]  a literature review this very rich area [SEP]  paper lacks introduction [SEP]  a includes literature review
ICLR_2020_2199,50233,3 .the paper is not clearly written and is missing many details. the paper is unpolished and the objectives and contributions are not clearly stated ..,clarity [SEP] negative [SEP]  3 the paper is not not not clearly written [SEP]  is not missing many details
ICLR_2020_2199,50234,the paper is well presented and the derivations of analytical solutions are clear ..,clarity [SEP] positive [SEP]  the paper well presented [SEP]  derivations analytical solutions are clear
ICLR_2018_570,50428,the proposed method while simple is novel ..,originality [SEP] positive [SEP]  the proposed method simple simple is novel
ICLR_2018_570,50429,the novelty of this submission seems a little limited ..,originality [SEP] negative [SEP]  the novelty this submission [SEP]  novelty this submission seems limited
ICLR_2018_570,50430,2 .the face datasets are rather small ..,substance [SEP] negative [SEP]  face datasets rather small
ICLR_2018_570,50431,2 .the achievement in this paper seems good the proposed neural network architectures are reasonable ..,soundness [SEP] positive [SEP]  the achievement this paper seems good are [SEP]  the the achievement good good proposed neural network architectures
ICLR_2018_570,50432,this paper is well written ..,clarity [SEP] positive [SEP]  this is paper well written
ICLR_2018_570,50433,what is missing is the comparison with other methods (besides the baseline)..,meaningful-comparison [SEP] negative [SEP]  what is missing [SEP]  is missing missing the comparison
ICLR_2018_387,50454,"the adversarial learning aspect is not new. the theoretical contribution extends the seminal work of ben david et al. , the idea of using adversarial learning is not new, the novelty is mediaum significance the theoretical analysis is interested but for me limited, the idea of the algorithm is not new but as far as i know the first explicitly presented for multi source.",originality [SEP] negative [SEP]  not far first explicitly presented multi source [SEP]  the adversarial learning aspect not new [SEP]  the theoretical contribution extends work [SEP]  the contribution extends seminal work [SEP]  the is is is not theoretical novelty mediaum significance analysis [SEP]  the learning not idea using
ICLR_2018_387,50455,new theoretical analysis for multisource problem paper clear smoothed version is interesting cons learning bounds with worst case standpoint is probably not the best analysis for multisource learning experimental evaluation limited in the sense that similar algorithms in the literature are not compared extension a bit direct from the seminal work of ben david et al .summary.,originality [SEP] positive [SEP]  the not extension bit direct seminal work [SEP]  new theoretical analysis multisource problem paper clear smoothed version [SEP]  experimental evaluation limited [SEP]  the not sense similar algorithms
ICLR_2018_387,50456,"overall, the improvements from using mdan were consistent and promising. this succeeds in convincing the paper appears to be correct ..",soundness [SEP] positive [SEP]  the improvements using [SEP]  using mdan [SEP]  the convincing paper
ICLR_2018_387,50457,since it is not backed by an empirical or a theoretical study. the soft max version of the algorithm obtaining the best empirical study is not backed by the theory. i am not particularly convinced that the proposed theory explains best multi source learning.,soundness [SEP] negative [SEP]  best theory explains multi source [SEP]  is not backed a an empirical or theoretical study [SEP]  not empirical the the study soft max version best [SEP]  not empirical the study obtaining best [SEP]  not the study best theory [SEP]  i not the theory proposed [SEP]  the theory proposed explains source
ICLR_2018_387,50458,it does not completely address the problem of learning from multiple source domains ..,motivation [SEP] negative [SEP]  it does not not not not completely address problem [SEP]  does not not not completely address the problem [SEP]  learning multiple source domains
ICLR_2018_387,50459,me that the proposed approach is of interest. tackle an important problem that is not studied as it deserves. the proposed bound is of some interest ..,motivation [SEP] positive [SEP]  interest bound some [SEP]  the proposed approach interest some [SEP]  interest tackle problem [SEP]  tackle an important problem
ICLR_2018_387,50460,the empirical study is exhaustive enough to show that the proposed algorithm actually works ..,substance [SEP] positive [SEP]  the empirical study exhaustive enough show [SEP]  the show proposed algorithm
ICLR_2018_387,50461,"my major concern is that the baselines evaluated in the experiments are quite limited. there is no comparison with other (deep learning methods) tackling multi source scenarios (or equivalent), while i think it is easy to find related approaches.",meaningful-comparison [SEP] negative [SEP]  find related approaches [SEP]  no comparison other methods
ICLR_2018_387,50462,the paper is very clear originality.,clarity [SEP] positive [SEP]  the paper very clear originality [SEP]  the paper very clear originality
ICLR_2019_927,50529,"the model is interesting, novel containing innovative elements.",originality [SEP] positive [SEP]  the model interesting [SEP]  containing innovative elements
ICLR_2019_927,50530,"while the idea of applying dual adversarial approaches is new in the context of ner, the technical novelty of each component is limited. there is no technical novelty in applying adversarial training either ,.",originality [SEP] negative [SEP]  the idea applying approaches [SEP]  the idea is new new context [SEP]  the technical novelty each component
ICLR_2019_927,50531,", clearly exposed in sufficient detail the paper is well and clearly written nicely and clear written paper.",clarity [SEP] positive [SEP]  sufficient detail the paper [SEP]  clear clearly paper written written nicely
ICLR_2019_927,50532,the idea to unify representation differences and data imbalance under one model is noteworthy ..,motivation [SEP] positive [SEP]  the idea unify differences [SEP]  unify representation differences
ICLR_2019_927,50533,"i find that the description of related work, especially in the introduction, does not credit past contributions sufficiently ..",meaningful-comparison [SEP] negative [SEP]  i find [SEP]  description does not not not credit contributions sufficiently
ICLR_2019_927,50534,a good overview on sota ..,meaningful-comparison [SEP] positive [SEP]  a good overview sota
ICLR_2019_927,50535,"this experiment setup troubles me, especially in light of real and synthetic ner data available to test the setup for true low resource languages but that alone does not suffice.",soundness [SEP] negative [SEP]  setup test true low resource languages [SEP]  light real ner data [SEP]  real and synthetic ner data data available test
ICLR_2019_927,50536,the results go beyond sota for low resource ner which seems a solid contribution.,soundness [SEP] positive [SEP]  the results go [SEP]  a seems solid contribution
ICLR_2019_927,50537,and i would be able to replicate the experiments i am not sure if they are really super strong.,substance [SEP] negative [SEP]  am not not sure they [SEP]  replicate the experiments [SEP]  i would be able not
ICLR_2020_116,50724,"i find the paper very clear although this paper is generally easy to follow, the paper is well written, with detailed explanation of proof skeleton ..",clarity [SEP] positive [SEP]  detailed explanation proof skeleton [SEP]  i find clear [SEP]  paper this is generally easy [SEP]  find the paper clear
ICLR_2020_116,50725,"in property 1 of theorem 2, smooth and multilinear partition might be a bit misleading. m afraid the current form of the paper does not meet the standard of the conference.",clarity [SEP] negative [SEP]  the form does not not not meet standard [SEP]  smooth and multilinear partition might be misleading [SEP]  the m afraid afraid current form not
ICLR_2020_116,50726,and the result very clean.,soundness [SEP] positive [SEP]  the result result very clean
ICLR_2020_116,50727,partitioning itself is not very interesting.,soundness [SEP] negative [SEP]  partitioning itself not
ICLR_2020_116,50728,"it seems to me the construction of the local minima is very similar to 1, since the main idea is to consider the linear region by activating all the neurons the insight of this paper is somehow shortcoming.",originality [SEP] negative [SEP]  it seems is [SEP]  the main idea consider region [SEP]  the consider linear region
ICLR_2020_116,50729,"and the motivation about nonlinearities and the loss surface is clear i think this paper is studying an important and interesting question, and the efforts of constructing local minima and understanding big picture are both interesting to me ..",motivation [SEP] positive [SEP]  interesting efforts are both me [SEP]  think this paper [SEP]  an and is paper studying important interesting question [SEP]  the efforts constructing [SEP]  understanding big picture
ICLR_2020_116,50730,the significance of the results are not clear. but the motivation of this extension is somewhat unclear to me.,motivation [SEP] negative [SEP]  the the significance results not [SEP]  somewhat me unclear
ICLR_2020_116,50731,can be significantly improved if more details and experiments are provided. details are given below.,replicability [SEP] negative [SEP]  more details details
ICLR_2020_116,50732,"1 .this paper only considers piecewise linear activation, which is a special type of non linear activation.",substance [SEP] negative [SEP]  1 this paper only considers activation [SEP]  paper only considers piecewise linear activation [SEP]  is a special type
ICLR_2018_530,50853,an interesting new idea it is a novel setup to consider reservoir sampling for episodic memory ..,originality [SEP] positive [SEP]  an interesting new idea is setup [SEP]  a is novel setup [SEP]  consider reservoir sampling
ICLR_2018_530,50854,that has potential to be useful in rl.,motivation [SEP] positive [SEP]  be useful useful rl
ICLR_2018_530,50855,elegant algorithm to solve at least part of the problem properly.,soundness [SEP] positive [SEP]  elegant algorithm solve part properly [SEP]  solve at least part properly
ICLR_2018_530,50856,"math is fudged around quite a bit with approximations that are not always justified what are the theoretical advantages of using reservoir sampling it is hard to justify the empirically better performance without hyperparameter tuning. the technically soundness of this work is weakened by the experiments. therefore, empirically, it is really hard to justify whether this proposed method could work better. the experiments they demonstrated in this article are not well designed so that the conclusion they made in this article is not robust enough ..",soundness [SEP] negative [SEP]  is are justified what [SEP]  the theoretical advantages using sampling [SEP]  the justify empirically better performance [SEP]  this proposed method demonstrated [SEP]  not the conclusion made
ICLR_2018_530,50857,while overall the writing is clear the paper is well written and easy to understand ..,clarity [SEP] positive [SEP]  overall the writing is clear [SEP]  overall the writing is clear clear paper
ICLR_2018_530,50858,in some places i feel it could be improved i had a very hard time understanding the set up of the problem in figure 2 i also recommend against using figure captions to describe the setup. physical meanings of theorem 1 are not well represented ..,clarity [SEP] negative [SEP]  the setup physical meanings not [SEP]  a had very hard time [SEP]  understanding the set [SEP]  figure using captions [SEP]  the describe setup
ICLR_2018_530,50859,the proposed architecture is only compared with a recurrent baseline with 10 unit gru network ..,meaningful-comparison [SEP] negative [SEP]  the proposed architecture is only compared [SEP]  a architecture is only compared recurrent baseline
ICLR_2018_530,50860,it seems that hyper parameters for rnn haven t been tuned enough ..,replicability [SEP] negative [SEP]  it seems [SEP]  seems hyper parameters
ICLR_2020_2116,50884,i believe that the contributions of this paper are week in analyzing individual layers across layer since there are many extensive studies are conducted on information bottleneck methods with mutual information.,originality [SEP] negative [SEP]  are many extensive studies conducted [SEP]  believe the contributions are
ICLR_2020_2116,50885,"thus, it would be better to clarify the definition. it would be good to spend more space and resources () to explain the definition of label distribution ..",clarity [SEP] negative [SEP]  definition explain label distribution [SEP]  thus it would be better [SEP]  clarify the definition
ICLR_2020_2116,50886,it is not clear that the label distribution reflect the actual distribution of (nodes or feature maps) in a specific layer. 3 .there is no detail on the regularization strength of the wasserstein distance.,replicability [SEP] negative [SEP]  not the distribution reflect actual [SEP]  nodes feature maps
ICLR_2020_2116,50887,to the in depth analysis of neural networks.,motivation [SEP] positive [SEP]  the in depth analysis neural networks
ICLR_2020_2116,50888,why the use of teacher student networks are pertinent or necessary ..,motivation [SEP] negative [SEP]  the use teacher student networks
ICLR_2020_2116,50889,the setting of multi label classification does not really motivate the use of measures 2 .it is unclear.,soundness [SEP] negative [SEP]  the setting multi classification not [SEP]  the setting does not not not not really motivate use
ICLR_2020_2116,50890,"i believe this paper does well by connecting the intuitive explanation with the proofs, and then by confirming their results through experimentation ..",soundness [SEP] positive [SEP]  i believe [SEP]  believe this paper [SEP]  connecting the intuitive explanation
ICLR_2020_2116,50891,there was no cross fold validation or even repeat trials with different partitioning to see whether the differences in performance were just random perturbations or a consistent effect ..,substance [SEP] negative [SEP]  no cross fold validation even repeat trials [SEP]  even repeat trials [SEP]  performance just random perturbations
ICLR_2020_1010,50892,the paper is well written the paper is mostly clear.,clarity [SEP] positive [SEP]  the paper is is well written [SEP]  the paper is is well written
ICLR_2020_1010,50893,and the ideas presented are interesting while this paper is interesting and highlights advantages of modeling transformations of sequential data.,originality [SEP] positive [SEP]  the ideas presented [SEP]  interesting this is paper advantages [SEP]  modeling transformations
ICLR_2020_1010,50894,"but in my opinion not novel enough or thoroughly demonstrated to justify acceptance i don't think the contributions are currently sufficient for iclr conference but since it stops at image registration, which is a well known existing model i cannot qualify the paper as novel ..",originality [SEP] negative [SEP]  do think the contributions [SEP]  a is well known existing model
ICLR_2020_1010,50895,a comparison with this related work would help assess the differences in terms of modelling power and in performances.,meaningful-comparison [SEP] negative [SEP]  a comparison related work [SEP]  assess the differences
ICLR_2020_1010,50896,the assumptions made in this work are fairly strong for most interesting applications the setup is reasonable.,soundness [SEP] positive [SEP]  the assumptions made [SEP]  made this work
ICLR_2020_1010,50897,some claims are not backed up by experiments.,soundness [SEP] negative [SEP]  some claims are not not backed [SEP]  claims are not not backed experiments
ICLR_2020_1010,50898,the authors only demonstrate the tevae on relatively simple experiments that are only tailored to simple image transformations and the experiments are lacking. and they should be explored in experiments.,substance [SEP] negative [SEP]  relatively simple experiments experiments [SEP]  the authors only demonstrate tevae [SEP]  only simple are tailored image transformations [SEP]  experiments are lacking they
ICLR_2020_1010,50899,the conditions on dot are interesting and potentially useful.,motivation [SEP] positive [SEP]  the conditions dot
ICLR_2020_618,50961,this is well supported as the model generates these and it is very reasonable that it can.,soundness [SEP] positive [SEP]  the model generates
ICLR_2020_618,50962,i think the idea could be presented in a better way. section 4.2 is a bit hard to read. it is not clear for me what is the goal of this section ..,clarity [SEP] negative [SEP]  think the idea [SEP]  it read not
ICLR_2020_618,50963,the presentation is clear ..,clarity [SEP] positive [SEP]  the presentation clear
ICLR_2020_618,50964,the general concept of exaggerating a feature that represented a class seems novel and exciting ..,originality [SEP] positive [SEP]  the general concept exaggerating feature [SEP]  a exaggerating feature [SEP]  a represented class
ICLR_2020_618,50965,the coverage of prior work is sufficient.,meaningful-comparison [SEP] positive [SEP]  the coverage prior work
ICLR_2020_479,51333,the meta learning approach appears to be a novel contribution. and presents an interesting method for structure learning the idea of disentangling the marginal and conditional factors to reduce the sample complexity and thus achieve fast adaptation is novel and insightful ..,originality [SEP] positive [SEP]  thus achieve fast adaptation [SEP]  the meta learning approach appears [SEP]  a be novel contribution [SEP]  an presents interesting method [SEP]  the reduce sample complexity
ICLR_2020_479,51334,"the paper is very well written i really enjoyed reading this paper. it is, well written, does a good job of connecting to related work.",clarity [SEP] positive [SEP]  connecting related work [SEP]  the paper is well written [SEP]  i is well written [SEP]  paper it reading [SEP]  a does good job
ICLR_2020_479,51335,and most claims are carefully proven proposition 1 and its proof provide the theoretical supports on this point very well ..,soundness [SEP] positive [SEP]  proof provide the theoretical supports well [SEP]  claims are carefully proven proposition
ICLR_2020_479,51336,"the empirical validation is not strong enough, as no real i am unconvinced of two of the theoretical claims made the simplicity of the representation learning setup doesn t convince that the method is applicable to more real world settings with more complicated encoders. even though the authors prove that the method will converge to the causal graph with lowest online likelihood, it is unclear why this is necessarily the correct causal graph ..",soundness [SEP] negative [SEP]  the causal graph unclear correct [SEP]  the empirical validation is not not not strong [SEP]  the not theoretical claims made simplicity [SEP]  the not made simplicity [SEP]  is real applicable more world settings [SEP]  the even authors prove
ICLR_2020_479,51337,"dataset is used, only toy datasets. the toy experiments themselves could also be more extensive. no experiments for more than two random variables are performed in this paper. would be great to add an additional experiment showing the results in this case the authors to provide discussions about real data tasks with neural causal models in future work ..",substance [SEP] negative [SEP]  authors provide discussions [SEP]  dataset is used [SEP]  is used only toy datasets [SEP]  experiments be more extensive no [SEP]  experiments more than two random variables are performed [SEP]  experiments are performed this paper [SEP]  experiment an add additional [SEP]  the showing results
ICLR_2020_479,51338,"additionally, some important details on this experiment are missing (see below). could you provide details on the representation learning experiment.",replicability [SEP] negative [SEP]  details experiment could provide the representation learning [SEP]  details could you provide [SEP]  important details details
ICLR_2020_479,51339,"clear, well motivated the paper does a good job of motivating its contribution and exploring its effect in simple intelligible tasks potentially quite significant as this is starting to bring causal structure learning into the realm of tensorflow and pytorch. .the work opens a new direction of inferring causal relationships together with representation learning, which has the potential for more out of distribution scenarios.",motivation [SEP] positive [SEP]  clear well motivated the paper does [SEP]  its exploring effect [SEP]  a work opens new direction [SEP]  the potential has
ICLR_2020_638,51795,this paper provides both theoretical insights and empirical demonstration of this remarkable property ..,soundness [SEP] positive [SEP]  this paper provides insights [SEP]  paper provides both theoretical insights [SEP]  both theoretical insights empirical demonstration
ICLR_2020_638,51796,paper will benefit quite a bit in its contributions through attempting a convergence analysis towards a stationary point even for solving a routine smooth non convex stochastic optimization problem ..,soundness [SEP] negative [SEP]  paper will benefit bit [SEP]  a attempting convergence analysis [SEP]  a solving routine smooth non convex stochastic optimization problem
ICLR_2020_638,51797,"2 .the writing of the proofs should be imporved. , but needs to be carefully read through because i see typos and ill formed sentences that should be rectified e.g .see point 3. i find the connections to other learning rates (such as the cosine learning rate) to be rather hard to understand interpret, in the current shape of the paper it is now a must read paper for anyone doing research on deep learning this paper is a bit rough around the edges, and reads a bit like a draft this paper is a bit rough around the edges, and reads a bit like a draft.",clarity [SEP] negative [SEP]  a reads draft [SEP]  the writing proofs [SEP]  understand interpret [SEP]  the interpret current shape [SEP]  learning paper deep this
ICLR_2020_638,51798,the paper is reasonably written (the proof of the main claim is fairly easy to follow) the authors improved the writing of the paper substantially relative to the first version they submitted.,clarity [SEP] positive [SEP]  the paper is is reasonably written [SEP]  the authors improved writing
ICLR_2020_638,51799,"the paper makes an interesting observation connecting the use of weight decay normalization to training the same network (without regularization) using an exponentially increasing learning rate schedule, under an assumption of scale invariance that is satisfied by normalization techniques including batch norm, layer norm and other variants ..",motivation [SEP] positive [SEP]  paper makes an interesting observation [SEP]  an using exponentially increasing learning rate schedule [SEP]  norm normalization techniques including
ICLR_2020_638,51800,"while the connection of scale invariant models to novel schemes of learning rates is interesting (and novel from a theory viewpoint, the paper offers new insights into batch normalization and other normalization schemes. from a theory viewpoint, the paper offers new insights into batch normalization and other normalization schemes ..",originality [SEP] positive [SEP]  paper offers new insights [SEP]  to novel schemes [SEP]  learning rates
ICLR_2019_103,51801,the motivation is clear.,motivation [SEP] positive [SEP]  the motivation clear
ICLR_2019_103,51802,", and the proposed strategy is original and to the point. novel, principled sequence to sequence model ..",originality [SEP] positive [SEP]  sequence sequence model model [SEP]  the proposed strategy original [SEP]  the point novel sequence [SEP]  the point novel principled sequence
ICLR_2019_103,51803,"2 .the technical content looks good, with each formula written clearly and with sufficient deductive steps. the hypothesis and derivations make statistical sense, and a couple of assumptions approximations seem to be mild. the overall quality of this paper is technically sound ..",soundness [SEP] positive [SEP]  technical content looks good [SEP]  each formula written clearly [SEP]  hypothesis derivations make sense [SEP]  hypothesis make statistical sense [SEP]  a couple assumptions
ICLR_2019_103,51804,figure 1 provides clear illustration on the comparison with traditional attentions and shows the advantage of the proposed model ..,meaningful-comparison [SEP] positive [SEP]  figure provides illustration [SEP]  provides clear illustration [SEP]  the shows advantage
ICLR_2019_103,51805,3 .extensive experiments are conducted including 5 machine translation tasks as well as another morphological inflection task. strong experimental results in machine translation and morphological inflection. the results clearly show the advantages of the proposed approach over soft and sparse attention baselines ..,substance [SEP] positive [SEP]  the results clearly show advantages [SEP]  3 extensive experiments are conducted [SEP]  including 5 machine translation tasks [SEP]  task another morphological inflection strong experimental results
ICLR_2019_103,51806,further ablation experiments could be included. the main missing experiment is not doing attention feeding at all ..,substance [SEP] negative [SEP]  further ablation experiments could be included [SEP]  the experiment experiments could be included main missing not [SEP]  experiment is not not not doing attention
ICLR_2019_103,51807,"the rich information contained in the paper is not very well organized. it takes some time to digest, due to some unclear or missing statements. this part is confusing it should be better to make the statement more clear by explicitly explaining eq (11) on how it assembles hard attention computation. 4 .can you explain how is the baseline prior joint constructed there are just a few typos and grammatical errors in sections 4.2 and 4.3 the authors need to clarify the following issues.",clarity [SEP] negative [SEP]  the clarify following issues [SEP]  the rich information contained not [SEP]  the contained paper [SEP]  the clear statement make [SEP]  explicitly explaining eq [SEP]  how assembles hard attention computation [SEP]  is explain you are [SEP]  the authors need
ICLR_2019_103,51808,"the paper is mostly written very clearly the ideas are presented well, if the readers go through it slowly or twice.",clarity [SEP] positive [SEP]  it readers go slowly [SEP]  the paper is mostly written clearly [SEP]  the ideas are presented well
ICLR_2019_103,51809,the two formulas for proximity biased coupling and monotonicity biased coupling are not well explained ..,replicability [SEP] negative [SEP]  the two formulas proximity biased coupling not
ICLR_2018_462,52145,"evaluated on a relevant multi task problem in general, the paper proposes an idea to tackle an interesting problem ..",motivation [SEP] positive [SEP]  the paper proposes idea [SEP]  an paper proposes idea [SEP]  an problem tackle interesting
ICLR_2018_462,52146,the authors have failed to convey to me why this direction of research is relevant. i do not think that this paper is relevant for the iclr conference.,motivation [SEP] negative [SEP]  this is do not think paper [SEP]  the authors have failed [SEP]  this direction research [SEP]  i relevant do not think
ICLR_2018_462,52147,"it is well written, the idea is well articulated and presented. everything is very clearly explained and the paper is generally well written ..",clarity [SEP] positive [SEP]  is the clearly explained paper [SEP]  is well written the idea [SEP]  presented everything
ICLR_2018_462,52148,the idea to represent task graphs are quite interesting. while this paper is as far as i can tell novel in how it does what it does the method is novel.,originality [SEP] positive [SEP]  the how does method [SEP]  the idea represent graphs [SEP]  can tell novel
ICLR_2018_462,52149,"however, it's still more convinced if the paper method is demonstrated in more domains. the experiments are somewhat lacking but at least show an improvement over more a naive approach only one type of tasks is used. it would also be a clear good addition to also demonstrate more convincing experiments in a different setting.",substance [SEP] negative [SEP]  more a experiments convincing different setting [SEP]  more method is demonstrated domains [SEP]  least show an improvement [SEP]  more a naive approach only one type [SEP]  a would also be clear good addition [SEP]  more demonstrate experiments also convincing
ICLR_2018_462,52150,the experiments cover different settings with different task difficulties ..,substance [SEP] positive [SEP]  the experiments cover settings [SEP]  experiments cover different settings
ICLR_2018_462,52151,it's not clear why learning seems to completely fail without the pre trained policy the example domain makes no sense ..,soundness [SEP] negative [SEP]  it not clear [SEP]  not why learning seems [SEP]  no not domain makes sense
ICLR_2018_462,52152,"it it thus hard to properly evaluate your method against other proposed methods. the paper is severely weakened by not comparing experimentally to other learning (hierarchical) schemes, none of the comparisons in the paper feature any learning i would have liked to see a discussion in the related work comparing the proposed approach to the long history of reasoning with subtasks from the classical planning literature, notably htns ..",meaningful-comparison [SEP] negative [SEP]  properly evaluate your method [SEP]  the none comparisons [SEP]  the the proposed related work approach [SEP]  the the proposed approach long history [SEP]  the long history reasoning
ICLR_2018_462,52153,it does not seem clear how the whole training is actually performed (beyond the pre training policy.,replicability [SEP] negative [SEP]  it does not not not seem clear [SEP]  does not not seem clear clear the whole training [SEP]  not how the training training is actually performed pre policy
ICLR_2018_182,52726,"in general, i think this paper is interesting. it s studying an important problem with a newly proposed neural net structure ..",motivation [SEP] positive [SEP]  i think is [SEP]  think this is paper [SEP]  s studying an important problem
ICLR_2018_182,52727,i think this paper.,motivation [SEP] negative [SEP]  i think paper
ICLR_2018_182,52728,the experimental results are good and the model is compared with very recent baselines. they seem to perform well on real datasets experiments provide some basic verification and analysis of the method.,substance [SEP] positive [SEP]  experiments provide some basic verification [SEP]  the experimental results good [SEP]  model is compared very recent baselines [SEP]  real datasets experiments provide verification
ICLR_2018_182,52729,"would help establish the sample complexity benefit more precisely and add important details about unsupervised disentangled representations the experimental evaluation is limited. they test their model only on a simple, artificial dataset. it would also be helpful to see a more extensive evaluation of the model's ability to learn logical recombination operators, since this is their main contribution this again could be addressed with experiments on more challenging datasets. but this does not seem to be tested with experiments.",substance [SEP] negative [SEP]  be again could addressed experiments [SEP]  establish the sample complexity [SEP]  is add important details [SEP]  test their model [SEP]  a more evaluation see extensive [SEP]  the model's ability learn operators [SEP]  learn logical recombination operators
ICLR_2018_182,52730,"i am, however, still lukewarm on this submission for its limited technical innovation and over simplified experimental.",originality [SEP] negative [SEP]  i however still lukewarm submission [SEP]  however still lukewarm this submission submission
ICLR_2018_182,52731,the idea of concept learning considered here is novel and satisfying. this clear and well written paper describes an interesting and novel way of learning a model of hierarchical concepts. the idea of learning compositional representations inside of a vae framework is very appealing ..,originality [SEP] positive [SEP]  the idea hierarchical concepts [SEP]  concept learning considered here [SEP]  and this clear well written paper describes way [SEP]  novel an and paper describes interesting way
ICLR_2018_182,52732,i would strongly suggest the authors perform additional experiments on standard benchmarks for a fair comparison. is missing some important evaluation. there should be a more systematic evaluation of this claim it's missing some evaluation that.,meaningful-comparison [SEP] negative [SEP]  evaluation more systematic this claim [SEP]  would strongly suggest the authors [SEP]  authors perform additional experiments [SEP]  is missing some important evaluation
ICLR_2018_182,52733,"qualitatively, concept samples are correct and diverse, generating images with all configurations of attributes not specified by the input concept. and it provides useful visualizations and implementation.",soundness [SEP] positive [SEP]  provides useful visualizations [SEP]  concept samples correct [SEP]  concept not specified the input
ICLR_2018_182,52734,there seems to be a mistake in figure 5 unless i interpreted it incorrectly. the paper should explain the differences and trade offs between other multimodal vae models more clearly. it should also clarify differences between the scan u baseline and scan in the main text ..,clarity [SEP] negative [SEP]  the scan main text [SEP]  the paper should explain offs clearly [SEP]  the paper should explain differences and trade offs clearly [SEP]  the u should differences also clarify scan baseline
ICLR_2018_182,52735,the paper is well written.,clarity [SEP] positive [SEP]  the paper is well written
ICLR_2018_182,52736,details in the appendix.,replicability [SEP] positive [SEP]  details the appendix
ICLR_2020_592,52768,this paper is clearly presented the paper is well written. it is well structured and easy to follow ..,clarity [SEP] positive [SEP]  this is paper clearly presented [SEP]  is paper clearly presented the [SEP]  is well written it
ICLR_2020_592,52769,and the algorithm shows gains over other methods the contributions are solid ..,soundness [SEP] positive [SEP]  the algorithm shows gains are [SEP]  algorithm shows gains are
ICLR_2020_592,52770,but did you do any error analysis on the models.,substance [SEP] negative [SEP]  did you do analysis [SEP]  did do any error analysis
ICLR_2020_592,52771,"the paper conducted good analysis demonstrating the effectiveness of the proposed components, including detailed ablation analysis ..",substance [SEP] positive [SEP]  analysis including detailed ablation [SEP]  paper conducted good analysis [SEP]  the demonstrating effectiveness
ICLR_2020_1926,52791,the rest of the machinery is well motivated and well.,motivation [SEP] positive [SEP]  the the rest machinery
ICLR_2020_1926,52792,no test of statistical significance is presented ..,substance [SEP] negative [SEP]  no test statistical significance
ICLR_2020_1926,52793,this will make this table much easier to read ..,clarity [SEP] positive [SEP]  this will make table easier
ICLR_2020_1926,52794,"but the paper has a lot of issues both technically and grammatically, which makes the paper hard to follow. 1 .on writing there are glaring grammar errors in numerous places. this is hard to parse. 2 .on math notation the math notation is messy and there are lots of inaccuracies. there are many typos and wrong notations in the text. overall, the descriptions in this subsection is confusing. this paper is poorly written and difficult to follow ..",clarity [SEP] negative [SEP]  paper is this confusing poorly written difficult [SEP]  the paper has lot technically [SEP]  are glaring grammar errors [SEP]  on parse 2 math notation [SEP]  the math notation wrong notations [SEP]  many typos wrong notations
ICLR_2020_1926,52795,the idea is ok and the concept of using adain for efficient voice conversion is also good ..,soundness [SEP] positive [SEP]  the idea is ok [SEP]  using adain
ICLR_2020_325,52906,"there seem to be a lot of errors and typos in the manuscript, which made the paper unfortunately a bit frustrating to review. in algorithm 1, there seem to be some typos which makes it difficult understand the method in detail. i could not follow the reasoning in section 2.2 and the clarity should be improved please use operatorname or text in math mode for operators such as var or text ..",clarity [SEP] negative [SEP]  the made paper frustrating [SEP]  typos some makes difficult [SEP]  the understand method [SEP]  the could not not follow reasoning [SEP]  text math mode
ICLR_2020_325,52907,i also don't see too much novelty in this approach.,originality [SEP] negative [SEP]  i don't n't n't see novelty [SEP]  don't n't see too much novelty
ICLR_2020_325,52908,and i like that it doesn.,originality [SEP] positive [SEP]  i like [SEP]  it doesn
ICLR_2020_325,52909,"while this new metric is compared qualitatively to existing methods, quantitative evaluation is lacking.",substance [SEP] negative [SEP]  this is new metric compared qualitatively [SEP]  is metric existing methods quantitative
ICLR_2020_325,52910,it would be useful to also include quantitative comparison of methods measuring the perceptual distance between the original image and the embedded image.,meaningful-comparison [SEP] negative [SEP]  it would be useful [SEP]  also include quantitative comparison [SEP]  methods measuring distance
ICLR_2020_325,52911,"this is a well reasoned and well presented paper following in the spirit of smile vector type investigations, with compelling results ..",soundness [SEP] positive [SEP]  a well well reasoned and presented paper following [SEP]  following the spirit [SEP]  smile vector type investigations
ICLR_2020_1746,54035,"their work gave a rather detailed motivation and analysis of their findings, proposing and testing several hypotheses for how and when model based methods could outperform replay based model free variants ..",substance [SEP] positive [SEP]  how model based methods could outperform replay free variants [SEP]  work gave a rather detailed motivation [SEP]  testing several hypotheses
ICLR_2020_1746,54036,the first is the presentation of the empirical results. a way to improve the paper would be to make it clear from the beginning that these results are about dyna style algorithms in the atari domain ..,clarity [SEP] negative [SEP]  the first presentation [SEP]  the improve paper [SEP]  the make clear beginning are
ICLR_2020_1746,54037,the paper is well written.,clarity [SEP] positive [SEP]  the paper is well written
ICLR_2020_1746,54038,the paper is written as if the conclusions could be extended to model based methods in general.,soundness [SEP] negative [SEP]  the paper is written [SEP]  the paper is written conclusions [SEP]  to model based methods
ICLR_2020_1746,54039,and the experiments are well designed to support the claim ..,soundness [SEP] positive [SEP]  the experiments are well designed [SEP]  the support claim
ICLR_2020_1746,54040,"however, the research contribution of the project is limited to image space discrete rl tasks, and does not cover the wide range other rl. in terms of the novelty, the proposed algorithm is not fundamentally different from rainbow ..",originality [SEP] negative [SEP]  the the research contribution project [SEP]  however is limited image space discrete rl tasks [SEP]  the terms novelty
ICLR_2018_256,54666,"having scalable models is important, the extension of an approach for learning with privacy to make it scalable is of merit. this is for sure an important topic ..",motivation [SEP] positive [SEP]  important an sure topic [SEP]  important the extension [SEP]  learning privacy
ICLR_2018_256,54667,"the paper is well written, and the idea of the model is clear ..",clarity [SEP] positive [SEP]  the paper is
ICLR_2018_256,54668,i think some clarification is needed with regard to item c above.,clarity [SEP] negative [SEP]  i think [SEP]  think some clarification
ICLR_2018_256,54669,i personally would prefer to see the proposed model applied to this kind of data sets as well it would be great to discuss and show experimental results for utility privacy tradeoff with different variances of laplace and gaussian noise ..,substance [SEP] negative [SEP]  utility privacy tradeoff different variances [SEP]  see the proposed model [SEP]  show experimental results
ICLR_2018_256,54670,the paper proposes novel techniques for private learning with pate framework ..,originality [SEP] positive [SEP]  the paper proposes techniques [SEP]  paper proposes novel techniques
ICLR_2018_256,54671,it would be helpful to add a comparison ..,meaningful-comparison [SEP] negative [SEP]  it would be helpful [SEP]  a add comparison
ICLR_2018_153,54796,the paper is clearly motivated.,motivation [SEP] positive [SEP]  the paper clearly motivated
ICLR_2018_153,54797,and authoritative in its conclusions but it's somewhat lacking in detailed model or experiment descriptions ..,replicability [SEP] negative [SEP]  authoritative its conclusions
ICLR_2018_153,54798,"first, it wasn't completely clear to me what the down projection is there has been some confusion in the literature as to which of these parameterizations is better or more standard.",clarity [SEP] negative [SEP]  these parameterizations better more [SEP]  n't completely clear me [SEP]  has been some confusion
ICLR_2018_153,54799,the plot in figure 2 is clear and persuasive.,clarity [SEP] positive [SEP]  the plot figure
ICLR_2018_153,54800,the results are interesting ..,substance [SEP] positive [SEP]  the results interesting
ICLR_2018_153,54801,and less tuning is needed for these larger datasets ..,substance [SEP] negative [SEP]  less tuning is needed [SEP]  tuning is needed these larger datasets
ICLR_2019_1114,54824,"i have have three main concerns unconvining experiments. the experiments seem not convincing. i am suspicious the proposed model is overfitted, in my opinion the intuition, effect and limitations of the cross graph attention mechanism should be described in more detail. the main problem of the paper is that it is not clear where the performance improvement comes from ..",soundness [SEP] negative [SEP]  the not performance improvement comes [SEP]  three main concerns unconvining experiments [SEP]  experiments the seem not convincing [SEP]  the suspicious proposed model is overfitted [SEP]  main the more detail problem
ICLR_2019_1114,54825,"firstly, no details of dataset split is given ..",replicability [SEP] negative [SEP]  no details dataset split
ICLR_2019_1114,54826,the experimental comparison is largely convincing ..,meaningful-comparison [SEP] positive [SEP]  the experimental comparison largely convincing
ICLR_2019_1114,54827,i would like to suggest to also use a simple heuristics for the graph edit distance as a baseline.,meaningful-comparison [SEP] negative [SEP]  i would like [SEP]  a also use simple heuristics
ICLR_2019_1114,54828,the proposed approach is motivated by graph matching and a connection to the graph edit distance is implied.,motivation [SEP] negative [SEP]  the proposed approach is motivated [SEP]  approach is motivated graph matching [SEP]  a graph matching connection
ICLR_2019_1114,54829,some discussion on this would be very fruitful. it would be nice if the author can do some ablation study on the structure of the new matching module ..,substance [SEP] negative [SEP]  some the ablation study structure [SEP]  some discussion would be fruitful [SEP]  some author can do ablation study
ICLR_2019_1152,54905,the paper deals with a topic of interest for the autonomous driving community.,motivation [SEP] positive [SEP]  the paper a deals topic [SEP]  the paper a deals topic [SEP]  a topic interest
ICLR_2019_1152,54906,the paper could be written better. it seems unfinished and some additional proof reading is necessary to correct the multiple typos across the paper.,clarity [SEP] negative [SEP]  the paper could be written better [SEP]  is some additional proof reading necessary [SEP]  the correct multiple typos
ICLR_2019_1152,54907,"there are no quantitative results and no comparisons with baselines and related works, making it difficult to evaluate the performances of this work. there is no baseline or other related method considered for this evaluation. the segnet family of works as well as many works leveraging the now established skip connection u net architecture is missing entirely ..",meaningful-comparison [SEP] negative [SEP]  no no quantitative results comparisons [SEP]  related other method considered [SEP]  this considered evaluation [SEP]  related works making difficult
ICLR_2019_1152,54908,it is not clear from which set where the 500 images taken and how representative they are for the entire dataset the structure of the proposed architecture is not clear when it comes to the quantitative evaluation some important detail appears to be missing much of the experimental detail is also left unclear ..,replicability [SEP] negative [SEP]  the detail be missing much much experimental [SEP]  not set where the 500 images structure [SEP]  it clear
ICLR_2019_1152,54909,much of the evidence corroborating the principal claims of the submission appears to be missing. the evaluation itself is mainly qualitative and does not serve to convince the reader that the approach offered here is beneficial. though much remains to be done to make the science case more convincing ..,soundness [SEP] negative [SEP]  the make science case convincing [SEP]  the evidence corroborating claims [SEP]  much the submission appears [SEP]  the approach offered here
ICLR_2019_1152,54910,this is also not remedied in the experimental evaluation as almost no benchmarking to the established state of the art is performed ..,substance [SEP] negative [SEP]  remedied the experimental evaluation [SEP]  the benchmarking established state
ICLR_2020_544,55021,"results are very clearly presented, and writing is clear throughout. the paper is well written.",clarity [SEP] positive [SEP]  results are clearly presented [SEP]  clear writing is
ICLR_2020_544,55022,"in this way, the main message of the paper seems misleading to practitioners ..",clarity [SEP] negative [SEP]  message seems misleading misleading practitioners [SEP]  this way the main message [SEP]  the message paper seems misleading
ICLR_2020_544,55023,these results are significantly weaker than any multiple source attack ..,soundness [SEP] negative [SEP]  these results significantly weaker [SEP]  significantly weaker any multiple source attack
ICLR_2020_544,55024,simple approach that seems to be giving good results.,soundness [SEP] positive [SEP]  simple approach seems [SEP]  be giving good results
ICLR_2020_544,55025,"there are several very interesting empirical findings in this paper to the best of my knowledge, this is the first time someone has identified the skip connections security problem in resnets ..",originality [SEP] positive [SEP]  several very interesting empirical findings this paper [SEP]  best my knowledge [SEP]  the first time has identified problem
ICLR_2020_544,55026,the method is simple and comprehensive experiments are conducted to prove its correctness ..,substance [SEP] positive [SEP]  the method simple experiments [SEP]  prove its correctness
ICLR_2020_544,55027,"although, the paper includes ablation analysis for different values of the decay factor.",substance [SEP] negative [SEP]  the paper includes analysis [SEP]  paper includes ablation analysis [SEP]  ablation analysis different values
ICLR_2020_544,55028,it is a good empirical paper that can inspire future research on investigating the role of shortcuts when defending adversarial examples ..,motivation [SEP] positive [SEP]  it good paper [SEP]  a good empirical paper can inspire research [SEP]  can inspire future research [SEP]  investigating the role
ICLR_2020_544,55029,"results are reported without variance information there are some details missing on how the decay factor is selected, i could not find details on how the decay factor hyperparamenter is selected ..",replicability [SEP] negative [SEP]  are the details decay factor could not not find hyperparamenter [SEP]  results are reported variance information
ICLR_2020_1496,55525,"another also strong point of this paper is that several experiments under different settings are presented, along with ablation studies and some model exploration. strengths slight improvements on a wide range of downstream tasks qualitative analysis of dynamic recursion highlighting the adaptability of the method to different task properties weaknesses from the equations in section 2.",substance [SEP] positive [SEP]  the different task method properties weaknesses [SEP]  another also strong point this paper [SEP]  several experiments different settings [SEP]  ablation studies some model exploration [SEP]  strengths slight improvements [SEP]  strengths downstream tasks qualitative analysis [SEP]  strengths qualitative analysis analysis
ICLR_2020_1496,55526,i think that more discussions and ellaboration on this could be useful i am also missing stacked lstm in experiments on logical inference (table 2.,substance [SEP] negative [SEP]  i think [SEP]  i think [SEP]  am also missing stacked lstm table
ICLR_2020_1496,55527,"finally, one can argue that this work is incremental.",originality [SEP] negative [SEP]  finally one can argue is
ICLR_2020_1496,55528,and variations with respect to other methods in literature should.,clarity [SEP] negative [SEP]  and variations respect [SEP]  respect other methods
ICLR_2020_1496,55529,stands for in caption of table 1 overall it is a good and well written paper.,clarity [SEP] positive [SEP]  caption table
ICLR_2020_1496,55530,the obvious connection with this work and work of alex graves on adaptive computation for recurrent neural nets and many of its followups including universal transformers by dehghani et al is missing from experimental comparison and is not even mentioned in related section ..,meaningful-comparison [SEP] negative [SEP]  is not not even mentioned related section [SEP]  the obvious connection this work [SEP]  is missing experimental comparison
ICLR_2020_1965,55596,a variety of empirical results.,substance [SEP] positive [SEP]  a variety empirical results
ICLR_2020_1965,55597,confirm the theoretical analysis. the conference is a venue with quality control ..,soundness [SEP] positive [SEP]  confirm the theoretical analysis [SEP]  the a conference venue
ICLR_2020_1965,55598,the modifications made by the authors are still not sufficient ..,soundness [SEP] negative [SEP]  the modifications made not [SEP]  the made authors
ICLR_2020_1965,55599,the results presented here are interesting and i particularly liked the introduction of the renormalized kernel to study the noiseless case abundance of new ideas and novel content i agree that there could potentially be great ideas in this paper ..,originality [SEP] positive [SEP]  ideas could potentially be great this paper [SEP]  the particularly liked introduction
ICLR_2020_1965,55600,"the topic is salient and will interest most theoretically minded researchers, and i think there is an they made much effort to address the issues i raised ..",motivation [SEP] positive [SEP]  i is think [SEP]  will interest most theoretically minded researchers [SEP]  made much effort [SEP]  the address issues
ICLR_2020_1965,55601,"i think more effort should be devoted to speaking to the machine learning audience this paper is poorly written. many mathematic notations and terminologies are not well defined. i don't think readers can figure out what is exactly the kernel and the target function from this description. i am concerned about the writing style of this paper. but i think the authors should write equations in a clear way. however, the paper is poorly written. the authors failed to deliver effective scientific communication to the readers. i found that the authors modified and improved their manuscript a lot i asked the authors in my review to clarify what is the target function for the experiments jargons and non rigorous tools.",clarity [SEP] negative [SEP]  the machine learning audience [SEP]  learning audience [SEP]  the concerned writing style [SEP]  deliver effective scientific communication [SEP]  improved their manuscript lot [SEP]  should the authors write equations [SEP]  readers can figure what
ICLR_2020_1965,55602,"the papers these physicists wrote deliver clear scientific communications, though also using.",clarity [SEP] positive [SEP]  deliver clear scientific communications
ICLR_2020_1965,55603,the setup of the experiments are not given clearly ..,replicability [SEP] negative [SEP]  the the setup experiments not
ICLR_2020_1965,55604,it would be nice to cite related literature and compare the results ..,meaningful-comparison [SEP] negative [SEP]  it would be nice [SEP]  cite related literature [SEP]  compare the results
ICLR_2020_1895,55699,2 .the application and combination of different techniques in this paper are smart. it is a good application of known techniques the solution designed for this problem seems very reasonable. experiments are useful and reasonable and the experimental results are promising and in the favor of the paper. it could be a correct piece of code for.,soundness [SEP] positive [SEP]  a could be correct piece [SEP]  application combination [SEP]  a application good known [SEP]  the solution designed [SEP]  this solution problem seems reasonable [SEP]  seems very reasonable experiments [SEP]  the are experimental results promising [SEP]  the are results promising favor
ICLR_2020_1895,55700,the incorrect binary operator example in listing 2 does not seem to be a well justified bug.,soundness [SEP] negative [SEP]  the incorrect binary operator example listing not [SEP]  a not be well justified bug
ICLR_2020_1895,55701,3 .the experiment results show better performance of contextual embedding based method compared with non contextual embedding based methods ..,substance [SEP] positive [SEP]  based non methods [SEP]  results show better performance [SEP]  contextual embedding based method
ICLR_2020_1895,55702,"2 .it is suggested to evaluate the effectiveness of the proposed approach on various source code analysis task such as variable misuse. however, implementation, representation and dataset are missing ..",substance [SEP] negative [SEP]  evaluate the effectiveness [SEP]  various source code analysis task such [SEP]  such variable misuse
ICLR_2020_1895,55703,but the novelty is limited. the paper is a bit low in technicality ..,originality [SEP] negative [SEP]  the novelty is limited [SEP]  the novelty is limited paper [SEP]  bit low technicality
ICLR_2020_1895,55704,3 .it is suggested to compare with other state of the art baseline methods.,meaningful-comparison [SEP] negative [SEP]  compare other state
ICLR_2020_1895,55705,the paper addresses an important and impactful problem. accept i think this paper is overall a good work and can open direction of research even beyond the scope of the paper.,motivation [SEP] positive [SEP]  the paper addresses problem [SEP]  paper addresses an important and impactful problem [SEP]  paper think this is [SEP]  a good work can open direction [SEP]  can open direction [SEP]  the research scope
ICLR_2020_1895,55706,the paper is well written and clear ..,clarity [SEP] positive [SEP]  the paper well written clear
ICLR_2020_1779,56119,i like the idea and hope the authors improve the paper and submit to a future conference 1 .the idea for this.,originality [SEP] positive [SEP]  idea a submit future conference [SEP]  like the idea [SEP]  the hope authors [SEP]  the authors improve paper
ICLR_2020_1779,56120,2 .i m not convinced about the novelty of this paper. the proposed idea.,originality [SEP] negative [SEP]  convinced the novelty
ICLR_2020_1779,56121,"2017 .thus her (preferably implemented with sac rather than ddpg for fair comparison) is a vital baseline that is missing from figure 3 1 .the experiments presented in this paper do not include appropriate comparisons to baseline methods. while indeed the proposed method outperforms pearl, this comparison is inherently unfair. therefore, directly comparing the proposed method to any general meta rl algorithm is unfair. the lack of proper baselines ..",meaningful-comparison [SEP] negative [SEP]  presented this paper [SEP]  experiments do not not not include appropriate comparisons
ICLR_2020_1779,56122,there are no experiments supporting this i think the addition of these experiments would greatly strengthen the paper.,substance [SEP] negative [SEP]  the addition would greatly strengthen paper [SEP]  no experiments supporting [SEP]  the think addition
ICLR_2020_1779,56123,2 .the authors provide a detailed description of the configurations and the hyperparameters for each experiments. carefully investigated.,substance [SEP] positive [SEP]  authors provide description [SEP]  a authors provide detailed description [SEP]  the the configurations hyperparameters
ICLR_2020_1779,56124,overall i think this paper presents an interesting idea in learning fast adapting goal reaching policies ..,motivation [SEP] positive [SEP]  goal reaching policies [SEP]  overall i think [SEP]  overall think this paper [SEP]  paper presents an interesting idea [SEP]  learning fast adapting goal
ICLR_2020_1779,56125,the idea is very well presented paper is really well presented. the structure of the paper is well organized and the authors include informative illustration to explain the architecture of the hierarchy of policies. the experiment results are easy to interpret. the idea in the paper is well presented and.,clarity [SEP] positive [SEP]  the idea well presented [SEP]  authors include informative illustration [SEP]  the explain architecture
ICLR_2020_1779,56126,a second concern is that i'm confused about the experimental protocol. latent variable z this sentence doesn't make sense as written.,clarity [SEP] negative [SEP]  doesn't n't make sense [SEP]  a second concern confused
ICLR_2020_1779,56127,and authors include many empirical evidence to support the proposed method ..,soundness [SEP] positive [SEP]  authors include evidence [SEP]  authors include many empirical evidence [SEP]  support the proposed method
ICLR_2020_1779,56128,i am still not convinced about and the magnitude of performance improvement given i am leaning towards rejecting this paper because many of the claims made in the paper are not empirically validated. it would be quite inefficient to directly learn such a policy.,soundness [SEP] negative [SEP]  a directly learn such policy [SEP]  performance improvement given [SEP]  i not convinced [SEP]  the claims made [SEP]  it be would inefficient
ICLR_2020_1779,56129,how is the reward function for the low level policy defined the experimental protocol were clarified.,replicability [SEP] negative [SEP]  the reward function low level [SEP]  the low level policy defined protocol [SEP]  the defined experimental protocol
ICLR_2019_59,56341,i think this paper is a useful contribution. well motivated approach.,motivation [SEP] positive [SEP]  i think is [SEP]  think this is paper [SEP]  this paper a useful contribution
ICLR_2019_59,56342,i like the idea behind the algorithm ..,originality [SEP] positive [SEP]  i like idea [SEP]  like the idea
ICLR_2019_59,56343,the submitted paper misses an extremely relevant piece of literature.,meaningful-comparison [SEP] negative [SEP]  paper misses an extremely relevant piece
ICLR_2019_59,56344,the experiments comprise only some simulations ..,substance [SEP] negative [SEP]  the experiments comprise simulations [SEP]  experiments comprise only some simulations
ICLR_2019_59,56345,"experiments on diversified data sets to show their approach's performance, with.",substance [SEP] positive [SEP]  experiments diversified [SEP]  show their approach's performance
ICLR_2019_59,56346,with good examples from clinical setting sound proof on why information theoretical approach is better than mle based approaches fairly strong assumption on the existence of mutually independent senior experts in the labeling process.,soundness [SEP] positive [SEP]  the existence mutually independent senior experts [SEP]  good examples clinical setting sound proof [SEP]  why information theoretical approach is better [SEP]  the fairly strong assumption existence
ICLR_2019_59,56347,hard to check assumption for theorem 3.4 for real world problems i believe this line of work will benefit the community in taking a more information theoretical approach with relaxed assumptions on the data collection process.,soundness [SEP] negative [SEP]  a more information theoretical approach relaxed assumptions [SEP]  check assumption [SEP]  hard real world problems believe [SEP]  hard believe this line [SEP]  the line will benefit community [SEP]  a taking more information theoretical approach
ICLR_2019_59,56348,on the sufficiency of senior expert's info to predict the true class label the paper is in general well written.,clarity [SEP] positive [SEP]  the sufficiency senior expert [SEP]  the predict true class label
ICLR_2020_2071,56808,the idea is not very novel since several previous work have tried the mixture of flow such as the mentioned rad and deep mixture i think though the paper makes contribution on exploring better flow models but the novelty is relatively weak.,originality [SEP] negative [SEP]  flow exploring better models [SEP]  the idea is not not not novel [SEP]  the not work have tried mixture [SEP]  i think [SEP]  paper makes contribution
ICLR_2020_2071,56809,the paper tries to solve a problem build upon intuition ..,motivation [SEP] positive [SEP]  the paper tries [SEP]  a solve problem [SEP]  build intuition
ICLR_2020_2071,56810,the intuition of the paper is weak and heuristic there are some rough edges to this paper ..,clarity [SEP] negative [SEP]  the intuition paper this [SEP]  heuristic some rough edges
ICLR_2020_2071,56811,the initial motivation is well presented and relatively easy to follow.,clarity [SEP] positive [SEP]  the initial motivation is well presented easy
ICLR_2020_2071,56812,", the discussion and comparison of related work is insufficient for the experiment section, i would have liked to have seen comparisons not only to the simplest baseline but also to some of the other methods mentioned in related works. it omits comparisons with more recent generative flows that have shown to be able to model discontinuous densities. it also makes the comparison with previous methods more difficult.",meaningful-comparison [SEP] negative [SEP]  methods methods more previous difficult [SEP]  the the discussion comparison [SEP]  the other methods mentioned [SEP]  related mentioned works [SEP]  have seen comparisons [SEP]  comparisons omits more recent generative flows [SEP]  the comparison also makes
ICLR_2020_2071,56813,"the experiments are not convincing or have mistakes their justifications are nonetheless largely conjectural and further theoretical or empirical evidence would be welcome in its current state, this work appears to be quite fragile both from a theoretical and experimental point of view. the whole paper rests on intuition without strong theoretical backup. the question remains whether using a continuous mixture translates into significant improvements for those baselines as well it is not clear why generative models that are good at sampling only gans) should not then be preferred.",soundness [SEP] negative [SEP]  the experiments are not not not not convincing mistakes [SEP]  not or largely conjectural and further theoretical empirical evidence would be welcome [SEP]  not would be welcome welcome its current state [SEP]  are this work appears [SEP]  experimental point view [SEP]  the is question remains [SEP]  translates significant improvements well
ICLR_2020_2071,56814,"the observation that continuity imposes a hard constraint on the network is sound, and the proposed solution appears to show some improvement ..",soundness [SEP] positive [SEP]  show some improvement [SEP]  a continuity imposes hard constraint [SEP]  the proposed solution appears
ICLR_2020_2071,56815,"in general, the experiment section is quite short and i didn't get a very good sense of how well this method performs second, the experimental evaluation is weak and insufficient. the experiments are quite poor and results frankly oversold ..",substance [SEP] negative [SEP]  the insufficient experiments [SEP]  a didn't n't get very good sense [SEP]  well this method performs second [SEP]  the well method experimental evaluation weak
ICLR_2020_555,57201,there are some drawbacks that limit the significance of this paper.,motivation [SEP] negative [SEP]  some drawbacks limit significance [SEP]  the limit significance
ICLR_2020_555,57202,kernel which is of great interest to the theoretical deep learning community as it describes gradient descent dynamics in a tractable way this is an important contribution to understand finite depth and width corrections to the ntk ..,motivation [SEP] positive [SEP]  is great interest [SEP]  an important contribution understand depth [SEP]  understand finite depth
ICLR_2020_555,57203,"the authors should refer to the work of arora et al. , 2019 which afaik is the first paper that provides empirical study of the ntk predictor at infinite width on relatively large datasets like cifar 10 there are two main limitations of otherwise significant work ..",meaningful-comparison [SEP] negative [SEP]  work two main limitations otherwise significant [SEP]  the authors should refer [SEP]  the authors should refer work [SEP]  work otherwise significant [SEP]  the is first paper [SEP]  provides empirical study
ICLR_2020_555,57204,second limitation is lack of empirical check ..,substance [SEP] negative [SEP]  second limitation lack
ICLR_2020_555,57205,i still believe that empirical support should be a strong foundation of science of neural networks and this paper would improve even with some toy model implication of simultaneous depth width limit.,soundness [SEP] negative [SEP]  paper would improve some toy model implication simultaneous [SEP]  i still believe [SEP]  still believe empirical support [SEP]  be a support should strong foundation
ICLR_2020_1525,58032,"regarding the usage of energy based models, the idea is interesting. this is interesting, and different from previous methods, which use either an explicit vector of factors that is input to a generator function, or object slots that are blended to form an image. i think the idea proposed by this paper is of novel interest.",originality [SEP] positive [SEP]  regarding the usage [SEP]  different previous methods use vector [SEP]  an form image [SEP]  i is think [SEP]  the idea is interesting
ICLR_2020_1525,58033,the concept inference is not clear from the text mostly because of unclear writing some sentences are not clear writing can be improved. the description of the dataset in section 3.4 is barely readable at least there should be some more detailed description of the settings in the.,clarity [SEP] negative [SEP]  the description more detailed settings [SEP]  the concept inference not clear [SEP]  the clear text [SEP]  not clear writing some sentences [SEP]  clear be writing [SEP]  the not be writing can improved description
ICLR_2020_1525,58034,"this paper is well motivated i agree with the authors that the composition of energy based models is a very desirable property and a very important direction to explore, and i believe that the work of this paper can have great potential in the future ..",motivation [SEP] positive [SEP]  work can have great potential [SEP]  is agree the authors [SEP]  a energy based models very desirable property [SEP]  the believe work [SEP]  this paper well motivated agree
ICLR_2020_1525,58035,showing compositional generation and inference for images.,substance [SEP] positive [SEP]  showing compositional generation
ICLR_2020_1525,58036,convincing quantitative experiments on disjunction and negation lacks ..,substance [SEP] negative [SEP]  convincing quantitative experiments
ICLR_2020_1525,58037,"5 .the description of the baseline joint model in section 3.4 is missing. since the results in table 1 do not involve composition of energies it is desirable to compare the results with other generative models as well, such as conditional pixelcnn.",meaningful-comparison [SEP] negative [SEP]  5 the description baseline model [SEP]  the results table not [SEP]  results do not not not involve composition
ICLR_2020_1525,58038,but the paper still lacks in sound justification of assuming equal normalizing constants in concept disjunction and concept negation.,soundness [SEP] negative [SEP]  the paper still lacks [SEP]  paper still lacks sound justification [SEP]  assuming equal normalizing constants
ICLR_2020_1525,58039,"there is no detailed description of model architecture or hyperparameter in the paper. the author provide no detailed information on how the model was trained no code is available. the paper is very hard to reproduce, which hurts the reliability of the experimental.",replicability [SEP] negative [SEP]  the no detailed description model [SEP]  no detailed author provide information [SEP]  is no model how was trained code
ICLR_2020_1326,58444,confirm that both the hierarchical setup and the joint intrinsic rewards are useful.,substance [SEP] positive [SEP]  confirm both the hierarchical setup are
ICLR_2020_1326,58445,"it makes me wonder if there is a way to employ these exploration schemes in a non centralized training form it would be better to use more standard tasks if they are available however, the experiments are conducted only with a very limited number of agents (only 2 in the non toy environment of vizdoom but would benefit better investigation.",substance [SEP] negative [SEP]  would better benefit investigation [SEP]  use more standard tasks [SEP]  they are available however [SEP]  the are experiments conducted [SEP]  a very limited number agents
ICLR_2020_1326,58446,though paper is reasonably well written.,clarity [SEP] positive [SEP]  paper is well written
ICLR_2020_1326,58447,it would be good to include more learning curves in the main text for the paper.,clarity [SEP] negative [SEP]  it would be good [SEP]  include more learning curves [SEP]  more learning curves the main text
ICLR_2020_1326,58448,i find the contributions are very marginal ..,originality [SEP] negative [SEP]  i find are [SEP]  find the contributions are
ICLR_2020_1326,58449,overall i like the approach in the paper. it proposes a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi agent systems. this design seems rather unique in that this part of the policy can optimizing for which intrinsic reward to toggle based on the extrinsic rewards observed.,originality [SEP] positive [SEP]  overall like the approach [SEP]  it proposes method [SEP]  a proposes nice 2 pronged method [SEP]  this design seems unique [SEP]  for intrinsic reward part can optimizing which
ICLR_2020_1326,58450,if authors can position the paper well with the existing literature and bring out the impact of the contributions it will be helpful.,meaningful-comparison [SEP] negative [SEP]  the bring impact [SEP]  authors can position the paper well [SEP]  the existing literature bring impact
ICLR_2020_1326,58451,the parts that a bit lacking with the current version of the paper in this are the evaluation tasks are few and a bit simple and i think there needs to be more discussion on the coverage of the intrinsic reward types task 2 seems a bit contrived. i am not sure if the discussion on the behaviours the intrinsic reward functions result in are very surprising.,soundness [SEP] negative [SEP]  the discussion not sure result [SEP]  the bit lacking current version [SEP]  i think not
ICLR_2020_1326,58452,this method appears to work well in the centralized training scheme that many have adopted recently.,soundness [SEP] positive [SEP]  this method appears [SEP]  the centralized training scheme many
ICLR_2020_1326,58453,this does not make the problem very multi agent with different goals ..,motivation [SEP] negative [SEP]  does not not make the problem agent
ICLR_2018_36,58507,it will be informative to provide results with a single gp model correct annotation of enough cases to train a deep model in many domains is not affordable there is a need for more experimental study to show how the methodology work.,substance [SEP] negative [SEP]  a need more [SEP]  provide results [SEP]  not not many domains is affordable
ICLR_2018_36,58508,the suggested method seems to work well on and have good experimental.,soundness [SEP] positive [SEP]  the suggested method seems
ICLR_2018_36,58509,the methodology seems pretty ad hoc to me and.,soundness [SEP] negative [SEP]  the methodology seems
ICLR_2018_36,58510,this algorithm can be useful because.,motivation [SEP] positive [SEP]  this algorithm can be useful
ICLR_2018_36,58511,my main problem with the paper is the lack of enough motivation and justification for the proposed method.,motivation [SEP] negative [SEP]  my main problem the paper [SEP]  the lack enough motivation
ICLR_2018_36,58512,"the paper is well written, easy to follow ,.",clarity [SEP] positive [SEP]  the paper well written easy
ICLR_2018_36,58513,the idea of using surrogate labels to learn representation is also not new ..,originality [SEP] negative [SEP]  the idea using labels not [SEP]  using surrogate labels [SEP]  learn representation
ICLR_2018_36,58514,the authors didn't compare their method with this one ..,meaningful-comparison [SEP] negative [SEP]  the authors didn't n't n't compare method [SEP]  didn't n't compare their method
ICLR_2020_1142,58556,the claims are clearly stated and the framework is detailed while the paper does a great job at presenting the problem and its applications and propose a framework that generated a loss that can transfer to other datasets without any tuning required the paper is well written and easy to understand ..,clarity [SEP] positive [SEP]  the claims are clearly stated is detailed [SEP]  a paper does great job [SEP]  the presenting problem [SEP]  paper any tuning required
ICLR_2020_1142,58557,it would be beneficial to clarify when it is happening.,clarity [SEP] negative [SEP]  it would be beneficial [SEP]  it would be beneficial
ICLR_2020_1142,58558,i think it lacks a more thorough evaluation and description of the dynamics observed during the genetic evolution you should also cite label smoothing as an additional way to achieve a very similar implicit regularization effect as the baikal loss.,meaningful-comparison [SEP] negative
ICLR_2020_1142,58559,paper proposes a very interesting idea of loss function optimization i like the idea. the paper's idea is very interesting ..,originality [SEP] positive [SEP]  idea like the paper's [SEP]  a proposes very interesting idea [SEP]  idea like the
ICLR_2020_1142,58560,this part is very weak since mnist and cifar10 are very small datasets and the provided results are far from state of the art results. and do not analyze the overall behavior of ec for loss functions.,substance [SEP] negative [SEP]  the overall behavior ec [SEP]  the do not not analyze overall behavior
ICLR_2020_1142,58561,it's a compelling idea that is well motivated ..,motivation [SEP] positive [SEP]  it compelling idea [SEP]  a compelling idea is motivated
ICLR_2020_1142,58562,there are some important drawbacks of this work ..,motivation [SEP] negative [SEP]  some important drawbacks this work
ICLR_2018_666,58679,several parts are missing and not well explained. it is not clear to me how to train the proposed algorithm. the experiment settings are not described clearly ..,replicability [SEP] negative [SEP]  not how train the proposed algorithm [SEP]  not not not well explained it [SEP]  not clear me how train algorithm
ICLR_2018_666,58680,many claims in paper are not proved properly by theory results or empirical results. the union bound discussed in sec 3.2 is also problematic the quality of the paper is not good the results and the interpretation of the results are not complete the whole paper and experiments has nothing to do with local connectivity you didn't show any support for the idea it need more extensive discussion and emphasis also this result is not available. and i am still not convinced by the quality of the paper ..,soundness [SEP] negative [SEP]  the is problematic quality [SEP]  many claims paper not the [SEP]  claims are not not proved theory results empirical [SEP]  the good interpretation [SEP]  the results good [SEP]  paper paper are not not not the complete whole [SEP]  not has nothing [SEP]  any didn't n't show support [SEP]  n't need more extensive discussion [SEP]  not result emphasis this [SEP]  i not available convinced
ICLR_2018_666,58681,seems to be a valid variant.,soundness [SEP] positive [SEP]  be a valid variant
ICLR_2018_666,58682,"the authors should provide a more clear and rigorous objective function. but the rest of the paper has not been written well. after reading it the reviewer has absolutely no idea what the paper is about (except hierarchical latent variable model), what is the motivation, what is the general idea, what is the contribution of the paper. this section is really bad ..",clarity [SEP] negative [SEP]  this section really bad [SEP]  the authors should provide function [SEP]  the a more clear and rigorous objective function rest not [SEP]  it reading [SEP]  the reading reviewer [SEP]  the the idea motivation general
ICLR_2018_666,58683,"the introduction and related works sections read well ,.",clarity [SEP] positive [SEP]  the introduction related sections [SEP]  introduction related works sections read well
ICLR_2018_666,58684,"the experiments part is not complete. also the experiments have not been conducted thoroughly, and you need to give more metrics, or generation examples, recontruction examples, and so on nor does the paper discuss any of the results. 5 .more importantly, some experiments should be conducted to explicitly show the validity of the proposed hierarchical latent model idea ..",substance [SEP] negative [SEP]  the explicitly show validity [SEP]  the experiments part not [SEP]  not you need [SEP]  give more metrics [SEP]  the does paper discuss results
ICLR_2018_666,58685,it is hard to justify whether the proposed algorithm is really useful based on fig 3 the idea of local disentangled lv is not well justified to be useful ..,motivation [SEP] negative [SEP]  it hard [SEP]  is justify the proposed algorithm [SEP]  based fig
ICLR_2018_666,58686,i think this paper presents a direct and somewhat straightforward extension of ali.,motivation [SEP] positive [SEP]  i think [SEP]  think this paper [SEP]  paper a presents direct and somewhat straightforward extension
ICLR_2018_666,58687,compare and discuss about the results baseline methods might be insufficient. i think the paper would be stronger if it directly reproduced the experiments from dumoulin et al. .,meaningful-comparison [SEP] negative [SEP]  discuss the results baseline [SEP]  the think paper
ICLR_2018_666,58688,therefore the novelty is limited ..,originality [SEP] negative [SEP]  the therefore novelty is limited
ICLR_2020_332,58809,"but rather ad hoc. it is not motivated by theory or the analysis is interesting, but i am not fully convinced by the strong evidence to the efficiency and effectiveness of our algorithm. the analysis of the compression rate throughout training is interesting but does not seem to be fully convincing. provided more convincing evidence why the proposed method is effective.",soundness [SEP] negative [SEP]  the effective proposed method [SEP]  is not motivated theory [SEP]  i not not not interesting am fully convinced [SEP]  the not not am fully convinced strong evidence [SEP]  the evidence efficiency convincing more [SEP]  is evidence convincing provided more
ICLR_2020_332,58810,i believe the experimental results to be strong the performance seems to be good.,soundness [SEP] positive [SEP]  i believe [SEP]  believe the experimental results
ICLR_2020_332,58811,"the key limitation of the proposed model come from the experiments. 2) another weakness is that proposed model has to be tested on large scale dataset, e.g .imagenet 2012.current two datasets are too small to support the conclusive results of this proposed model though it would be more convincing if the paper showed results on larger datasets like imagenet. it would be stronger if the paper 1) included more results on bigger datasets like imagenet , 2) described the main idea more.",substance [SEP] negative [SEP]  the more described main idea [SEP]  the limitation come experiments [SEP]  limitation proposed model come [SEP]  be tested large scale dataset [SEP]  conclusive results results [SEP]  the results paper showed [SEP]  results more paper included [SEP]  datasets results paper included bigger
ICLR_2020_332,58812,"as for the model itself, i donot find very significant novelty ..",originality [SEP] negative [SEP]  the model donot donot donot donot find novelty [SEP]  i donot donot donot donot donot find novelty [SEP]  donot donot donot donot find very significant novelty
ICLR_2020_332,58813,the idea of applying trainable mask to weights and regularizing toward masking out is quite interesting and new to my knowledge. this paper proposes an interesting idea (trainable mask ).,originality [SEP] positive [SEP]  the idea applying mask [SEP]  new my knowledge [SEP]  idea an interesting paper proposes
ICLR_2020_332,58814,the description of the main idea is not clear ..,clarity [SEP] negative [SEP]  the description main idea not
ICLR_2019_1162,58847,"the motivation of the work is not clear method, and consequently the motivation of the current paper does not make sense at least to me ..",motivation [SEP] negative [SEP]  not not me make least [SEP]  the work not clear method [SEP]  the the motivation work not [SEP]  motivation not not not not not consequently does make sense least
ICLR_2019_1162,58848,the problem of pu learning is interesting ..,motivation [SEP] positive [SEP]  the problem pu learning
ICLR_2019_1162,58849,but the novelty seems to be present.,originality [SEP] negative [SEP]  the novelty seems
ICLR_2019_1162,58850,"the paper is very hard to follow as the problem description and intuition of the d gan is not clearly written. the quality of the writeup is quite bad and a large number of critical sentences are unclear. in short even after a careful reading it is not clear exactly what is the method that the authors are proposing the mathematics in this paper is not easy to follow, and there are many other critical issues. i cannot easily follow the meanings behind the equations. the logic in the story line is unclear to me.",clarity [SEP] negative [SEP]  the paper very hard follow [SEP]  the is not not clearly written quality [SEP]  a quite bad large number [SEP]  number critical sentences are unclear [SEP]  a it not careful reading [SEP]  clear exactly what [SEP]  the the method authors [SEP]  the are authors proposing mathematics [SEP]  follow not critical easy many other issues
ICLR_2019_1162,58851,so the impact of this work to solve positive unlabelled data problem is not evident furthermore the reference pn method performs worse than other pu learning methods which does not make sense. i am not quite convinced by the experiments. pgan and the proposed.,soundness [SEP] negative [SEP]  not not does make sense [SEP]  the impact this work not [SEP]  solve positive unlabelled data problem [SEP]  the not reference pn method [SEP]  performs worse worse other pu learning methods
ICLR_2019_1162,58852,3 .the experimental results in table 4 and table 3 do not compare to genpu ..,substance [SEP] negative [SEP]  3 the experimental results table not [SEP]  results do not not compare genpu
ICLR_2020_685,59467,"this paper was very clearly written and easy to follow. the main contributions section was excellent as well as it allows the reader to quickly understand what the paper is claiming. the introduction related work section was very clear, and seemed to quickly get the reader up to speed. this is a great paper, with some interesting results presented in a tight, clear manner. the paper is overall well written and the algorithm is clearly described ..",clarity [SEP] positive [SEP]  is clearly the algorithm described [SEP]  this paper was clearly written easy [SEP]  is paper the section claiming introduction related work [SEP]  the allows reader [SEP]  some interesting results presented [SEP]  a clear results presented tight manner [SEP]  paper the reader quickly understand
ICLR_2020_685,59468,i find the need to clarify my understanding and request for more information in order to make a decision ..,clarity [SEP] negative [SEP]  a make decision [SEP]  find the need [SEP]  clarify my understanding
ICLR_2020_685,59469,the experimental evaluation section was exceptionally clear ..,substance [SEP] positive [SEP]  the experimental evaluation section exceptionally clear
ICLR_2020_685,59470,"in general, i would have liked to see more evaluation e.g .i would have liked to see more results with a variety of perturbations and on a variety of datasets i would be interested in seeing how network size affects the performance of your technique while i would like to see more experiments on larger datasets e.g .imagenet the results seem solid and absolutely worthy of publication.",substance [SEP] negative [SEP]  g e see more evaluation [SEP]  a results variety the [SEP]  would datasets be interested [SEP]  how size affects the performance [SEP]  would like more experiments larger [SEP]  g e results larger imagenet seem solid
ICLR_2020_685,59471,what hyper parameter tuning did you do.,replicability [SEP] negative [SEP]  what hyper parameter tuning did do [SEP]  tuning did you do
ICLR_2020_685,59472,ingredient is a novel algorithm for layer wise adversarial (re) training via convex relaxations. .the proposed methodology seems original and novel ..,originality [SEP] positive [SEP]  the proposed methodology seems original [SEP]  ingredient a novel algorithm [SEP]  training convex relaxations
ICLR_2020_685,59473,"the concept of latent adversarial examples, the layer wise provable optimization techniques and the sparse representation trick are interesting in their own regard and could be valuable ingredients for future work in this direction ..",motivation [SEP] positive [SEP]  could be valuable ingredients [SEP]  the concept latent examples [SEP]  the concept layer layer wise techniques are [SEP]  the sparse representation trick are interesting [SEP]  trick are interesting interesting their own regard
ICLR_2020_685,59474,i am not concerned about the missing comparison with randomized smoothing based approaches.,meaningful-comparison [SEP] negative [SEP]  i not concerned [SEP]  concerned the missing comparison
ICLR_2019_251,59569,"overall, the contribution of the paper is somewhat limited but a little more than my initial assessment.",originality [SEP] negative [SEP]  the the contribution paper [SEP]  more my initial assessment
ICLR_2019_251,59570,"but this is not standard notation and should be defined i read it 8 times and i still cannot tell what it is supposed to do. overall the paper suffers from a lack of clarity in the presentation, especially in algorithm 1, and does not communicate well why the assumption of different dynamical processes should be important in practice. i find algorithm 1 unclear and do not understand how it is formally derived, its justification seems rather fuzzy.",clarity [SEP] negative [SEP]  its justification seems fuzzy [SEP]  not standard notation be [SEP]  not still cannot tell what [SEP]  a lack clarity [SEP]  not the does communicate assumption different [SEP]  important practice find unclear [SEP]  read it times
ICLR_2019_251,59571,the paper is very well written ..,clarity [SEP] positive [SEP]  the paper is well written
ICLR_2019_251,59572,the paper has merit and would be of interest to the community ..,motivation [SEP] positive [SEP]  the paper has merit [SEP]  paper has merit [SEP]  would be interest
ICLR_2019_251,59573,but are limited to two end the proposed method would help for a larger variety of datasets.,substance [SEP] negative [SEP]  are limited two end
ICLR_2019_251,59574,datasets and it is unclear to what extend.,soundness [SEP] negative [SEP]  datasets unclear
ICLR_2019_251,59575,authors also clearly discussed the relevance and difference to related work ..,meaningful-comparison [SEP] positive [SEP]  authors also clearly discussed relevance [SEP]  authors also clearly discussed the relevance
ICLR_2020_1141,60130,the idea of using meta learning to deal with the forgetting issue is interesting. it is a novel and well explained idea i really like the intuition behind optimizing for the anchors via gradient descent.,originality [SEP] positive [SEP]  the really like intuition [SEP]  the idea using learning [SEP]  using meta learning [SEP]  it interesting [SEP]  idea a novel well explained [SEP]  i well explained
ICLR_2020_1141,60131,2 .the comparison with the previous shows that the proposed method performances consistently well on multiple tasks.,meaningful-comparison [SEP] positive [SEP]  2 the comparison previous shows
ICLR_2020_1141,60132,"the results in table 3 deserves more discussion. basically, this result is not persuasive for the effectiveness of the proposed anchor point learning method ..",soundness [SEP] negative [SEP]  the persuasive effectiveness proposed [SEP]  results deserves more discussion [SEP]  result this not persuasive
ICLR_2020_1141,60133,the technique of replay is well established. and the results are compelling.,soundness [SEP] positive [SEP]  the technique replay [SEP]  the technique is well established results compelling
ICLR_2020_1141,60134,2 .the writing can be polished. the paper is well written.,clarity [SEP] positive [SEP]  writing can be polished [SEP]  the writing can be polished polished paper
ICLR_2020_1141,60135,there are several typos. this section could be clearer it's not clear to me why this constitutes a meta learning process and add further discussion and intuition as needed.,clarity [SEP] negative [SEP]  section could be clearer clearer it not [SEP]  clear not me why constitutes process [SEP]  a not why constitutes meta learning process
ICLR_2020_1141,60136,the paper seems quite centred on memory replay based approaches to continual learning.,motivation [SEP] negative [SEP]  the paper seems
ICLR_2018_5,60676,"this is a set up that has been used in a large amount of previous work and the novelty is relatively limited ,.",originality [SEP] negative [SEP]  is a set
ICLR_2018_5,60677,the work is extremely creative and packed with interesting experiments ..,originality [SEP] positive [SEP]  the work extremely creative packed [SEP]  packed interesting experiments
ICLR_2018_5,60678,"i see this as an interesting piece of work that may be of interest to researchers exploring questions around language creation and language evolution ,.",motivation [SEP] positive [SEP]  exploring questions [SEP]  an interesting piece work [SEP]  researchers exploring questions
ICLR_2018_5,60679,but i think the results require more careful analysis.,substance [SEP] negative [SEP]  i think [SEP]  think the results [SEP]  results require more careful analysis
ICLR_2018_5,60680,"clarity of exposition the paper was rather hard to read. also, you should explain what the degenerate strategy the agents find is ..",clarity [SEP] negative [SEP]  also should explain what is [SEP]  clarity exposition [SEP]  exposition the paper
ICLR_2018_5,60681,there is virtually no discussion of this interesting interplay in the paper. but the authors could at least apply the topographic analysis of compositionality in the raw pixel study as well.,soundness [SEP] negative [SEP]  the topographic analysis compositionality [SEP]  virtually no discussion this interesting interplay [SEP]  the authors could least apply topographic analysis well
ICLR_2018_5,60682,and it is difficult to compare them.,meaningful-comparison [SEP] negative [SEP]  it difficult [SEP]  compare them
ICLR_2018_5,60683,"section 3 i couldn't find simulation details how many training elements, and how is training accuracy computed.",replicability [SEP] negative [SEP]  couldn't n't find simulation details [SEP]  training is accuracy computed
ICLR_2020_524,60726,"i am very much in doubt about this paper as there are too many aspects of the work i do not (currently) understand. i found the geometric exposition to be rather confusing. i found this exposition to be rather chaotic, and i suspect that this is the root cause of me not understanding many aspects of the work ..",clarity [SEP] negative [SEP]  are many aspects not [SEP]  doubt this paper [SEP]  this exposition be rather confusing
ICLR_2020_524,60727,experiments with language affinities are not convincing to me ..,soundness [SEP] negative [SEP]  experiments language affinities not [SEP]  me convincing
